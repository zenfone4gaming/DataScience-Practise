Time,Speaker,Text
0:13,Sanyam Bhutani,"Hey, this is Sanyam Bhutani and you're listening to ""Chai Time  Data Science"" podcast for data science enthusiasts, where I interview practitioners and researchers and Kagglers about their journey, experience, and talk all things about data science.

Sanyam Bhutani  0:46  
Hello, and welcome to another episode of the ""Chai Time Data Science"" show, the show bring you quarantine content to enjoy interviews with my machine learning heroes about their journey. In this episode, I interview Emmanuel Ameisen who's a machine learning engineer at stripe, and the author of the O'Reilly book building machine learning powered applications, going from idea to product. That's the subtitle of the book. In this interview, as you can imagine, we talk about Emmanuel's journey into machine learning, and how his journey through different through the different roles led him to writing the book. We talk all about the book. In my opinion, the book even though it's this 250 pages, is one of the greatest resources for the title for Building ML Apps, and also one of the greatest top down learning books that follow the top down teaching approach that I very much learned from fast AI. Please do pick it up if you'd like to enjoy it greatly during the quarantine physical isolation time. We talk about who the book is a really for, what can you expect out of it? Emanuel's journey of writing to Book and where to go after you've read the book. How do you find your idea to take to project your passion project or your million dollar app idea either ways, for both Emanuel says many great advices I feel this is a great interview covering all sorts of biases in the realm of machine learning and building machine learning products, milling machine learning apps. So I'm really excited to be sharing this interview with you. Without further ado, here is my conversation with Emmanuel. And as a reminder to the audience, you can also go to YouTube and watch these interviews in the form of a video along with properly checked me uploaded subtitles for non native English speakers and for people that would like to read about the data sciency terms if any, that would go over so please feel free to go to the YouTube channel for the podcast. Without further ado, here's the conversation. Please enjoy the show.

Sanyam Bhutani  3:12  
Hi, everyone, I'm really excited to be talking to Emmanuel Ameisen on the show today. Emmanuel, thank you so much for joining me on the podcast."
3:19,Emmanuel Ameisen,Thanks for having me.
3:21,Sanyam Bhutani,"Really excited to be finally talking to you. So, like always, I want to start by talking about your journey. What made you start your journey into machine learning? I believe you have a background in math and then business. When did machine learning become your passion?"
3:35,Emmanuel Ameisen,"Yeah. So that that's right. Initially, I you know, post sort of high school education, I went towards math and then towards engineering and electrical engineering. And then when I was working on my master's, I got kind of a little,  maybe disillusioned with the field in the sense that although the technical work was compelling, but it's kind of felt very old school, a lot of what I learned was more about, or what I was taught was more about, like the electrical engineering aspect rather than maybe more modern things like how computer science work. And so I remember thinking, oh, I I'd like to have more like an applied skillset. And that's why I decided to go to business school. Looking back on that, you know, the decision to sort of double major in electrical engineering in business. I'm not sure that I really got what I wanted out of it. I think business school was certainly informative. But as far as like finding meaning and giving meaning to your life, maybe not a choice I'd recommend. And so it was while I was in business school that I was particularly bored in an HR class I remember and, and I actually went online and I stumbled upon Jeff Hinton's lectures, she had on Coursera."
4:56,Sanyam Bhutani,There's like 11 course right?
4:59,Emmanuel Ameisen,"Yes. Yes, exactly. I feel like a lot of people got their start from the Andrew in Coursera. But for me it was Jeff Hinton's. Although I checked out Andrew Yang's later. I was fascinated. I thought that that was absolutely. You know, he had a way of sort of explaining machine learning and the beginnings of deep learning as this serve almost. Kind of, yeah. unexplainable, magical. You wouldn't even believe it thing like you would, I certainly had the server like model that would be fed relationships between like a family tree and then would infer, you know, like, you would give it like a bunch of like, this is this person's father and this is person's like, sister, and then you would you'd like phrase a question, no way to say like, Okay, then who's who's the uncle of that person? They would like, figure it out without you ever having a hard coded any of the rules. I was like, oh, wow, this is crazy. And so, shortly thereafter, I decided to switch back and actually, I was already double doing a master's in electrical engineering and a master's in business. I was like, well, AI actually seems really interesting. And so I am I signed up for like a research Master's in artificial intelligence and worked a little bit on deep learning a little bit optimization. And actually, my master's thesis was mostly focused on multi agent simulations, which is something that's like very explored outside of RL, I guess. But yeah, that was just really interesting to me. And after I did that, I decided that machine learning was really fun. And that's when I moved from France from from to the valley. And I started my career as a data scientist at a startup called local motion that then was acquired by Zipcar."
6:35,Sanyam Bhutani,"Okay, now I sort of want to jump forward to Zipcar where you were working as a data scientist, and this will help me segue later into talking about the book that you've written. But I was I was going to LinkedIn which if I may, is also a resume and you'd mentioned you also were involved in the front end and back end, that that is in the sexiest thing to at least data scientists aspirants. You were a data scientist working on front end back end tech. Can you maybe explain a bit about the importance of even being involved in these things while still working on the data sciences side."
7:07,Emmanuel Ameisen,"Yeah, yeah, for sure. That that's not how I'd say my first few months on the job were my first few months were very much more on like the data side and sort of like algorithmic side and optimization. You know, I worked on various jobs, one algorithm that would take GPS data and try to recompute itineraries and trajectories, because GPS data is like, super noisy. And so you need to actually do some signal processing to, you know, from just a bunch of GPS points, I get to try the streets that a car went through, for example, it's like very data sciency stuff. But then, in a few of these projects, what I found is, I think what a lot of other data scientists have found in their careers and what's been the fuel for many medium articles, which is that getting the data in the correct form early, even having access to the data And then I think it's even more importantly, once we had a model, like taking actions based on that model, serving this model to users, even internal users was always the biggest challenge, it was a big challenge, because it served like didn't fit within the traditional, maybe like sprint planning that you'd have at these types of orgs. where, you know, we really needed the support from engineering to actually integrate our models in production. And that was something that at the time we didn't really have. And so due to that, I ended up growing very frustrated, and then ended up sort of, you know, bothering engineers that were more skilled than me and asking them to like hold my hand as I was trying to learn how to do front end and how to do back end and all that stuff. And you know, they were super helpful and searches helped me actually get our products shipped across the line. And this was like, you know, I did front end, just to be clear, not for the Zipcar website, very wisely, they wouldn't let me get close to that one, but it was for more, you know, internal tools, where we'd have tools for, you know, our contractors, for example, that would service cars. And so we needed to display predictions to them in a way that they could access it from their phones or laptops. And so that was the front end that I was working on."
9:14,Sanyam Bhutani,"Now again, I'm sort of again jumping forward because I can't wait to talk about the book but you later joined insight fellows. I also want to discuss your journey from I believe you were one of the first fellows the first batch in the student mentees that they taken up your journey from there to becoming the lead and your takeaways from later mentoring so many students."
9:36,Emmanuel Ameisen,"Yeah, so I, I was a part of the first session of the AI programme, but actually insight was older than that had been operating for years, I think, since 2012, I believe, for their data science programme. But they had just started the AI programme. And, you know, as I was working at Zipcar, I sort of had decided that I wanted to get A new role, and potentially a role that was closer to I guess what was called at the time, which was mostly like a little bit of deep learning research with the hope of being applied. That was back in 2017. And so most people, you know, thought that you just hire a bunch of smart people, they do like a bunch of deep learning research, and then somehow, it would make it into your product. And you'd make millions didn't exactly turn out that way, in terms of how I was shift, but that's that's a story for another time. But yeah, I joined and I was part of the programme and I loved it. And I joined because I wanted what insight offers, which is insight, gives you this opportunity to one work on a project for a month and get to dive deep into a topic. So I did some style transfer for audio, which was still to this day, one of the most fun projects I've ever worked on. And then you get to actually, you know, the whole goal of insight is to introduce you to companies that you could work out and so you get to like, have discussions with all of the team members of these companies. And so that was just extremely fun to have all these conversations and really see what these teams were doing, like, you know, as opposed to what they have on their job board, you actually got to talk to the data scientist or the ML engineer, you know, like in your day to day, what do you do? What do you spend most of your time on? What are your big problems, and that was that was extremely informative. And so it turned out that when they did ask me to join the team, I valued that experience. So much like the experience of getting to talk to various people that were all these teams and learning what they do. I felt like I learned so much so fast, that I jumped on the opportunity to help with the programme. Because it was just such a great opportunity to see a lot very quickly, more breadth over depth, if you will. And so yeah, I joined, I joined I sort of grew the AI programme from where it started to a much larger programme over two years eventually ended up leading the team that was taking care of it. And and through that work got to chat with like dozens and dozens dozens of companies that were doing applied machine learning and mentor, hundreds of students are fellows. And I think that was yeah, still like the pace of learning at that insight was incredible because you very quickly pattern match once you've seen, you know, not one NLP project with like 25 or one image classification project with 30. So that was that was an amazing experience. "
12:24,Sanyam Bhutani,"Awesome, and I believe you mentored a lot of people. Did you see any common pitfalls? I believe this was this might have been the groundwork for you also leading to the book have any common pitfalls, any common takeaways from mentoring so many people?"
12:39,Emmanuel Ameisen,"Yeah, there definitely were. That was definitely a motivation both for the book and for writing, you know, online in general, I think I'm not gonna have to convince you, I think you're, you're very much on board but like blogging, I got really into blogging during my time inside because it felt like a huge very good way to share the lessons I've learned. You know, there's a common saying that if you, if you explain something or write an email twice, you should probably write a blog post about it. And that was very much that and so yeah, there were a lot of common pitfalls, I'd say that there's probably too many to discuss all of them. But there were a few that I think are just wildly applicable to machine learning projects, even today. And that was that one, fellows often, and practitioners in general, kind of focus a lot on the methods on the on the how, and less on the why. And, you know, that means that like, when you have an initial conversation about like, what projects they should work on, whether it's at a company or whether it's for their startup, whether it was an insight, we'd often say like oh, well, you know, like, I want to work with Transformers or, you know, I want to do reinforcement learning or, you know, and and that always like, makes a lot of sense, right. These techniques are exciting, but it actually I found that never worked to sort of start from the metal. They didn't say like, okay, well, I want to do reinforcement learning and then try like find some some problem, you know, that could justify you doing it because it was always obvious to whoever you would talk to later that was like, oh, you're not actually solving this problem, like you just shoehorn this random thing into your technique. And so one of one of the biggest shortfalls was like, if a project didn't start with, like an actual purpose, then it would almost never succeed. Because you know, what you'd find is if you want to use reinforcement, learning to solve something, and then in the course of solving it, you realise that actually, you could solve it better with something else? Well, what you really should do is you should do something else. But your whole goal was to use reinforcement learning. So you're probably going to just do your reinforcement learning thing. And then the people that see your work are just going to say like, we're like, I guess this is interesting, but in general, they hire you for your ability to solve problems, about your ability to use techniques, and I'll definitely judge you, because you solve you didn't solve a problem or you solve it in an underwhelming fashion. So that was a big one. There's two other ones that I think are crucial. The second one is very related, which was starting with the simplest thing. This is something that I held on in my book is something that many programme directors before me had insight, you know, would would harp on about, and it's that, usually, for any given project, you should build something that's just as complicated as you need, and not not any more complicated."
15:23,Sanyam Bhutani,And be of sorts so that you can pitch to your manager.
15:27,Emmanuel Ameisen,"Exactly, right. Like in the in the entrepreneurship world. Like this is not new, right? Yeah, of course, there's like, the classic MVP. And, you know, there's like a bunch of diagrams and books on the topic of machine learning. It's, it's the same. The reason why that might have not been clear is a lot of the field of machine learning is full of newcomers, because it's a very exciting field. And when you're a newcomer, you often want to show that you actually can do the complicated thing. And so you'd have this failure mode, where you'd have somebody that's new to the field and I would say like, oh, well well, you know, for this sort of like classification problem, I'm going to do this kind of crazy thing where I'm like embedding all these images using NLP, like doing this, like very intense thing, where, you know, you could have like, used fast AI and done like transfer learning and gotten like a really good classification model pretty quickly. And they did this not because they liked making their lives harder, they did this because they, they're understanding both from being new to the field and from seeing fancy blog posts from like fancy companies was that that was what was going to get them notice, right that like, if you go to like a hiring manager, a company and you say like, hey, look, you know, I've built this like, really elaborate system to say, like, Oh, my God, I need to hire this person. They can do the hard stuff. But in reality, that's something that that hiring managers get just a bunch of, they get a lot of very complicated projects. When I was, you know, interviewing fellows for insight we'd interviewed like, thousands of fellows every session, we would have no shortage of complex projects. When there was a shortage of was somebody that like would would take a project, I would say like actually, you see this project, you may think that it's complicated, but I found a way to frame it in just a simple way. And then my model is like very simple, and it works. And it's reliable. And it's resilient. It took me a couple of weeks. And that person, every time the fellows that actually do, this would just be the ones that, you know, like, would be successful, we'd get all the interviews and all the callbacks. And so it was like a bias towards simplicity, which again, is obvious other fields, but not so much in machine learning. That was the sort of like potential pitfall from from fellows. And then there was the last one, which was simply iterating. It's linked into simplicity. But there's basically two ways that people would go around the projects, which is one would be, again, just like complex approach. And then what that means is like if your projects and say a month, you'll spend a month getting it to work and maybe that like by the end of the month, you'll have something that works. And it kind of doesn't work just right, but you spend your whole month and you just have to figure out a way to pitch it. Or you have the folks that worked on something simple and then they could do that. The experimental approach of saying like, okay, like now I have this simple object, a simple, you know, like model I've built or the simple thing I've made. And they can say, ah, this part, this part is the one that is the worst, I'm gonna spend a week on this part. And then they would like do it again and be like, okay, now I have my version to this thing. Ah, now this part is good. This other part, that's what I need to fix. And those projects would be much more impressive because they would tell such a longer and more detailed story, right? You'd say like, well, you know, in four weeks, I've actually built like three different versions. And those three different versions solve these very specific problems. And learning to do that was was how you success succeeded. "
18:34,Sanyam Bhutani,"Make sense. I have definitely been guilty of chasing the bigger, extremely biggest model I could ever make. I think that that's one mistake every one of us makes if we honest, it's really about how much value can you provide to the company you working at? That's that's where the huge salaries in machine learning lie and people often miss out on the fact that if you try telling your manager that, hey, I'm going to make a state of the art model and it will take me 15 days. Good luck with that."
19:02,Emmanuel Ameisen,"Yeah, yeah, exactly. And it's completely fine to play with fancy balls, right? Your point everybody's done it. But as long as you're honest with yourself, and you're saying like, hey, this is mostly like prototyping slash, you know, learning or throw away work, I'm going to try to like replicate this transformer architecture just because I want to know how it works. And that's fine. But it's very different from the kind of skills when it demonstrates to yet deliver at a company of your working out or show to a potential company interviewing you that you're a high quality hire."
19:30,Sanyam Bhutani,"Yeah. Now coming to where you currently working at stripe your role as a machine learning engineer, stripe is a payment company, if I may read is machine learning coming to the picture of payments. It's this transactions. How is machine learning involved?"
19:45,Emmanuel Ameisen,"Yeah, that's that's a good question. I think there's many, well, I know there's many parts of stripes that that use machine learning and some may be more obvious than others. One, one nice distinction that you can think of is stripe is a company that helps merchants process payments. And so there's two sides to it. There's merchants and payments. And so we have machine learning teams that focus on detecting things like bad actors are account takeovers for merchants. So you know, either a merchant that's trying to sign up for something that's not allowed on stripe. You know, there's lists of businesses that are forbidden on stripe trying to detect that automatically. You can build models to address that. Or you also have the payment side, that's the side that I'm working on, which is, you know, stripe processes, very many payments a day. And not all of those payments are by their rightful cardholder or you know, the person that actually wanted to initiate the payments. Some payments are due to you know, somebody stealing a credit card or seeing somebody information. And stripe actually has a product called radar, which helps merchants that use stripe automatically detect these fraudulent payments. And so you can imagine that you have like a very classic machine learning problem here where you have you know, the vast majority of payments on stripe that you want to happen just as they are, then you have like a small, very, very, very small fraction of payments, that is illegitimate, but that you want to block you want to block them because you know, they're essentially the result of theft usually. And so it's it's like the needle in the haystack problem machine learning is the opposite of the ones that usually have in the books are usually in the books you have like a very nice 50-50 split between your classes. But here you have this this like very, very, very small fraction of cases that you need to catch. And you need to catch them with a very low false positive rate, right because if you use stripe and I started just blocking your normal transactions, then you're not going to want to use stripe. And so that's like a very interesting problem because it combines two They're like a pretty hard a classification problem. But it's pretty hard framing, like the stakes are very high. And aspects that I think is starting to get considered more and more machine learning, which is heavy engineering requirements. Like because it's on every transaction, you have to have a model that will be highly available, and that you know, will not fall over and that we'll be able to score and transactions fast enough that like you can actually buy whatever it is that you're buying."
22:27,Sanyam Bhutani,"I guess I like to call it the parental control by my bank, whenever it tries to buy something internationally, it always blocks my transactions and annoys me very much. For example, even even it blocked my payment for your book with;"
22:41,Emmanuel Ameisen,It did!
22:42,Sanyam Bhutani,"Yes, unfortunately."
22:44,Emmanuel Ameisen,"UUnacceptable. So yeah, this is why you need a good team of machine learning engineers. And yeah, and some of these are hard problems. A lot of banks in the world use like heuristics, right where it's like, well, this card holder is from this country and they're buying something another country. Let's just block it. But to your point, when you're taking a vacation, that's terrible. And you know, you don't want that to happen. And so it actually takes some much more sophisticated, both data processing and like machine learning models to actually be able to tease out, you know, what's, what is an unusual payment?"
23:16,Sanyam Bhutani,"And I think many people assume that, hey, this has been going on for so many years, we will have credit cards, even before machine learning, why isn't this a solved problem? It's like, like you pointed out a needle in a haystack. The cases are so less the class imbalance if I may, is completely off the charts."
23:34,Emmanuel Ameisen,"Yeah, it's the class imbalance definitely makes it tough. Because regardless of how easy the problem is, if, if you have a wild class imbalance, you're gonna have to work pretty hard to get a model that has like, you know, perfect recall, and no false positives. That's that is very much unsolved. And there's also it, there's sort of, one thing I talked about in the book is that for most machine learning problems, you have an irreducible error, like, it's unreasonable to expect that, you know, even if we were to hire all machine learning practitioners and give them infinite budget and let them do whatever they want, that you'd be able to catch all fraud, right? If you think of, you know, like, you're buying patterns, maybe you're a person that mostly uses, you know, your credit card to buy books on Amazon. And then let's say maybe you drop your credit card at some cafe and I'm a mean thief. And actually, I'm also mean thief that loves books, I steal your credit card, you know, I live close to where you live. And I also buy a book of Amazon. Like that's, I don't know how you detect that right? Like it's same card, same code of purchase from the same location, provided you haven't reported your card that's very hard to detect, proactively. And so there's, there's always going to be like some amount of fraud, whether you can imagine it's just going to happen and it's just not something that you can classify. And even the question of saying, like, well, what is this amount? It's a question you could serve spin up a research team on because it's not easy. I used to even know what you should aim for."
25:02,Sanyam Bhutani,"Actually, funnily, I remember an instance, I was in New York for my Google interview, which absolutely failed. But I swiped my card at the hotel and I got a call from my bank saying, hey, have you swiped the card at the hotel that you're supposed to stay stay, I I had given my itinerary to them. And I actually ended up asking them why are you asking me this question? They gave me the same response. Since it was just a transaction of $200 we were worried it was stolen because that that's not an amount you pay in New York."
25:35,Emmanuel Ameisen,"Oh, interesting. Yeah, exactly. Any sort of like outlier? You know, you can you can look at it and say like, well, obviously, they should have seen that this is fraud. This is much more expensive than usually buy. But then when you buy your TV, you're very happy that you're, you know, your bank doesn't like immediately ban your card because it's more expensive than what you usually buy."
25:53,Sanyam Bhutani,"Now, coming to the book, it's titled machine learning powered applications going from idea to project. Now when I was young, I would If you write a book, it takes you a few days, and you become this famous superstar. But now I've come to realise that it does take a lot of effort. It's it's really a service to the community, if I may, because you're really teaching them at least much better than in university in a much more recent fashion. And it does take a lot of effort. Why did you decide to write a book go along that path?"
26:26,Emmanuel Ameisen,"Yeah, that's, that's, uh, I, I'm amazed that you you thought that writing a book took a couple days. I think I underestimated the effort, man. A couple days. That'd be impressive. Although I was reading about an author just today that apparently manages to write 80 pages a day, which is just crazy and much faster than I that I write. To answer your question, I think so initially, I got started by writing these blog posts, right as a consequence of a lot of these come on, like error slash pitfalls. So it's there, you know, like a bunch of projects I saw that were around natural language processing. And I said, well, okay, all these projects are essentially trying to class."
27:09,Sanyam Bhutani,"We can read these if you want to right now, can we read these blog posts? Are they still up?"
27:14,Emmanuel Ameisen,"Yeah, they are. Yeah. So you can read them at two different locations. They're on the official blog of insight data science, but they're also on my personal website, which is the same as my Twitter handle. So if you go to mlpowered.com, all the blog posts are here. And you can sign up, you know, I have a notification list. So you can sign up and you just get the future blog post in your inbox as I as I publish them. "
27:37,Sanyam Bhutani,Awesome. 
27:40,Emmanuel Ameisen,"Yeah, thanks for the opportunity for the plug. And so yeah, I started with these blog posts, and the blog post started from like, oh, here are common errors, like I'm going to just teach you like if you're classifying text, honestly, you can use this sort of like cookie cutter approach. You know, it won't solve all your problems, but it'll solve most of your problems and you should probably start there. And you know, I didn't For NLP I did one for computer vision as well. And the reception to those was honestly amazing. It felt so heartwarming. I kind of wrote them mostly as a as a way to coalesce my thoughts initially. But then, you know, folks from all over the world would say, like, hey, you know, I was working on this really, like hard projects, either either personally, or for my company, and I was stuck. And then I saw your blog post, and I could actually get me unstuck. And so like, thanks, you know, it's really cool that you wrote that. And that made me really happy. I was like, oh, wow, actually, it has a multiplier effect, right? It's almost like I can, like make little clones myself that then go talk to all these people that are, you know, I don't even know where that where they live. And it can tell them like, well, in my opinion, you should do this. And so that was that was the motivation for writing the book. I want to do that but in a more thorough manner, in a manner where I could actually cover all of the topics and so that's why I went to write the book. But that's not the whole reason, the reason. The other reason that was important is I felt like until recently, there was a disconnect between the resources that would teach you machine learning and what hiring companies would want and what would make you successful at your job. And I saw this every day at my previous job at insight, where, you know, folks would read, sir, like either very math heavy, sorry, very theoretical books, or they would read very fancy blog posts from like, you know, companies that are saying, oh, we're using, like, reinforcement learning to do auto ml on this thing. And so that's what they would study. That's what they would focus on. And then we talked to hiring managers at the same companies that were pushing these blog posts, and they'd say, like, no, honestly, we, you know, if they know how to do a linear regression, we really just care about them being good engineers, or like, hold on, like, there's like this huge disconnect where you're saying like, what I really value is like these engineering skills and these like product focus skills that will get you to build applications fast. Where's like all of the candidates have been reading the blogs that you've been putting out. They're saying like, no, no, no, no, no, like, go like publish a crazy paper like beat the state of the art image net, that sort of stuff. And it's not to say that, like, the more academic approach is wrong, it has its place. And it's gotten us to where we are. But it just was was kind of used as a way to get into the field when it shouldn't have been. And so I want to write a book that would help two kinds of people, the people that wanted to get into the field, and the people that just wanted to use machine learning for their products for their startups for their current company. And it felt like there wasn't a book that specifically kind of focused on that. And so it's it was missing. And since I felt like that was a lot of my day job, I decided to write the book."
30:41,Sanyam Bhutani,"Certainly. And so mine my naivety of the assumption that book doesn't take a lot of these came from, if you already have a bunch of great blog posts, it just really takes compiling them into a book. Can you talk a bit more about the process? How did you find it?"
30:57,Emmanuel Ameisen,"Yeah, I mean, having written blog posts definitely helpful, at least to the extent that you've like, started the process of getting your thoughts out. The whole process of writing a book, I would say is I, when I started writing it, I talked to other O'Reilly authors. And I asked them about, you know, like, how is it for you to write this book? And I'm sure he wouldn't mind. me sharing this. I talked to Pete Worden, who wrote a great book about tiny ML machine learning on embedded devices. And he told me, it's about whatever your estimate is, it's about at least twice as hard as you think. And I said, oh, that's fine. So I doubled my estimate. And I would say it was about twice as hard as that doubled estimate. So I don't know you know how the world works. It seems to me like it beats the laws of mathematics, but no matter how many times you double your estimate, it will still be twice as hard as that. And it took a while It took about 18 months from start to finish. The whole process of writing a book is variable. Different from blog posts because the feedback loop is is is like, kind of long, and writing 250 pages in a way where every page is informative is actually it's not easy, right? Because there's a temptation, especially because you want to, like get all your thoughts out to just like, right, right, right, right, right. But then by doing that, you're doing a bit of a disservice to your readers in the sense that this isn't sort of like a fiction novel. This is supposed to be a book that teaches you machine learning. So I, you know, I don't want there to be like fluff where I kind of like ramble on for like six pages, I wanted every page to have an impact. And so it was a bit disheartening because I would write like 50 pages, and I would cut them down to 20. And I would do that again. And then it takes a while, you know, if you're always cutting down your pages, and so that was the part that was maybe the longest once I had a final draft of the book. Then we did a certificate tech review process, but that part is much easier because then you know, you have we had like very qualified data scientists read through the book. Tell me what they thought and then I could address you know, all of the questions or comments, you know, anything that he noticed that wasn't accurate. I could fix and and that was much easier. The real hard part is getting all the information to make 250 useful pages. That's that's tough. It was tough for me."
33:16,Sanyam Bhutani,"Okay. No so Jeremy, Jeremy Howard mentioned your book in the upcoming fast AI lectures. And I looked it up. I was like, okay, this is just 250 pages. I can finish this in a weekend. That was me just being overconfident. I am still in the first few chapters, if anyone is wondering. So who is is the book really for? Do I need to be an expert? Do I need to be a machine learning practitioner in order to pick up because it titles taking applications to a product? And do I absolutely need to know every new template of machine learning in order to be able to pick it up?"
33:50,Emmanuel Ameisen,"Yeah, it's, it's a request. So I you know, I hope you get through the book and you enjoy it. Please let me know. If you don't you know, I'll get your refund."
34:01,Sanyam Bhutani,I've been definitely enjoying it.
34:03,Emmanuel Ameisen,"Okay, good. Um, there's there's a few things here, which is, it's, you know, when you write a book, part of the book proposal is they ask you, sir, like what your audiences? And every book author, I think at some point just wants to answer everyone, like, Oh, well, you know, everybody would benefit by book, it's great, you should all read it. But you do need to point to narrow down on a set of folks that would benefit from it. My, my two audiences that I mentioned a little earlier, you know, were folks that were transitioning into mountain lion to learn about it, or folks that just wanted to use ML for practical purposes. And those don't always have the same background. In fact, what I found is a lot of readers have been sending me an email or writing reviews, or readers that are data scientists and ML engineers, and they're like, oh, I was stuck on this particular project or a second problem. I read your book and it made me think about it differently and give me like a few comparisons, a few tips and I like how to break through And actually managed to ship this project. I mentioned this because they weren't the especially the intended audience for the book. So it was a big surprise for me. And I was really happy that it was valuable. the intended audience, and a lot of the other comments I've been getting is, again, folks that don't necessarily need to know, any prerequisites, all of the parts where you actually need prerequisites where it says like, oh, you know, like, here, use a random forest, maybe like, what I have no idea what the random forces are written so that you can kind of just skip. There's code examples that are also written so that you can skip them. You know, I've had, I've asked a friend that that doesn't know, Python at all like to read through and, you know, to tell me if there was any part that wouldn't make sense if you skip the code examples, and they were like, No, no, no, this actually you get a lot of value from reading the book, even if you just skip all the code examples. And so, as much as possible, I tried to minimise prerequisites. And that was a conscious decision. Because again, I felt like the other problem of the existing literature is like, you know, you're like, oh, I want to learn about machine learning. And you're like, okay, you open your machine learning book and then the first thing is like, oh, you know, like, calculus like, what do I remember from calculus? Like nothing? And you're like, okay, well, I just want to classify images and like, no, no, no, no, like you first you have to be able to derive backprop from scratch. And then maybe you can classify images. And so, you know, you mentioned Jeremy Howard, I like, very much respect and admire his approach, like it's very much something similar that I went to do, where it's like, it makes no sense that you have all these prerequisites, like, you're welcome to dive into them. If you do discover, like you have a passion for machine learning. But for this book, honestly, it's aimed for folks that have an interest in machine learning and that are computer literate."
36:35,Sanyam Bhutani,"So this is more of a fan moment. But Jeremy calls it the top down approach. And usually because I am the laziest person, I usually skip forward from the code sections come back to them later when I'm in the when I have just woken up in the morning and having chai and then I enjoy coding. And I was absolutely able to through your book and I just realised that it's because your book really also follows the top down approach. So thank you for creating one of those very unique books."
37:03,Emmanuel Ameisen,"That's I'm glad to hear it. Similar to Jeremy, I learned personally in a top down manner. I'm just like you. So I'm glad that that it follows that well."
37:12,Sanyam Bhutani,So what all do you cover in the book? For someone who's just picking it up? Can will they will will they be able to ship every single type of machine learning model into production? What all can they expect from it?
37:25,Emmanuel Ameisen,"I mean, that would be the greatest sell, right? I could just tell you, this, you just throw away all the other books and courses is the only one you need. No, you'll definitely I throw some references, you know, in the intro for subject follow up topics and the book does link to other books that could help with with different parts. But it does aim to cover every part I'd say it aims to cover so like the breadth of ML and then to give you like, hey, if you want to dive deeper into like actually deploying applications, like you probably want to read this other book, but it covers what it covers is sort of like four big parts, which is first the intersection between sort of product thinking and machine learning. And that's something where that is too often skipped. And it is too often the differentiator between like a project that lasts for four months and then fails. And a project that is just like shipped in two weeks is you know, you have some some product manager or like your CEO or yourself that has like a vision for a feature that you want to accomplish a thing. And then usually, depending on what you choose for your algorithm, or what you choose for your data set, it will be very easy or hard. The first part is all about helping you make the best decisions. So you can just progress as fast as possible. The second part is all about actually, like exploring and looking at your data that's also a part that either is skipped or other data scientists skip, or I mean complain about they're like, ah, 95% of my job is just, you know, looking at data. And, and there's no reason it should be that way. You actually learned the most from looking at your data set. And so it's just gives you various tools like gather data set, inspect it, try to see whether a model will actually learn from it. Once you're done with that, the whole third part is about iteration back to the pitfalls that I talked about. A lot of maybe less experienced folks are to focus on on the machine learning. task as if it was linear. You know, they say, okay, well, first, you know, you get the goal, you get a dataset, you train a model, you evaluate it, you're done. But almost every single machine learning project is a loop, where you do very many iterations of, you know, look at your project, train a model, get some results, and then maybe you retrain the model and you retrain the model here. Okay, now it turns it performs better and then maybe you realised that like, you have a crucial feature that's missing. So you add like you do some feature engineering, you add a feature and then you realise that maybe like, your products, not quite right to change, like, what kind of predictions you make, etc. So the whole third part is that is like the iteration of loop of machine learning. And how to speed that up. And finally, the last part is, you know, once you've actually decided that your model is good enough to ship, what are your options to ship it? What are different paradigms that you can use? And sort of like how should you think both about how to ship it and how to how to ship it like safely and reliably? There's a lot you know, once you start shipping models that customers actually use, there's a lot of things you have to keep in mind when you want to update a model or even when you want just want to check that your model isn't going completely bonkers and kind of breaking everywhere. And so that's what the fourth part is about. And so it's everything but obviously, you know, for each of these parts, you can like write a whole book about and whenever I found such books I try to link to them so that you can you can dive deeper if you so wish. "
40:47,Sanyam Bhutani,"Awesome. Do you have any advice for the how fast should be your iteration, uh Radek Osmulski I just want to give a shout out to his technique. As much as I love watching the loss values go down, I'd be happy to debate with anyone who's a machine learning practitioner. Are you not a real practitioner unless you wasted hours just watching the loss codes. But what's what's your take on how fast should be the iteration loop? Radek mentioned that when you're interactively working on models, that should be around 30 to 60 seconds, because after that you lose your attention. Any any thoughts? Dou you, how far should you iterate on having the first model ready, then going back to inspecting your data set and fall in that too?"
41:31,Emmanuel Ameisen,"Yeah. So I agree, I think, I don't know about 30 to 60 seconds. I think that depends probably on, you know, if you can, that's great. Sometimes, you know, if you're training on a giant data set, that might not be possible."
41:44,Sanyam Bhutani,"So to elaborate on that 30 seconds, we're just starting out on the smallest possible subset of your data set, then the loops should be around 30 seconds because that will allow you to think properly and not go into the trap of control T, Let me go to YouTube"
42:01,Emmanuel Ameisen,"Yeah, exactly. Are they like, you know, what are you doing other things compiling? Like, I'm just gonna go for a walk. Oh, my models training, I can just go like, you know, cook a steak or something. Yeah. Yes. So actually have have little to add except to say that, yes, you should make your feedback loop as short as possible. And in fact, in the in the third part that I talked about in iteration, one thing I talked about is like one way to do that is to think of three, six, like almost like a hierarchy of like building your own project. So in other words, your first goal should be to have your data go all the way through to your model, and to have your model like even an untrained model, just kind of like output a prediction. And for that you need like, you know, if it's temporary, like a couple rows, or a couple images or a couple sentences, and so for that, it should, in fact, be extremely fast. And at that point, you know, you're debugging sort of like tensor size mismatches are like your you like some pre processing function is opening something of the wrong format. So that's like very quick and you're just like getting the data through. Once that's done, you want to check that you can over fit on a single example. And that's something that that isn't advice has been shared by many other folks. For me, it was Ross Bailey from inside actually, that, that told me that for the first time, and that's something that I now swear by, it's like, once once you can, like get data all the way through, you just train your model on one example, and you see that you can get the last, you know, two to zero, basically. And then you know, if that doesn't work, you know, you have a problem somewhere. And so you don't need to use your whole data set, you can stay on this, like, you know, couple example regime and just figure out what's going on. And then once that happens, then you can actually train your model on a reasonable data set and validated and so obviously, for the first two parts, I agree, like, honestly, your feedback loop should probably be even way shorter than 30 seconds. It's really in the order of a few seconds. And then for that last part, that's where you know, you maybe jump down the road hole of YouTube and and listen to some good podcasts. But yeah, for the first few parts you want that feedback loop to be extremely short."
44:08,Sanyam Bhutani,"Awesome. So the next question is sort of another issue that happens with top down learning is to just be able to trust the teacher. I think you'll pick up an NLP project to example in the book, how will I be able to apply this to computer vision? Any thoughts? I know that you are giving very rich advice in the book, but the part of me that's a bottom up learners, thanks to university also also makes me worried I need to Google this up. I need to know this. How do I do this? What are your thoughts?"
44:41,Emmanuel Ameisen,"Yeah. That's a super good question. Because I think, especially if you're somebody that's interested, okay, that's a there's two things. If you're interested in building a computer vision app for particular purpose, you want to you know, a;"
45:03,Sanyam Bhutani,"Hot dog or not hot dog, for example."
45:05,Emmanuel Ameisen,"Exactly a hot dog or not hot dog. Or you want to do you know, like just anything where you try to recognise something in an image, I would argue that you'd still, I mean, I wrote, it's obvious, I'm biassed, but but you should still maybe like start with a book and you get a lot of value from it. Because the book will help you, like, get to your end goal faster. So like, regardless of your method, it's it's not that much about NLP as much as it is about building ml powered applications. However, if your interest is, you know, diving deep into the world of computer vision and understanding, okay, well, you know, how does the CNN model classify images, then I would recommend going for a resource that focuses on that, you know, in other words, if you're trying to get a deep understanding, and if I put a matter even of NLP, or if computer vision or reinforcement learning there are resources are dedicated to teaching you that and a lot of time they are bottom up research. And they're very good. But if you're looking to be a better practitioner that ships things faster and more efficiently, then the whole point of the book is that it tries to make that advice as generalizable to any, you know, data set slash model that you may have. I do dive into sort of like specific here's how you'd vectorize images you know, using a pre trained model, here's how you do that stuff. But I'd say like most of the value is in fine tuning that process. So you become like this like machine learning machine that can like more quickly, frame your problem the right way quickly, get a data set quickly, iterate quickly, test it quickly deploy it, as opposed to you know, learning more about a specific domain."
46:46,Sanyam Bhutani,"This is also one unique thing in the book CICD and testing. Now to me as a young ML practitioner, I would have never heard of these things. Can you can you give us an easy way were these are using the ML pipeline and also in the book what all do you cover in this area."
47:01,Emmanuel Ameisen,"Yeah. Yeah, it's always something you don't think about until you're the person has to fix everything that broke. And then, you know, after cursing your past self for a while you you decide to focus on it a little more. It's still new for, you know, like, see CICD for software engineering has a bit of history behind it and is now better understood, I'd say for machine learning, there's still a lot of paradigms are being currently discovered. But there there are things that are worth doing. More specifically, you can do everything that you do normally for software engineering, and that a lot of a lot of books have been written about that I like to some of them. But then there's a few different things when you have models. So when you have models, your models kind of only as good as the data it was trained on. Right. And that means that of course, you should be careful about the data was trained on and that's part of the second part of the book about training data set, but it's also something that you should think about when you're shipping your model right? There's many errors, tragedies are due to training your model on a certain kind of data set, and then trying to run inference and another kind of data set, right? If you only have folks have, you know, a given skin colour and your training data, it will only work for folks at that given colour in your app. And that could be terrible, most likely. So there's, there's like, of course, like you can have like the products that things think about practically, but you can also just, like, monitor that and be alerted if that happens. And so, like, a simple way to do that is you can just look roughly at the distributions of your features in production and compare them to the distributions you trained on. And so that's something I give a few tools with, using a library called Great Expectations where you can, you know, simply say like, okay, well, here's what you know, the mean and median values of these various things were in my trading site or even like distribution and like, I want to check that we're within, you know, a reasonable bound of these that means that you will be alerted if that's not the case. And the reason that that's super important is because your model will run no matter what data is fed. And so one of the biggest mistakes I see is like, oh, well, you know, like the models still running, still making prediction. And it's like, yeah, but if like, your distribution is completely shady, it's basically you have like a random number generator in production. And you're just like, you know, patting yourself on the back saying, like, oh, we shipped ML, but essentially, you have this like random box of garbage. That's just like outputting random stuff. And ideally, you'd like to catch that before your customers complain. And so there's both those tests on the distribution. And then you can also just look at your models outputs. Similarly, if your model is a classifier, and it's starting to always output something close, like 50%, there's something like that maybe a foot, if it's, you know, starting to output, always one class, whereas like it used to be pretty balanced or something as opposed. And, and one of the things that you can do in that case, is you can have what's what's called a filtering model, which is you now have another machine learning model that tries to decide whether you should run your model like your real model. This is something that's used, for example, for Smart Reply by Google. And their paper, they talked about how they don't always generates these, like suggested responses. A lot of the time, they'll have like a simpler model that says, like, hey, actually, this is not appropriate. Like, we should not run it on this email, it won't work. And that allows them to just save the user from having terrible results. "
50:27,Sanyam Bhutani,"Okay, so the next question comes from Vrinda Prabhu, also along these lines, how do you handle bias or outliers in a CICD environment where it's a constant loop of integration."
50:42,Emmanuel Ameisen,"Yeah, this is an interesting question, because I think it's very open. So my understanding of the question is, is mostly that about outliers in production? I don't know. Because the other the other version that's that's can affect your models is how outliers affect your training set, then you could train some like a wacky model. We can skip that for now. Because hopefully you could back test that and verify that your model is not, you know, acting weirdly because an outlier in the training set. So if you have outliers at inference time, the two methods I just brought up, address, address them both. So if you have outliers in terms of your input data, you can sort of say like, whoa, you know, we have this serve confidence interval where like, 95% of values should fall within, you know, like minus two plus three or whatever. And like, we just got 27. So something's definitely wrong. And then it's sort of up to your application, what you do this is very application thing, like maybe you, you need to run another model. Or maybe you can afford the luxury of telling the user like, hey, something's weird. We're just not going to show your prediction right now. Like, maybe that's fine, right? If it's something that's not critical, and so you can have control flow that says like, oh, if we detect an outlier, because because we've now computed the usual distributions, we do something different, we run a different model, or in the book, I talk about having a backup heuristic where you can say like, hey, if there's an outlier, and we're like pretty sure that the model is going to go crazy if we feed that data, just fall back to a heuristic. Having such a heuristic is another reason why it's really good to start with the simplest approach, because you build your heuristic as like the first baseline that you're hoping to beat with your model. But then you can take that heuristic all the way to production saying like, hey, if everything else fails, like if all our data is wrong, if you give us like weird outliers, we can fall back on this heuristic and it should be fine."
52:37,Sanyam Bhutani,"I think this has been a very rich interview this this is one of the last questions maybe for a beginner so to speak. How do you suggest a less creative person maybe a person like me find their idea before we've even before they want to take it to production? Many, many people struggle with that. How do I find my million dollar app idea that I want to take to production"
53:00,Emmanuel Ameisen,"That's, that's interesting. And I guess you're trying to find a million dollar idea which makes this harder. Hmm."
53:07,Sanyam Bhutani,"I mean, a passion project that I can burn my GPU credits on."
53:12,Emmanuel Ameisen,"Yeah. As somebody that's, you know, not a millionaire. I'm definitely not the resource on finding million dollar ideas. But as far as passion projects, I do have a few recommendations, which is it's kind of like blog posts. I think that stops a lot of people from writing blog posts is that, you know, they say, oh, everything has been written about you. And this is something that, you know, you're in the Romans way back in, it's still complained about where they were like, oh, what, what is there to write? We've already written everything that's useful. Why would I bother writing stuff and the truth of the matter is, there's still a lot of things to write. There's a lot of things to build, but also it's okay. If the thing you write or the thing you build is your version of something that exists. You know, I'm not saying Like plagiarise and lie and steal, I'm saying like, you can take a popular app that you enjoy and try to make your version like if you like Grammarly and you use it, maybe you make your own Grammarly. It might not make you a million dollars, you know, they probably have thought about the problem for a while, but you're probably gonna think about it from like, a different approach, and you probably can just have a different take on it. And regardless, it's going to be super valuable because, you know, it's a useful product, it's like by a company that already works. Like they can sell it, you know, people want to and so you validated that part of it. And then you can focus on the part that presumably you actually want to learn, which is like, okay, like, how do I ship this ML product? How do I get it out there? So taking an existing idea, that's a good one. I just think like, okay, you know, I'm gonna build my version of like a photo tagging system. I'm gonna build like my version of some like, speech to text system. It doesn't matter if you're not the first. In fact, like you'll be able to lean on existing work. A lot to shore up your weaknesses so that you can focus on the most valuable things for you to learn. And you'll be able to like, build all this stuff. And then once you've done it once, then you can sit down and think about your million dollar idea, because now you know how to do it. So you can just focus purely on the idea."
55:14,Sanyam Bhutani,"If I may contribute to that, I don't know how would this translate to engineering because this is more more of a philosophy will take but for blog posts, what helped me is, there's so many movies out there even even the famous famous ones are just the same baseline story, right? It's more of a display of how generated so look at even the movies coming out. It's almost the same story for every single genre, but yet you enjoy every single one of them. Same same with blog posts, I would say. "
55:44,Emmanuel Ameisen,"Yeah, that's a good point. I agree with that."
55:48,Sanyam Bhutani,"Awesome. Emmanuel before we end the call, I'll have all of your profiles and websites linked in the description. Any special ones that you want to give a shout out to for the lazy listener?"
55:59,Emmanuel Ameisen,"Yeah, I mean, you know, the book just came out. And as I said, I poured sort of my heart and soul into it for 18 months. It's truly everything I've learned about machine learning, both from doing it myself for many years and from mentoring hundreds of fellows. And so, you know, I couldn't think of anything else to add these pages. So I think there's a lot of information for anybody that's starting, or that has been in the field for a while. So, you know, I would just strongly recommend checking it out. If you go to my website, the first chapter is actually available as a PDF for free. And so you can just check it out, see if that's your kind of thing. And if it is, you know, it's on Amazon and O'Reilly.com."
56:40,Sanyam Bhutani,The website is mlpart.com. Right.
56:43,Emmanuel Ameisen,That's right. 
56:44,Sanyam Bhutani,"Okay, awesome. If you were to write the next book, do you have any thoughts, any ideas there? What will your next book be about something that you think is missing or something that you will absolutely enjoy reading?"
56:55,Emmanuel Ameisen,"Oh, I think the other thing that I'd love to write about is the engineering side of ML, but I don't think I'm knowledgeable enough to write that book. So I'd like to learn more about sort of the the robust at scale engineering laws of ML. And then I'd like to make that more publicly available. Because I also think it's something that, you know, a small set of engineers at very big companies know when everybody else kind of just doesn't really understand."
57:25,Sanyam Bhutani,"Awesome, thank you so much for joining on the podcast and thank you so much for all of your amazing insight."
57:31,Emmanuel Ameisen,"Yeah, thanks so much for having me. This was really fun."
57:40,Sanyam Bhutani,"Thank you so much for listening to this episode. If you enjoyed the show, please be sure to give it a review, or feel free to shoot me a message you can find all of the social media links in the description. If you like the show, please subscribe and tune in each week to ""Chai Time Data Science."""
