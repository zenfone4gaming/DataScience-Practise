Time,Speaker,Text
0:13,Sanyam Bhutani,"Hey, this is Sanyam Bhutani and you're listening to ""Chai Time Data Science"", a podcast for data science enthusiasts, where I interview practitioners, researchers, and Kagglers about their journey, experience, and talk all things about data science.

Sanyam Bhutani  0:45  
Hello, and welcome to another episode of the ""Chai Time Data Science"" show. In this episode, I interview a researcher, practitioner and open source contributor. Yes, all three are aspects of one single person Sergey Kolesnikov, creator of catalyst, which deep learning and reinforcement learning framework based on Pytorch. In this interview, we talk all about Sergey's journey into the field of machine learning and reinforcement learning. His thoughts about open source development and the story of catalyst, how the development of catalyst started the story behind it, and its current features, the ecosystem. And what all can it support. We also talk a lot about the community in machine learning open data science community as well. Sergey shares many great advises about software engineering and open source development as well. And I believe that advices are applicable even outside of catalysts framework, generally speaking. We discussed about a lot of ideas about catalysts and outside of it, so please check out the description of this podcast if you'd like to read in depth about them. Along with a quick reminder to the non native English speaking audience if you're listening to the audio of this podcast please go to YouTube and enable subtitles because it will have manually checked and re uploaded subtitles to help video watching experience. For now, here's my conversation with Sergey Kolesnikov, creator of catalyst. Please enjoy the show.

Sanyam Bhutani  2:30  
Hi everyone. Today I'm honored to have on the show a researcher, practitioner and open source contributor, fortunately it's not three different persons. It's the same person Sergey Kolesnikov creator of catalyst. Thank you so much for joining me on the podcast."
2:46,Sergey,"Thank you for their my show for this invitation. It's it's really an honor for me to be here on this podcast because it's, it's like it's the first time I got such an honor to be on a podcast. I did not i'm not sure on the specialized end on or to make some fancy stuff. But thank you very much for your invitation."
3:12,Sanyam Bhutani,"Thank you so much for saying yes to the request. Now, before we talk about catalyst and the amazing framework, I want to talk about your journey. I think the secret to becoming really good at machine learning is having a name Sergey, or Dimitri, and having a background in physics. Is that true? Can you confirm that belief?"
3:30,Sergey,"I don't think I really strong background in physics. Yeah, I am graduated from Moscow Institute of Physics and Technology with this power skills in physics, mathematics and all the stuff. Nevertheless, I think the man when contribution machine learning and why it's so important to me, it's just my turn on motivation, because it's more in the form of this field, especially in the field of reinforcement learning, and deep learning self. So I think it's more about your inner inclination and motivation, rather than your hard skills."
4:14,Sanyam Bhutani,"Okay, at in your journey at what point did you get interested in machine learning? I believe you studied physics in school. Where did ML catch your interest? "
4:25,Sergey,"Oh, no. When I was on the first no, no. third year of my university I had large inspiration in deferral regarding fields like you know, mobile development, game development, all this stuff with development, several visualization projects, etc, etc. But later I found, you know, the simple example with monies and all stuff and then I was trying to understand how does it work. Understand the programming, but this looks like a little bit like a magic because he, and then this thing, somehow the standard it's one two three or; "
5:15,Sanyam Bhutani,Black magic. 
5:16,Sergey,"Yeah, it was interesting because I can get this process. But thanks to again for the university, there was a bunch of courses in statistics, optimization theory and all that stuff during this year. And with my motivation and some interest in this field, this game give me some boost to understand this machine learning part. Like a deep learning part and then reinforcement learning bottles. "
5:50,Sanyam Bhutani,"Okay, we'll definitely talk more about this but talking about your current you, you were working on open source, you're also leading data science teams. Can you tell us what problems are you working on? How do you balance your time?"
6:08,Sergey,"Oh, it's their complicated question because I'm not sure their experience in their into my time, right? Cause usually I just, I have my personal notion with all my stuff been just taskings ever to do. And usually when I look at it, it looks like work. So I work and we'll deal with it. It's really complicated. I don't know. Yeah, just somehow somehow it looks like a different fields of interest and I'm trying to work on each of them every day, for maybe several hours. But because of the number of different fields, gives them an opportunity to work the whole day like this."
7:16,Sanyam Bhutani,"So when you get bored of work, you switch to open source when you get bored of that you cease to community efforts."
7:22,Sergey,"Yeah, and I'm trying to, you know, combine all my interest interests around, you know, the catalyst, because it's like my expertise, open source expertise in one place. So every projects I'm working on, somehow contribute to the library, the development to open source and community. So it's, it's a lot of different fields and tasks and projects and the roles there's only one core, so somehow, it helps."
8:00,Sanyam Bhutani,"Okay, they were already many frameworks out there. TensorFlow was out there when you started catalyst. Why did you feel the need to create a separate framework? "
8:13,Sergey,"Okay. It was maybe around three years ago. 3 years ago, I was working with TenSorFlow and they'll stop. And they will listen, I found this amazing and simple framework like Pytorch but it has no disadvantage. It was a really low level. And for me, because of just take several projects simultaneously, like you know, several computer vision tasks by like, I don't know. But I found it. It's hard for me to keep you in my mind and to long barrel execute them. So they decided to make some common tools, some tools to use them during all my projects, and then the second development was mine my ideas like Ruby disability, then all know and it's another matrix oh I have another projects that no different we out so slowly slowly it's become not more complicated but but but more flexible and with a lot of extensions and after half year with development I decided to open the open data science community for open source because I want to show its produced and I felt this idea that with such time the framework, we can now create some kind of to, to really, you know, gain all this knowledge in this library and to share our knowledge between even different terrorist like division, natural language processing, time processing, reinforcement learning. And so this community of experts of professionals that can really have this ability to execute a lot of experience experiments, a lot of hypothesis testing with these two and to share the knowledge with all this community and to give the boost for the oldest era of deep learning. "
10:48,Sanyam Bhutani,"Okay, so, so sorry."
10:53,Sergey,"Yeah, and after another year of development to find make this package at least. And yeah, finally, it's now after one year with the development. And two weeks ago there was get was about the source. Yeah. So we're really happy that for this one tiny year we can say so we have no moves from one project to the whole ecosystem. It's looks amazing. And I think it's only the beginning. I hope."
11:40,Sanyam Bhutani,"For sure. For the audience, I'll speak out a few words that might sound very interesting, open, reusable, reproducible, modular, tested, deep learning with software engineering practices. This is not a wish list. This is these are conflicting words, if I may put together in the GitHub report description. of catalysts good Can you tell us more about this design philosophy? It's it's slightly uncommon at least in deep learning world world to find these words together."
12:10,Sergey,"Yeah, somehow just one is about floating around says it's all know it's research. It's unreproducible."
12:21,Sanyam Bhutani,Black magic.
12:23,Sergey,"Yes, black magic but now, there is no magic. It's just optimization. It's it was sophistic machine learning is our lovely grid in the French, the European descent, etc, etc. It's just, you know, programming with mathematics, nothing special and with some kind of abstractions, this architecture design, and you can make it deterministic, you're deterministic and really that's why the is some usable reproducible modeler? Because Okay, from my perspective, reproducibility was repositionable to really matters. So yeah, just needed strange clear that our department is producing guys, it's totally reproducible reusable because a lot of projects and I need to to to read modeler because for know for different projects you need to some some extensions or some;"
13:44,Sanyam Bhutani, benefits
13:45,Sergey,"Yes so you need to create the this architecture to make it available for some extensions, plugins and like registering all the stuff that we are working on. But to create this tool, this bicycle, you need to really good software engineer practice. Because just like the programming, it's difficult programming, but with these deep learning expertise, so, yeah, some unique synergy from both the fields, and I'm really happy we're, I hope we are somehow, you know, really in the middle and trying to combine all to these different fields because, and the standard for data science just, it's really hard to know this program staff engineer, and backend development. That's the first one from the programming and we can development. It's really hard to understand this machine learning both these two algorithms etc. And the Sunday but somehow I like both of the fields and try to combine them together and found I'm not particularly experts in deploring also engineering, but I tried to combine them together. "
15:17,Sanyam Bhutani,"Okay, to talk in a little different direction These are two different ways that you mentioned or software engineering and data science II. Usually they don't talk to each other in the best practices. What's your take on that? Should data scientists who are sometimes or even Kagglers known not to write the best code should they invest time learning into best software practices or do you think that will catalyst might help they could use catalyst to overcome that hurdle?"
15:45,Sergey,"I hope that this will be the most in research speed. This I have an idea to some somehow write a blog post about how to run 1000 experience experiments during the day and not today. Because, yeah, we can do it, we can do it. It's, but it's a little bit hard. I think for you know, today this, okay. Nowadays, if you're trying to make some kind of deep learning progress, you need this position power and it's why you need this machine learning tools, all this DevOps and the good computer science background, because you should just trying to to solve this problem along with in this node because some people like that it's really hard, because it sounds good, but solution. Just look at Google. It uses. There's there's this a lot of machine learning tools they can afford and a lot of GPUs and servers and by the synergy of computational power supply engineering and machine learning expertise, they gain visibility to create to push the limits of current deployment. This we are trying to make marketing open source. "
17:27,Sanyam Bhutani,"Okay. Now, coming back to catalyst, if I understand correctly, it sits on top of Pytorch. Can you tell us how it is different from Pytorch? And how does Pytorch not fulfill fulfill the philosophy that you aiming for?"
17:43,Sergey,"No, I think Pytorch is great work. It's simple. It's one way of doing you always say one way to do one thing. For example, loosely speaking about some of the framework;"
18:00,Sanyam Bhutani,Nothing to be named.
18:03,Sergey,"It's a little complicated. But Pytorch designs there are simple, it's pure, platonic and the world will understand. It's, it's good, it's amazing. But because a lot of deep learning stuff have a lot of same things, we really need some kind of fellow bi to do not to just reuse it. And there's why where's the countries come understand that. Nowadays we have a bunch of guys on top of Pytorch. Yeah, because we're even right. Currently, we are writing an article about comparison of different high level API's on top of Pytorch Nevertheless, I don't know I think capitalists have this philosophy about why we're doing this because it's not about a radical framework on top of batory because we love to run frameworks and now it's more about to give researchers an ability to test the hypothesis right or other don't just write on the batch of technical code, etc, etc. I don't know I think the human brain is human time is really expensive. So just give people good to, to know to remove all this hard technical part and give me the ability to test the hypothesis to test what they really interested in to have not I think with such kind of tools every such can give much more value of what he's doing. Because you must think about what you're trying to test and why you're trying to test this hypothesis, etc, etc, rather than to the back your seminar, the framework code. Yes, and it's not working. That's why we're writing this. And that's why we're writing other packages, really, because we're trying to make this r&d process more research oriented, rather than just do programming apart, hoping you were going regular."
20:48,Sanyam Bhutani,"It's really about taking a step back and doing the science not getting caught up in all of the nitty gritty details of software engineering or whatever details happened in that path. Now, now coming to the ecosystem, I think we can discuss these one by one but I want to talk about the different elements inside of catalyst. Just to name them out first these are alchemy catalyst, ml comp and reaction maybe you can start talking about alchemy, can you tell us what it is?"
21:21,Sergey,"Oh, okay. So speaking about the ecosystem. This nowadays maybe you see my post about that, we finally released our ecosystem, the contents of catalyst, alchemy and direction. The idea is simple. So, after the creation of catalyst and some development and evolution of the we have an ability to run bunch of experiments, you know, to transmit some things that are large number of models. But before speaking about during the process, it's only the beginning or from the in the middle. You also need to deploy it for your customers for your users, or someone who will test it and give you feedback about how does it work, etc, etc. And here comes the action framework. It's really simple one just gives you an ability to know to make a dynamical series with this all this best practices from the can development. See, a synchronous synchronous API, like batch processing. Know this bunch of began best practices But with this really simple API that you don't need to know all about this and not just write your typical Pytorch Python code, my quantum decorator and then not like a magic, but real simple, you can get this microservice. Because we're doing a lot of proof of concept, etc, etc. We have also an integration with telegram so you can give other people link to your board. And they can easily test your model and give you feedback about how does it work correctly. And it's really important because I now work with a bunch, a large number of researchers, developers, etc. And I just say okay, you give this model please rights with this mature series, we will try to understand how does it work, I will give you feedback, etc, etc. And also when you have this, you know, just like it's like a proof of goals of maker centers. But with this tool, it's already ready for development. So you can it has API so you can integrate it to an old system and give the value that you created with this model. Okay, you have got to turn this large number of models and also reinforcement learning part and action to deliberate to customer to deploy to give back. But then we'll also have alchemy. It's another problem when you were these framework that allows you to write to run a really large number of experiments you need to do to analyze what is going on and your clients now for now about it just a simple tool that allows you to monitor and to work all the mics, metrics, one place on the web, and also to share them. Just difficult, simple problem when I was sold in Norwich competition, I have four or five servers. And for me, it was really hard to simultaneously be on all the servers to check for the process, etc, etc. Like it's complicated. And you need some tool that will just collected in one place, give you all this time. Statistics give you all this beautiful blogs."
26:02,Sanyam Bhutani,A Dashboard of sorts. 
26:04,Sergey,"Yeah. So you can easily compare the models understand what the keeper parameters are, the speed where your problem and also, it's really important part that you can share link that any other person can check what's going on because nowadays I'm leading several groups of researchers and I just asked them to just please show me the link and escape I can easily understand what is going on with your experiments, etc, etc. So, there is no need, you know, to printscreen your metrics or you this is worth to have not come on. You know, to share these notebooks with bullets. Now you did it. You just need one of these And I can easily understand what is going on with your experience on maybe even check the code. So, so really about, again boosting the research speed."
27:14,Sanyam Bhutani,"Okay. Now I also want to ask about your opinion on how does this compare Pytorch's, I think it's the ONNX ONNX ecosystem where you can export a model and put into production."
27:29,Sergey,"Sorry, what again about it?"
27:31,Sanyam Bhutani,"So, catalyst also supports putting models into production. How does this compare the native Pytorch pipeline?"
27:40,Sergey,"Oh, yeah. So, catalyst also yeah, you're right. It supports the Pytorch tracing to. So that is quite simple because by authorities bureau protonic and it needs pattern code to Built model architecture to all the way etc etc. What for production needs, it's strange then you need some Python code to understand the model. And that's why last year by 13 interviews to Pytorch tracing, so you can easily just trace your model. So, get started graph some kind of been a file from the model is the shade between the servers between different architecture different hardware because it just some kind of static graph and you know file and reuse it in both Python or C++ code. So it's again some kind of technique think because with with the way again, for our reaction, for example, examples, we use only this, we train the model, then we trace it, we get some kind of, you know, file, we can easily load in our election forever, without an understanding about the work the architecture or this, networks, etc. We just need to know, the input and output of the and that's all. "
29:27,Sanyam Bhutani,Okay.
29:27,Sergey,"And it's a really good technique to make this, you know, from research to production quite easily."
29:35,Sanyam Bhutani,"Okay. Now, I also want to talk about something that isn't usually even talked about in frameworks, reinforcement learning, what's your take on reinforcement learning and why why even supported because most of the people perceive it as something that's not even production ready or won't help the world right now."
29:55,Sergey,"Yeah, the catalyst URL is another subframework for our framework, you can say so it was 2018. Okay, long story short, I'm working on the roots competition from 2017. And trying to do my best and some, in some places the and during of the first year of competition in 2017. I don't have any framework. But there were some kind of distributed training plan on top of just pytorch pubertal. Then we get this place, but no one cares. But in 2013, I was in Kimbrough that we need to do something bigger because I see that it wasn't funny parties, also quite general, especially when it is about continuous action control. There was a bunch of new algorithms like Dbg. Well now live tweet to the three and two, subject to predict etc, etc. And I was trying to find some framework that will allow me to execute a lot of experience. Not to tune the parameters, as I always like to, you know, make my research and somehow ultimate, but during two or three months of explorations, what's the best parameter for it was running. I haven't found it offering then. Okay, let's try to write it. And after two weeks of, you know this development we get this proof of concept and version of get those through. Its most powerful. It gives us ample, as I remember correctly, use us 1st place folks like some of things just like the first experiment, the thruster and model and like submitted for place and then after another to wonderful development. And yes, last little doubt, you know, algorithms in deeper interest in joining our DDbg, the free side, etc, etc. And then another three or four months of development we're now you know, support looks like all model free algorithms with a bunch of these, you know, extensions like, like, distribution of all the function books, nations such or etc. Yeah. So, yeah, it's just another world but because of reform to freedom for me, it's a beautiful field. And for me, it looks like you've got this deep learning part, this is mostly focused on running a good feature representations of the world and what is going on and to make a vector from Elgin, and on top of lead you this reinforcement learning part that is mostly focused on this control theory on how to make decisions and for, for me to use them simultaneously and reinforcement learning on top of deep learning path it's like and now it's just two parts of the thing. So that's why we are now working on combining deep learning, deep learning with capital sorrow to make this synergy and to use all our best practices for deep learning. Yeah, to boost our reinforcement learning pound because nowadays it's a little bit complicated."
34:43,Sanyam Bhutani,It's like one nuclear element on top of another nuclear element.
34:52,Sergey,"As usual, yeah, but it's so good. Like really beautiful. And the thing there, I have several ideas about how to improve this URL part. And think of this core refactoring of the library will get really interesting results in both RL and deploying because of new architectures features. Yeah, maybe maybe we will try to combine the ecosystem. And know try to combine the catalyst and drive simultaneously. So you can for example, training and elite etc, etc. Your model and just the one time it's interesting, I think, okay, it's the technical part. Sorry."
35:59,Sanyam Bhutani,"It's definitely a lot of fun, I'll have it all linked in the description, because we cannot go into much technical depth in a conversation. But for anyone who would like to check it out, it's already available to the public, it's not some future development that we're talking about, can you tell us what ideas are supported in the reinforcement learning side of world right now, in the sub framework?"
36:24,Sergey,"So, now this will support all this model free reinforcement learning algorithms, like normal Nichiren reinforce proximal policy optimization needed to G cycle free etc, etc."
36:41,Sanyam Bhutani,And sorry for the audience can you tell us what is model free RL and how; 
36:45,Sergey,"Yes. Yeah. So, speaker model training for small learning it's filled about trying to understand how to make good decisions parked along the policy that is good thoughts and reinforcement learning tasks are really general, you have only some environment and you have you or your agent and the judge and trying to you know, to explore the environment to do some actions to understand the world and long form it from this feedback. And feedback is really, really tiny, because you have this killer that says how we do without any label, so, etc. This model mostly using deployment. For such cases, are impossible one of two big approaches will look free or interesting one that tries to learn the model of the environment. So just without any bias about and model based RL that have some, you know, knowledge we can say about the environment. This URL is mostly focused on model free reinforcement learning. "
38:22,Sanyam Bhutani,Okay.
38:24,Sergey,"It's because it's much we get failed in wonderful URL Stevie curve(?) and the diversity of both methods and on policy matters of policy methods. I don't know. They they long the policy from that some replay buffer from some news experience. From just these transactions like you were in some state t, then you execute some action t you get these rewards to get to the state as dipasquale and buy these transaction you can the best action on policy matters learning from the whole trajectory and trying to optimize the culture Jake and simultaneous so on calls methods, record they require you to learn on the ball see they have executed just right now. And of course methods can learn from any policy from an experience they just need these transactions. Yeah. Nowadays, may be on both methods are more stable but really good only if you have some, a lot of samples from the environment if it's really quick, because on posts, the methods are really heavy, and for the samples because they need a lot of production to understand what is the best policy? And of course the members more simple efficient. They don't do any sample, but so many samples, but they're not. They're stable. Nevertheless, they are more production friendly. No, because when we speak about robotics, awesome, these can execute several millions of projections break; "
40:46,Sanyam Bhutani,Half of the world. 
40:48,Sergey,"Yeah, it's it's really because yeah, so and so four different locations you need different methods. For example, for these new IPS condition they were, I was to begin, there was an environment that was really slow. It was because about while frame per second, and for reinforcement learning, it's really, really slow. So you just don't have an opportunity to run their own policy methods because they can converge on such speed. But using this opals knotless a lot of tips, techniques, extensions, hacks, tricks that you can, again this amazing support efficiency. But it's like another story, because I have another pack of presentations for simple efficiency in reinforcement learning. Yeah. The circles and pictures, but for some to petitions, when you felt has been similar to my Sonic or you can use on both methods that more stable more easily than maybe just another two different worlds. But yeah, but still we're combining them and trying to even if the two different words the a lot of same ideas very common for both them and it's really interesting to to you know to see that of policy not let's have some kind of sanction that you can try on policy and see how does it work? It's really interesting. And maybe it's the whole idea of the capitalist, that when you know, get all this knowledge in one place, you can share the experience from one hour to awareness and see how does it affect? Really interesting. "
43:29,Sanyam Bhutani,"Okay, now, stepping back and talking about the bigger picture, can you tell us what sort of efforts and research goes into the open source development? I'm sure you invest a lot of time into it, but to give us a very high level picture."
43:44,Sergey,"Yeah. From the beginning, no contribution to open source. Sometimes I don't have time. Yes. Nowadays we're working on a wider range of ideas. For example, for last year, catalyst was mostly focused on computer vision because the team was mostly focused on competition and it's purely just interest and stuff from nowadays where development to an OB branch so we can see there are some, you know, their pipelines, tax purposes in etc etc. And also we're developing our tech was again because it's time another area for the sun we're in between of computer vision for honey so what else. Yeah, maybe maybe we'll try to make some stuff with sound processing. But it's a little bit complicated to combine all this something something also doesn't know we're now perfecting the URL part to make it more user friendly and human readable because currently it's really small engineering focuses focus because of the meat of distribution and training. Just like the food part understand. Yeah, and those who are development this the goal of the system also, so really a lot of parallel tracks when our development and get old steam. Look at Charles. We're trying return to look around. Yeah. Wow, it's looks really interesting."
46:06,Sanyam Bhutani,What what upcoming features are you most excited about?
46:11,Sergey,"Oh, of course, I'm really excited about second edition you can say so. "
46:17,Sanyam Bhutani,Okay.
46:19,Sergey,"Because after this improvement, I think we'll get an opportunity to apply all these reinforcement part to organization systems, for example. It's another field of my research I'm very interested in to somehow apply reinforcement learning to production. We can do and by this way, we you will get an opportunity you will get this framework capitalist. That is a parable for computer vision, natural language processing. Recommendation systems are impossible planning is beautiful because you have this do for everything. And the hope we will try to combine the different ideas and share the experience. I hope we can do. I know we can do. Okay, just the question of time."
47:28,Sanyam Bhutani,"I'm sure we'll be there soon. Is there anything in in, in the hindsight that you're most proud about? Something that the library currently supports? Some feature that you most proud of? "
47:42,Sergey,"Oh, because I'm really proud that we have the team such eam that is hard working. And I'm really proud that this initiative is still working because this is interesting project. I still can't understand how does it work? I mean, looking at when after one year of the development, I was making this retrospective about what we forget. And then then understanding for just one year of the development, we, like this amazing progress and like Kaggle figuration, Pytorch's system, different points of integration to the islands cape we have this from open data science for best project, open source project, we have this team that works on different areas, different startups, and contributes and develops around 50 contributors who kill this ecosystem even hurts some indication courses based on how does it work? It's amazing. It's something clearly. Wow. But still, I think it's only the beginning cause and see a lot of potential. What can we do with this with these two with this framework? That's why I'm now focused on yeah, maybe maybe the most important part, I mean, it's this ecosystem. Because we don't have this with projects, new products that we're working on, when we're speaking about the ecosystem, they give you much more value when they work simultaneously with this guten synchronization and synergy between all these projects. Yeah. And of course, I'm really proud for the team for the community. For I still can't understand how does it work because all the catalyst development is based on motivation. In this year, there is no support, okay, we get some kind of support from our friends, like, you know, I can ask for a server for example, and we can make several experiments over ????? center. But still it's just development, on motivation. And on the just, you know, from some some researchers decide to make some cool things for other researchers. Yeah. Let's hope only all these ideas we're trying to develop to create all this beautiful stuff. It's really hard to make it done. Yeah, it's not so easy."
51:39,Sanyam Bhutani,"It's it's really about it really speaks about the community. I'd like to also ask you about the community that you are an admin of open data science. I don't know how you find the time to also contribute to that. But if you could tell us about ODS and I think catalyst is of course very famous in ODS ,is it a part of how you get the feedback for the framework as well."
52:02,Sergey,"Oh, yeah. Open data science was really important about development. Because three years ago it was the first time in which I open this framework, which is oh, no. It's too complicated. Yeah, it's difficult part and they're trying to build something new. It's always complicated. But thanks to the open data science thanks to this community. Thanks to those ideas. They're open data science has also a large number of Google experts, for example. And this develops and nominated to integrate to get this expertise from all the schedule experts. For example, maybe you know, again if you tryna you have an interview with them with him he has his own fighters to belt or that is also his experts expertise and deep learning part one framework and what is interested it's also based on catalyst. So it's it's really cool to see that some are really experts in this field in the field in Kaggle and different competitions using this catalyst and surely ideas the back page the usage editor and open data sciences also the the it's it's a bit different I thought you nevertheless even though it's been us a lot of friends they're getting gets a lot of support for the future development because it's really important when you get in some new/interesting soon stuff and you need to have integration from other people. "
54:54,Sanyam Bhutani,Yeah
54:54,Sergey,"That because you're working all this stuff not for you but for that and that's why it's really important for me and hope for the whole capacity to get this back support from the open data science. Yeah. This but we can you know, we have this beat slack channel it's really some kind of boost because the loop of female trial then and execution of the our users and given the feedback it's so it's like another Fast and Furious are in the process. So we are developing some new feature or when we're asked, Hey guys, how you doing? How does it feel, than the US feedback and we are also trying to improve the next I release all the catalyst. So it's really good to community to try a lot of different sizes and improvements that you can want to do and get the feedbacks just a few days'"
56:26,Sanyam Bhutani,"awesome. I personally even I owe a lot thanks to the open to open data science community for being a huge supporter of the podcast I've been great lucky enough to also have many awesome people from it similar to you on the show as well. And for the audience, I'd like to mention please feel free to join it. Even though I personally felt at first that it's a Russian only community, Google Translate does the job pretty well. And when I talk about chai or English if I speak in English people usually are kind enough to switch to English for my, so please do join it. "
57:03,Sergey,Yes.
57:05,Sanyam Bhutani,"Now, do you think if a Kaggler who's listening to this podcast uses catalyst can can it be the secret element to a huge boost in the score? Do you think that can be a secret recipe?"
57:22,Sergey,I think;
57:30,Sanyam Bhutani,"Maybe you don't want to say yes, so that you can win a competition."
57:36,Sergey,"Now, thanks to our division, or computer vision base began with catalyst it was already integrated with a bunch of these communication and segmentation models. This so commonly used on Kaggle competitions and really if you check Kaggle competition you can see the people using Catalyst and it's really nice to see that it's quite easy to get the results. So big size and they go for the more Kagglers, we will use like at least, they've been breakable founders aboard. Nevertheless, I'm also in the hope that more engineers, small software engineers, and developers and developers use catalyst, because I think with this computer science background,they will easily understand what is going on in the catalyst and machine learning part. And we'll get this ability to run a large variety of deep learning experiencing Tennessee. It's certainly interesting. I think they will probably. So, yeah, nowadays we are trying to develop for the catalyst for all their endeavors, I think really interested one is, as I mentioned, is software engineering. Then it's, of course, it's about the Kagglers that really need this during the process, making the right fast and furious and just around a lot of experience. Of course, we're trying to apply all our expertise and use the catalyst for education purpose. Now, all of us I think it's a little hard because when you're trying to understand how does it work always deplaning stuff. And you might be really neat on the Pytorch pure PyTorch to write the code by your friends and to understand what is going on. And then after some experience, you really need these keys because you're bored with this portals. But the first and also Romance-Pytorch is great. Yeah. So nowadays, I think it's more about the, you know, the startups companies, with developers and Kagglers is a focus."
1:00:39,Sanyam Bhutani,"Okay. Now, to to, to a beginner, all of these beautiful algorithms and the library might sound intimidating. I want to point out that it's fairly straightforward to install. You don't need to figure out how to compile it from source or anything. What efforts do you think or what knowledge should one have before checking out the framework? Do you think a beginner can get started with the examples that are already present, or should they maybe do some courses before taking a look?"
1:01:10,Sergey,"Okay, from my personal view, you're in to take several courses, optimization and statistics, and mathematics. Also in linear algebra, john decided to have deep learning, and maybe not their deep understanding, but some kind of intuition. Simple listen, and then you can try to write your own Pytorch code. I think that you need to really try it, it's by your hands, because it's quite simple. Then after that, maybe after two months, you can try to use some parallel API's. You can use, you can try it at least you can try another framework. Nevertheless, I think catalyst is really straightforward to understand. Especially, okay. I'm also the person who allows to check the source code of the frameworks and understand what is going on. And if you will just check the source code, the catalyst or catalyst core, you can see that it's really simple. There is nothing special, it's really straightforward to understand that we just, you know, have this obstructions on top of four loops, that's all. So we control the catalyst and we already have this good tutorials for publication. segmentation. This is really from the beginning from the Epoch control data. And that's great the data set with my increase Pytorch data loaders, then okay, we need some augmentation. So let's begin by with augmentations, etc, etc. Okay, now we have this task to do. So we have some data we understand the problem we would like to solve, okay, we'll use this supervisor honor, make this train the model of not we also have several advanced tutorials. like okay, we can trace it to my production early. We can encourage you to check some statistics. We can execute some, write some extension to get some statistics that's a third center and also for each of our tutorial we have some advanced part about, for example, using one cycle techniques using this. For example, focus station needs its or best practice to smooth some napoca loss, etc, etc. all this stuff, what is the best practices? So, yeah. And so, catalyst tutorials, I think really great source of expert knowledge about how to make deployment, right? And I'm not sure we're writing all the no introduction, why it's so important, etc, etc. But you can check it it's really easy to the US and it's a lot of things already implemented so you can reuse it in all the projects. And that's why also, all our tutorials have same structure, for example, to prove that every deployment model is no general, and all the things can generalize. And to check that you can reuse the DS in all those fields like discussion, segmentation detection. Surely we can. I think we will get some generative adversarial networks tutorial and some kind of an obese discussion tutorials. And we can also show that the same ideas and what I do there there. "
1:05:50,Sanyam Bhutani,Okay. personally and on from the community. I'd like to thank you and the developers from the framework. Can you tell us how can we who are not active contributors support the framework as outsiders? 
1:06:05,Sergey,"Oh, I don't think anyone is. Yeah, I know. It's a little bit complicated, because we have some issues. We have a bunch of features for it, but come on. It's true. Just because we also have a bunch of pull requests and the time you need to check the pull request to understand the structure, and how to make it protein and all the design of the framework. It's your time. It's complicated. But, for example, we have an open source mode of the development difficult come down We write what we need to do. Also, if you would like to contribute to the libraries, you can open an issue. You can write your proposal. For example, for example, for example, for example, currently we have an interesting issue about how does it pronounced correctly and I must not notation. This technique was proposed in article on maybe two months ago. And thanks to our Avinash-he implement this mass normalization model and make a purpose with with it in our country. So that's all you need. Really. You just propose your ideas. You can bring someone from Little steam. And we're really excited then when someone tries to know, contribute to the library because it's beautiful when someone understand your ideas, to try to improve them. It's excited moment when they understand them. You see another contributor, like, it's always like, wow. pleasure for me to see that. Other people are trying to, you know, not to also contribute to what you're doing so many times your life because it's some kind of another type of support. Really important one. "
1:09:04,Sanyam Bhutani,Okay. So what single best advice would you have for someone who's just starting machine learning and secondly for a beginner who's getting intimidated of contributing to open source?
1:09:18,Sergey,"So okay, if you're only starting the deep learning and contributing, I think may be the best advice I can give it's just just do it. There is nothing special or you can need just to understand what you would like to do. What problem would you like to solve then you know understand what what's the goal for what you would like to do, and then step by step slowly, slowly, you're granted and you really rigid. Now just the max don't make these tiny steps of the progress, whatever they are now and that's all you need to do really think just every day. Try to make you better than you will."
1:10:37,Sanyam Bhutani,Gradient step into the right direction every day.
1:10:40,Sergey,"Yeah, just try to improve your day. Made some tiny, maybe tiny but contribution, what you are and what you like to do, and what you would love to know to be good at."
1:11:02,Sanyam Bhutani,"So what would be the best platforms to follow you and follow your work? Any platforms? Twitter, otherwise?"
1:11:11,Sergey,"Oh, yeah. So nowadays we have a Twitter account for catalyst team. Catalyst Core, also Okay, there were not we all also told this Catalust info atleast on our GitHub to share some, you know, on some blogs we can say so. Also we have telegram channel bancho, mostly it's about development progress like, Hey guys, we hope for a new release etc. by good ecosystem especially we're proud that we have our personal channel in open that the science community to get list. It's more than I founded I think already people there it's really cool to see such interest for our work. Those are the now maybe Peter telegram, you can have to follow us. It would be nice to see."
1:12:45,Sanyam Bhutani,"You can find all of the links in the description of the podcast if you want to check out any or all of these platforms. My final question to you would be, you have been active in the RA world are you a gamer yourself?"
1:12:58,Sergey,What what?
1:12:59,Sanyam Bhutani,Are you a gamer yourself since you have been involved in RA world?
1:13:05,Sergey,"Oh no, I don't have a see nowadays like a Sony PlayStation, but thanks to a bunch of works, projects, courses and competitions and other stuff. Don't have free time. Really because I have this opportunity. I okay, I have an opportunity but don't take the time to to use it."
1:13:40,Sanyam Bhutani,"I always ask this tricky question at the last what, what is your favorite game of all time and you have to pick one or maybe two."
1:13:51,Sergey,"Favorite damn, of course it's goty 2 metal dragon."
1:13:55,Sanyam Bhutani,"Okay, so thank you so much for all of your contributions to the open source community and also to open data science. And thank you so much for joining me on the podcast."
1:14:07,Sergey,Thank you very much. It's my honor to be here. Nice to meet you.
1:14:18,Sanyam Bhutani,"Thank you so much for listening to this episode. If you enjoyed the show, please be sure to give it a review, or feel free to shoot me a message. You can find all of the social media links in the description. If you like the show, please subscribe and tune in each week to ""Chai Time Data Science""."
