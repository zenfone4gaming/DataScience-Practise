Time,Speaker,Text
0:13,Sanyam Bhutani,"Hey, this is Sanyam Bhutani and you're listening to ""Chai Time Data Science"", a podcast for data science enthusiast where I interview practitioners, researchers, and Kagglers about their journey, experience, and talk all things about data science.

Sanyam Bhutani  0:46  
Hi, everyone. Welcome to another episode of the ""Chai Time Data Science"" show. In this episode, I interview Shivam Bansal, who is one of the top kernel Grand Masters on Kaggle currently ranked fourth in the kernel rankings. Shivam is currently working as a research scientist at NUS and he has been working in the data science field for the past few years. We talk about his journey into data science, his Kaggle experience and about his recent competitions solution to the competition that he's recently won. We also talk about his pipeline for writing the amazing kernels, and blogposts that I'm definitely a fan of. Without further ado, enjoy the show.

Sanyam Bhutani  1:44  
Hello, Grand Master, thank you so much for taking the time to do, to do this. It's really an honor for me to have you on the interview series."
1:51,Shivam Bansal,"Yeah, thank you so much Sanyam for inviting me. It's all also an honor for me to be part of this excellent ML series interview."
2:00,Sanyam Bhutani,"Thanks. Thanks for the kind words. Today you ranked as one of the top kernel Grand Masters, you're also a research scientist at NUS. And you had been working in the data science field for quite a while."
2:11,Sanyam Bhutani,"So, could you tell us what got you interested in data science at first?"
2:17,Shivam Bansal,"Yeah, so I did my undergraduate studies from computer science and engineering background, back in 2010 to 2014. So during the last few semesters of my course, I got acquainted with courses like natural language processing, computer vision, image processing, etc. That time I was not very much interested into these courses, but just out of curiosity, just to do something different from what other people have been doing I took these courses and later I got very deep interest in natural language processing specifically. And coincidentally, like my first job, my first company was also looking for people who had computer science background along with interest in natural language processing. So that I would say was that started my data science journey."
3:05,Sanyam Bhutani,"Got it. And I think this is like before you in TensorFlow was public, before there was this boom, so to speak. "
3:11,Shivam Bansal,"Absolutely, absolutely. That was the time when things like regular expression TFID of these techniques were very popular. These are the main go to techniques for any problem."
3:22,Sanyam Bhutani,"The state of the art, so to speak."
3:24,Shivam Bansal,Yes. 
3:26,Sanyam Bhutani,"Got it. And contrary to what people do, like they sign up for Kaggle after they want to get it. So data science, you had been working as a data scientist, and you signed up for Kaggle later on, so could you tell us what made you sign up for Kaggle?"
3:39,Shivam Bansal,"Yeah, so, so I was aware about Kaggle when I started data science, like back in 2014. So in fact, I was working on sentiment analysis problem. And at that time, one of the competition on sentiment analysis was also running on Kaggle. So just to get references just to get more ideas. I got aware of Kaggle but at that point of time, I did not join Kaggle, well the reason for that was I felt maybe I am not very much into competitions on machine learning, was not my core skill set at that point of time I was only into NLP. So I just took a hold that time. But after a couple of years, I would say in 2018 then I had this hobby of writing blogs, articles, etc, on different platforms. So whatever I used to learn whatever I used to whatever I learned new, I used to document it in the form of a blog or article."
4:36,Sanyam Bhutani,I am a total fan of your blog posts also by the way.
4:39,Shivam Bansal,"Haha, thank you so much. So, so I just just for fun just for side projects, I thought why don't I try something new, something, a different platform to share those knowledge which I have, so I started Kaggle kernels and I shared my first kernel in a competition which was donors choose competition and fortunately this kernel was also selected as winner of one of the kernel awards. So I realized that Kaggle kernels is not just a very good way to, to do apply data science, practical data science, but also they are a good way to, like write blogs in a different form in which you can get a direct feedback from the community. You can also get inspiration and motivated by seeing other people work and when people appreciate you in the form of say up voting, liking, commenting, so that that's kind of a great feedback that you get. So that's how I started Kaggle lately as such."
5:35,Sanyam Bhutani,"Got it, and I think you absolutely smashed it. You became a Grand Master, I think in less than under a year, in about 9-10 months."
5:44,Shivam Bansal,Correct. Yeah. So nine months to be exact. 
5:47,Sanyam Bhutani,Wow!
5:47,Shivam Bansal,Yeah. 
5:48,Sanyam Bhutani,"So can you tell us more about your Kaggle journey like what got you addicted to Kaggle when you finally like, caught the Kaggle bug."
5:56,Shivam Bansal,"Right. So as I mentioned, I always had this habit to do something to involve myself in something. Before Kaggle I was doing maybe similar stuff but in the form of say blogs, articles on or on some other mediums, like I used to write a lot of research paper as well. When I got to know Kaggle I just shifted all the focus on Kaggle and started sharing whatever knowledge I gained in past four or five years in the form of Kaggle kernels. Luckily, all of my work was appreciated a lot by community even even by Kaggle. I also want a couple of Kaggle kernel award, swag prizes, etc. So."
6:34,Sanyam Bhutani,I think in the first year itself.
6:36,Shivam Bansal,"Yes so that added on top of like motivation or motivating factor of keep writing kernels keep sharing what you what you know, as such."
6:46,Sanyam Bhutani,And do you think your previous experience or industrial experience was helpful as well? For the kernels.
6:52,Shivam Bansal,"Definitely, I believe whatever I learned, whatever I knew, the things which work, the things which are liked by business people, or how to approach unstructured problems. Those are some of the skill sets I gained during my work experience. And those are some of the things which I applied in my Kaggle kernels as well. So that experience definitely helped."
7:13,Sanyam Bhutani,"Got it. You're also currently working as a research scientist at NUS. So, could you tell us what problems are you looking at work? And is like Kaggle related to these problems, where does Kaggle come in the picture for you."
7:24,Shivam Bansal,"Yeah, so, I am working mainly in the areas of banking, finance and FinTech. As a research scientist, my goal is to try different ideas, try different experiments, from research, from analytics data science and try to solve the traditional banking methodologies."
7:43,Sanyam Bhutani,"The machine learning space, right? Just"
7:47,Shivam Bansal,"Yes, yes, I would say it's a mix of both research as well as applied, I have to come up with new ideas, new research ideas, and then also make sure to implement them to apply them on real data sets as such."
7:59,Sanyam Bhutani,Got it.
7:59,Shivam Bansal,"So for instance, I am looking for some of the alternative data sets and a fusion of concepts like network science and analytics to solve credit scoring in developing countries. So these are the conventional problems, traditional banking problems, but nowadays with more data, more techniques on how we can mix them together in order to improve what banks have already been doing. So these are some of the top level problems, I would say I'm working on. Talking about Kaggle, I would say Kaggle is not directly related to these experiences, to these projects, but whatever I'm learning from these projects is definitely something new, which I somehow apply in my kernels indirectly or directly. "
8:42,Sanyam Bhutani,"Okay, so both sort of reinforce each other in in a sense. "
8:46,Shivam Bansal,Absolutely. Yeah. 
8:47,Sanyam Bhutani,"Got it. And also, like, I think this is also a full time role for you. So how do you find the time to Kaggle because Kaggle in itself is also a full time role."
8:56,Shivam Bansal,"Correct yeah. Yeah so I treat Kaggle as my self learning time. So whenever I want to, let's say learn applied skills, I have learned a new research paper, some, some new concept from a research paper, but I want to apply it, I then go to Kaggle and write a kernel about it. So I treat it as something, a time in which I can learn something. Let's say, spending a dedicated two hours time every day is something which I make sure that I do, because that's how I not only give time to Kaggle, but I also learn something out of it."
9:32,Sanyam Bhutani,"Got it. I also want to ask you like, what are your go to steps when starting on a kernel? And how do you approach a new problem? I assume like as a data scientist, we have to ask ourselves questions also before looking into data. So what questions do you ask when looking at a new problem or a kernel or data?"
9:50,Shivam Bansal,"Yeah, so I believe this is a very good question, especially for beginners. How to approach an unseen or a completely new problem? So I believe that most of the data science problems, end to end data science problems are highly unstructured in nature, they just have one business metric, they have a business use case. And as a data scientist, the rule is to convert that unstructured problem into a structured one, and then take baby steps, then take step by step approach to write the proper solution for that. So I always make sure that I always think into it, I make sure that why I, why my solution will affect, say business person or business use case. And I make sure to break down a problem into smaller steps, smaller components, and then dedicatedly focus on each and every component. And then I creatively improving upon those tasks and those milestones, in terms of accuracy, in terms of improvements in terms of interpretations, explanations, etc."
10:49,Sanyam Bhutani,That's good advice. I think looking at the bigger picture while also like breaking the thing down into smaller goals.
10:55,Shivam Bansal,"So definitely, definitely good. Yeah. So for instance, machine learning problems are considered as straightforward problems, you have ML problem, you have to write feature engineering, pre processing, ML modeling etc. But when you think in the business direction as well, even the data scientists can improve on those areas as well. Maybe you can come up with very cool feature new features, which can definitely improve your machine learning scores. So I believe a mix of both technical thinking analytics as well as business thinking is something which, which one should keep in mind while starting any problem. "
11:32,Sanyam Bhutani,"Got it, and I think your rich experience will definitely count here. So how do you suggest that a beginner ask the right business questions who, also how do we cultivate that business thoughts like we, going by you?"
11:45,Shivam Bansal,"Like so I believe the most important and the most easy way to do that is to get yourself familiarized with the problem statement with the industry, with the, with the business use case. Let's say if it is a finance related problem. I don't think it takes more than, say one or two hours just to read about basics of finance and basics about the specific problem statement. Let's say someone wants to solve fraud detection in insurance, it is always good to read about why insurance is important and why fraud detection is really important in insurance. But just getting those initial business ideas can spark something new, can spark some new ideas and creativity. And then data scientists can jump into the exact problem formulation and then coming up with a solution. So I will definitely recommend to just do not directly start your data science problem. Always read more about the problem statement, specifically the business context and ask questions like who will be impacted? How much they will be impacted? And if a data science problem, if a human can solve with this problem, how much improvement can a data science model do in the similar problem? So asking these questions can give the right ideas to at least set up a groundwork for all that machine learning pipeline."
12:59,Sanyam Bhutani,"I think this is not just government to banking, all other sectors are coming from my mind. "
13:05,Shivam Bansal,Absolutely. 
13:06,Sanyam Bhutani,"So I'm also a huge fan of your EDA kernels. And could you tell why EDA is so important? First of all, Kaggle and for yourself also. And I see like you seem to work on multiple problems in your experience. Do you think this has also a help you ask the right, again, the right questions about different data sets?"
13:25,Shivam Bansal,"Absolutely. Yes, I would say EDA is as equal, equally important to getting the right business ideas before starting the problem, because in the first phase, we are getting to know more about the business problem. And the second phase, which is the EDA get us help to know more about the data that we have. The kind of tools or techniques that we can apply can be answered directly from getting the insights from the EDA. So doing a very comprehensive and a deeper EDA can set the groundwork for the next steps of any data science pipelines say, which features you want to curate, which models can work, which type of insights or interpretations can be given to business people, all of those initial direction can be obtained from a very comprehensive video. And also these days data science project, I would say the successful and complete data science projects are the ones which are not just good in say accuracies or evaluation metrics, but also the ones which serves the purpose which have a logical approach, and which, which gives the right answers to those right business questions. And for this part, EDA, is definitely one of the answer. Doing a right EDA right approach can give you those right business answers, I would say."
14:42,Sanyam Bhutani,"I think this is also a beginner sort of confused data science because they think of this as this model outfit and accuracy. Okay? Whereas like business people don't care about those 1 or 2%. They're more curious about why you're trying to solve it. Right. So I also want to talk about the second category of kernels that I think you write, which are the tutorial ones. So, I think those are also similar to your blog post. So why are these important to you? Like, what's your motivation for these?"
15:10,Shivam Bansal,"Yeah, so I treat them as some of my documentation for a new concept that I learned, or maybe something which I want to refer back in future. So as ways to make your notes and since we have Kaggle, so Kaggle kernels is a very good way to make your own notes in the form of Kaggle kernels, which not only will help us but also may help many other people. So I believe Kaggle kernel serves these dual purpose in which you are writing tutorial for yourself at the same time for the community as well."
15:42,Sanyam Bhutani,"Good, And like I'm also curious, like many people are not like for them, it's this competition. So why, why not keep the secret sauces to yourself all of these knowledge that you've learned and gained? So why, why share it with the community?"
15:57,Shivam Bansal,"So in my experience, I would say I have learned from other peoples work as well, or the so called secret sauces. So I don't believe in just keeping, share secret sauces to yourself. If I know something new, it's good to share with the community. Because in somehow in the future, it will also help you. Because let's say when you see people are using your approach, then it's also sets up a standard, it also raises the bar for yourself. So in the next competition, or maybe in the next panel, you have to improve on your previous approaches that somehow improves you as well."
16:32,Sanyam Bhutani,Got it. And I also want to share with the audience that you're a kernel Grand Master but you still compete in a very special category of competitions which are the data science for good competitions. So what's your motivation for competing in this special category?
16:48,Shivam Bansal,"Correct. So I really enjoy data science for competitive and good challenges. This is because these are very open ended competitions. The problem statement presented in these competitions are very different from conventional Kaggle competitions, in which the conventional competitions asked for ML friendly problem statement in which the goal is to come up with the best possible model with the best possible evaluation metric on the leaderboard. I like those competitions in data science for good challenges that they asked for a logical approach a structured approach and end to end approach of how you approach the entire problem. So it does not require only machine learning skills, but it requires a good understanding of how you what, what is your way of approaching? What is your structured thinking, how you come up with the right visualizations? Do you have storytelling skills? Can you do an analysis which can just quickly explains all the business metrics as well as the data metrics to the business person and at the same time, they also involves concepts like natural language processing, statistics, even machine learning, deep learning in some cases. So in an overview, I would say these competitions, demand for versatile data science skills. So these competitions provides an opportunity to practice the complete data science lifecycle. Just by giving one complete solution you can, you can come up with a solution to the problems which are more closer to real life data science problems. That's why I enjoy."
18:22,Sanyam Bhutani,"I think these also sort of solve the complaint that people have with Kaggle, which is like it's just a modeling platform. I think these competitions make up for that."
18:30,Shivam Bansal,"Definitely. Yeah, many calculators in the past have said that Kaggle competitions are not equal to real life data science competition, but since last year Kaggle has released these, I think six or seven data science for good challenges and all of them presented a very different business use case. And all of them were very close to real life problems that personally I have seen in the industry and many other people as well."
18:55,Sanyam Bhutani,"Okay. So I think, I think that's another advice for the beginners to, if you are not very happy with Kaggle, please go ahead and try those competitions out."
19:04,Shivam Bansal,Definitely.
19:06,Sanyam Bhutani,"Congratulations. Also on your third win in the data science for good competition. For a little section, I'd also like to talk about the recent when your approach to it. So could you tell us a bit about the recent competition? And what was the challenge here and why it caught your interest?"
19:22,Shivam Bansal,"Sure, sure. So thank you so much for that. So yeah, this, I believe, was my third data science for good challenge. So in this competition, the business problem was very unique. So this competition was sponsored by city of Los Angeles, and they were in a situation that in a matter of one year, about one third of their workforce of the employees, they were eligible to retire. So they were having a lot of open vacancies which they wanted to fill in the next couple of months. They wanted to come up with an effective recruitment strategy by the use of data, by the use of analytics and data science and by effective data, effective recruitment strategy, they meant that they do not want any unconscious bias or let's say less diversity, less qualified candidates etc, they wanted to make sure all the candidates which are applying or getting on board, they have diversity in say gender, in say Irish ethnicities, races, maybe age etc. So, they wanted to make sure to remove that human bias which is generally present in, in, in the recruitment strategies. Additionally, they wanted to make sure that the any employer, which is part of this organization, they are, they are easily aware about the promotional opportunities that they have in the organization, because this is a huge organization with more than 50,000 employees and more than 200 different job roles. So, if an employee is working in the company, so, let's say they have a decent experience, they satisfy all the criterias but are they are eligible for next promotional parts that was not something which was really clear. So, they wanted to use make use of the available data and come up with a framework in which those commercial parts can be given. And on top of that, they wanted a very robust, very intelligent and comprehensive natural language processing engine, which can convert their unstructured job descriptions data available in different PDF documents etc, into one structured form, so that they can make more informed decision more data driven decisions about the vacancies, about the job roles, about the salaries, etc. So, this so, this problem had these multiple themes which I just talked about. So, this, like fusion of like three or four different themes in just one competition made, made this competition very challenging in my opinion. For instance, this, this competition required a solution which is complete in all sense, not just good technic, technical solution, but also solution which explains all these teams, all these components very well. And city of Los Angeles can just directly use one single solution to solve all their purposes. So that's why I decided I should try this competition."
22:17,Sanyam Bhutani,"So in a sense from what I can understand is, this was really like a data scientist problem rather than just a competition problem which is common to most competitions."
22:26,Shivam Bansal,"Correct. So maybe machine learning component was relatively lesser in this part. But we were open to use any approach as a, as the submissions given by different categories. They were open to use any approach, be it only a machine learning approach, as you mentioned, data science is not just machine learning. It's a, it's a sequence of many tasks. "
22:47,Sanyam Bhutani,Yeah. 
22:47,Shivam Bansal,So that's what something which was required in this competition.
22:50,Sanyam Bhutani,"I think that's also where many people get confused is that you're not using AI to replace a human, you're using software, I think in this case to replace the hiring pipeline or;"
23:00,Shivam Bansal,"It's more about making your strategies more effective, more data driven. So companies have been running their businesses since decades. But mostly that is being through knowledge and their experiences. What data scientists do when they come into picture is they improve those experiences they improve those, those decisions by giving them the right insights, right predictions from the data sets, because that is something which I believe should, everyone should be aware of. And data science is not just replacing those 20-30 experienced people but assisting them with data science metrics."
23:37,Sanyam Bhutani,"That's good, it is, are you a fan of the human in the loop concept or the AI concept? So;"
23:44,Shivam Bansal,"So in my opinion, I believe that humans are definitely one important piece for any project, relying only on AI to say all, take all the decisions may not give us the best possible results, they may create some implicit bias. It's good, good to have humans in the loop? "
24:03,Sanyam Bhutani,"Got it, also you mentioned about all of this knowledge. So could you tell us more about what sort of research for you, or what sort of background study for you went into the competition while you were competing for this?"
24:15,Shivam Bansal,"Yeah, so I structured my entire solution in a series of five to six steps, in which the first step was doing all the comprehensive research, reading all about why companies struggle in getting not diverse candidates, you know, what is the meaning of effective recruitment strategy? What is diversity hiring, what are the kind of implicit bias so I added more than 10 research papers on these different ideas. I read more than 50 blog posts and articles which were available on the internet. So one whole week I spent into just getting the more business insights, getting the more ideas about what this competition is actually talking about. "
24:55,Sanyam Bhutani,"Got it. Also, like people tend to just jump into competition, submit to the leaderboard right away, which is not possible in this. So what do you think of like, how should it be played for understanding the problem versus getting a baseline ready, versus adding features? "
25:11,Shivam Bansal,"Right. So these competitions, as I mentioned, requires a very comprehensive solution. So it is always good to start with a very simple solution or a very, start with very basic solution, let's say, as I mentioned this competition at four to five different streams. So a good strategy is to pick one of the team and try to come up with a simple approach or a simple solution for that, let's say you want to measure if job bulletins has racial bias or gender bias. So just come up with one visualization and see if that visualization is explaining the racial bias or gender bias in them. And then over the time, over the next few days, I creatively add more visualizations. I creatively add more statistical analysis, more recommendations and improve on top of that. So I believe these competitions also follow somewhat similar pattern to traditional Kaggle competition where you start with a baseline, and then it will improve. And then in the end ensemble different techniques to come up with stacking type architectures. So similarly, in these competitions, we also have to do the same thing, but it's not just we have to do for machine learning, maybe for analysis, maybe for some other types of EDA, maybe for visualizations, etc."
26:28,Sanyam Bhutani,"I think that's also great advice that what many people think of is the biggest model that, they can just throw at the data instead, you also have to work on small models, didn't create a POC or MVP in terms of the business will then complicate it for them."
26:43,Shivam Bansal,"Yeah, and that that's, that is very similar to what I've seen in all my past industrial projects, any business problem, it always starts with the simple solutions, the customers or the clients, they are not looking for very high accurate models in the first place. They're looking for an end to piece which shows that data science solution can give them something. "
27:04,Sanyam Bhutani,"And they are actually aiming for that final big, huge, yeah, that can do whatever but they do start with the small."
27:13,Shivam Bansal,"Yes, because they want to convince them first that yes, data science can do something, because they always have the business problem, but when we show them to see, so then they are aware that yes, we are on the right track. Now let us spend our time and effort and money to make the solution more comprehensive and more accurate."
27:31,Sanyam Bhutani,"Got it. Also, thank you for sharing your wonderful solution viral blog. I'll have that link in our podcast description. Also, could you tell us a bit about your solution to the to the data science for good challenge."
27:46,Shivam Bansal,"Sure. So like I mentioned before, I structured my solution in six different steps. And that's how I always start my any solution like I always break the bigger problem into different companies. And then come up with different kernels or different strategies or different solutions for every sub task that I have broken. So as I mentioned, first step was just to gain all the business ideas. The next step what I did was I created a very strong natural language processing engine, which, which was used to convert all the unstructured data into structured format. So I started small, I started with simple regular expression, keyword based layout based approach. But over the weeks, I kept on adding more grammar based rule, part of speech tag rules, more natural language processing techniques, and over the week, the solution evolved and solution improved in itself, but the biggest takeaway, which I learned from that first part was that I focused on completing that NLP engine end to end. Like at the first go it was giving very bad results, but it had all the components. It was giving all the variables that were required to be extra. And that's what I focused in the next few weeks, in improving the accuracy. So that was like the first part. The other part was more about quantification of those unconscious bias present in those job bulletins or job descriptions, etc. So that's where I made all the business knowledge which I gained from the internet, that came into picture, I converted those business insights which I learned, into data science strategies into different types of EDAs, which can be done, differently statistical analysis, which can be done. So I kept on it, relatively trying and implemented those techniques on the real data sets, which were available. I got to know that about five out of 20 ideas worked, which is very true in in all the data science scenarios that whatever, you know, not everything can work. So that's where I picked all those ideas which worked for me, I then polished upon those ideas. One of the important piece was validation as well. We can not just start with our hypotheses and say this is coming from the data. And this is true. So in this case, since we did not had any unseen data or any external data on which we can see whether our approach is good or bad. So that's where I use the concept of simulation, I designed the experiments in which assimilated world or simulated population was defined. Every population had some application, some candidates with different attributes. And then I take that whether the insights coming from my analysis or insights, are they creating some impacts or some fluctuations in that simulated environment? And are they significant enough to say that this insight or this recommendation is relevant? So I incorporated this, yeah."
30:46,Sanyam Bhutani,This was really your validation strategy to create a simulation of it.
30:50,Shivam Bansal,"Yes, yes, because I made sure that simulation is very similar or it mimics the real world. What I tried that I used census data, I use CT demographics data and all the aggregated values to generate those simulations. So in essence, the simulated data was not fake data or dummy data, this was very close to the real data set, as they call it, that is also one of the takeaway, which I would like to highlight here that sometimes simulations can also be very helpful in validating your approaches. Well, the third part of this, my submission was deep analysis of textual data by the means of content analysis, language analysis, word choice, text complexity, etc. So that's, in that piece, in that kernel I focused a lot on NLP techniques. I, quantification of men of all the different sentiments or different insights present in the data, and also measuring how well the person has written the text, is the text actually serving the purpose? For instance, there is an important section in job description which is called duties. What are the duties to be performed? So, by the use of natural language processing, can we collectively measure, is the duties fulfilling the purpose? Is the duty section explaining what are the actual duties to be performed? So, by the analysis of what kind of words the person has used, what kind of town phrases are present, what kind of word choice they have used, are they actually serving the purpose. So, these are I would say all the business ideas, and you, by using techniques like NLP POS tagging and you with the use of Python, I converted them into implemented form and then using visualization I made sure that the right idea which I want to convey is actually conveyed. And, so, this was the third part and finally, in the last two parts I made use of, for the natural language processing technique. Like I used fast text model to generate word embeddings for every sentence and then identified if there are contextual similarities between. Then in the job requirements, and whether I use those contextual similarity as a way to link those promotional pathways, let's say if an employee is working on one position, but after serving a complete, decent amount of experience, they can be promoted to other senior most role. So those things I captured using text analysis, and then I use d3 dot JS to visualize those permission pathways as well. So this was my whole solution. I believe that, that is very comprehensive and very long, may not be expressed in this podcast, but definitely I think anyone wants to refer they can definitely, refer my blogs."
33:40,Sanyam Bhutani,"We have all of those links also for those who want. Yeah, thanks. Thanks for the comprehensive summary also. So my biggest takeaway from this is A) you don't have to have the business knowledge when approaching a new problem. So people, like someone might think of this as we need to teach a hiring person machine learning to to be able to solve this problem. "
34:00,Shivam Bansal,Right. 
34:01,Sanyam Bhutani,"And the second takeaway for me is spend a lot of time on understanding the data. And even then, continuously, like you said, you were validating your ideas constantly, while even adding every future you will constantly visualizing"
34:14,Shivam Bansal,Correct.
34:15,Sanyam Bhutani,"Got it. And the other thing I wanted to ask you, like you mentioned, one out of 25 ideas work, it's probably worse even for most, some of the problems. So how do we know when to stop approaching with with this angle or stop trying this idea that wasn't working or might not work?"
34:34,Shivam Bansal,"Right. So I think the walk around can be taught from the other way, like in the first go, what we can do is start or create a list of very comprehensive ideas, different, all possible ideas, what can be tried, then, like try those ideas one by one and just make sure to log everything just make sure to document everything. What actually worked in that idea, whether this feature came up to be important whether this feature had some different impact; maybe you tried a machine learning idea, say you assemble models together and see something worked or not. So also creating that documentation say in a simple Excel file can also help you to gain and get an overall idea about what things actually worked and if there is scope to expand mode, is there is scope to try some more ideas, more status, some general pattern, that in general, most of the ideas are not working. There are specific type of ideas which are working. So probably we are on a saturation level, we cannot apply more. So I believe that that, creating that Excel file or documenting your ideas, and it's really all the ideas,"
35:42,Sanyam Bhutani,Treating it as a science problem. So having this lab journal of sort.
35:47,Shivam Bansal,"Yes, yes.."
35:48,Sanyam Bhutani,"Got it. So I also like, there's this common misconception that you can't be good on Kaggle unless you have a mega ton of servers or at least early Junko graphic card. So what are your thoughts on that about the hardware setup required to be to get a good taste of Kaggle?"
36:07,Shivam Bansal,"I believe that's one of the very biggest misconception people have. Because even with very simple specification, and very simple hardware, people can actually create very good, insightful analysis and machine learning modeling stuff. So I don't think people should just think about hardware specification, whatever they have, whatever resources they have, they should just take the first step, start with small things. And nowadays we have free Kaggle kernels, which have very good GPUs and even Google collab. So which provides the services for free. So if the requirement demands very good hardware, we can jump to these use cases. But all the other use cases or a majority of the use cases, can actually be solved with minimal hardware requirements. "
36:55,Sanyam Bhutani,"Got it. Also, you've been very vocal about the sort of toxic practices that have been cultivating on Kaggle. So how does a beginner avoid falling into the traps of the one, who's not very experienced or doesn't know what's going on?"
37:11,Shivam Bansal,"Right. So I believe people should be aware about or should, should know about what Kaggle actually is. Kaggle is not a platform to say, make your social media profiles. Kaggle is a platform to make your work profile. Kaggle is a platform to practice skills, learn from other skills, which is the most important skill. When someone understands these points, what Kaggle is actually meant to be, then they should know that it is important to appreciate other people's work. It is important to respect other people's work and toxic practices like say plagiarism, or be it, abusive language or something; those things are not on, valid on Kaggle platform because somehow, they can create some maybe good kernels. But if they have a bad reputation in the Kaggle community, and Kaggle is a worldwide known social, so that somehow will reflect on that person as well. So I, my biggest advice is to treat Kaggle as a learning platform and don't just think, to use Kaggle in some other forms."
38:12,Sanyam Bhutani,"I think also, as like people call it to be a second time job, really treated as a job environment."
38:18,Shivam Bansal,Absolutely. People spend like hours and days and weeks on day. So it's not just about you can start toxic practices and maybe disrespecting other people's work. You can learn if you appreciate other people's work.
38:33,Sanyam Bhutani,"Got it. So this also brings me to a question that even I sort of continuously ask myself is that, for example, I look at your guns, I get to learn a lot. But what if I want to build on top of it? So there is this fine green line that approaches if like, I might be plagiarizing your work if I'm trying to build on top of it or build something similar to it. So how does one take care of that?"
38:54,Shivam Bansal,"Yeah, I think whenever, there are always these cases, I think what people should try is to take inspiration and take ideas from other people's work and not try to just exactly replicate and reduce it as their own kernel, they can replicate for learning purposes. But take inspiration about, see I use some fancy visualization, I did some cool Ed there, you can try to replicate the same thing, but maybe on a different data set. Or other way can be you come up with an improvement, you come up with an enhancement, what people can do is that they can keep the entire kernel as it is, but in the end, they can share that these are the 10 new advancements on top of say Shivam's kernel. Appreciating and writing, giving credit to the original author are definitely some of the good ways to keep continuing in that work, and as well as the Kaggle community."
39:47,Sanyam Bhutani,"I think one of the traps that beginners fall into is they're trying to chase a kernel because of the gamification But what they don't realize is Kaggle is this beautiful community of people sharing their resources, so you might get away with a medao or two, but when you get back to the community for their help, they might not be as respectful of your approach."
40:06,Shivam Bansal,"Yeah, and not just community, but also in their real life jobs because somehow people know each other. And somehow, all these practices can be like, everyone can be aware about who did what, you know, it can reflect on your work as well."
40:21,Sanyam Bhutani,"I think again, it's like if you treat it as a job, and you're essentially stealing your co employee's work, that would have an effect down the line. "
40:29,Shivam Bansal,For sure. 
40:30,Sanyam Bhutani,"Yes. Got it. So setting aside these toxic practices assumingly, like one takes care of this. Do you think a non traditional, quote unquote, background person can like get into, get to break into data science fields, just on their Kaggle experience, based on that."
40:45,Shivam Bansal,"I believe yes, because first of all, Kaggle is a kind of a platform which can guide the person into right direction in terms of what all skills are required, what are techniques to learn. And secondly, Kaggle is a very well known platform all across the world, all across the data science community. So if a person is having a good Kaggle profile, so it can help the person in getting the data science jobs as well."
41:09,Sanyam Bhutani,"Got it. And what are your best tips for beginners who are just getting started and aiming to become Grand Masters, hopefully one day."
41:18,Shivam Bansal,"Right. So my one of the biggest tip is around learning. So whenever a new person wants to learn something, they sometimes refer to online courses, or maybe follow some blog articles, etc. And one of the pitfalls I have seen in many junior or aspiring data scientists is that they tend to get deviated from what they started. Maybe they find that this course that they started is becoming more complex, they are not able to understand this thing. Or maybe they got feedback from their fellow employee or their friend who said, don't take this course, wdon't you take other course. So my biggest advice is to stick to whatever you have started, stick, try to complete even if you feel that maybe you are not learning that much, maybe you're not getting that much but at least try to complete all those things that you have, at least started as such. The second advice that I will have is around end to end thinking, don't just treat data science as statistical approaches, machine learning approaches, modeling etc. Because all those things as you also mentioned that, that, that can be done in four lines of Python code. Data science is much more than that you think about why business need, why data science solution needs to be created and who will be impacted what are the roles and responsibilities of person that you are going to affect with your data science approach. And the third advice that I want to give is the structured thinking, most of the data science or analytics problems are open ended. They are, they are unstructured in nature. So if you have this mindset in which you can come up with a structure in the problem, you can come up with a ways to tackle down a problem in a step by step manner. You can approach the problem very well, you can implement that as well."
43:04,Sanyam Bhutani,"Got it. So what like I might do is like as, as a software engineer, we try to think of how cool, in what cool manner can we solve this, in this four lines of code. But it's really about looking at things in a business fashion. "
43:18,Shivam Bansal,Definitely!
43:19,Sanyam Bhutani,"Got it. And before we conclude, so any best tips for people who feel intimidated by the field, because like;"
43:29,Shivam Bansal,"Yeah, because people just should take the first step. It's all about taking the first step, just like, just maybe participate in very popular Titanic competition and get a taste of what can be done. What are the things out there and then make a plan, make a plan about how you want to learn, say machine learning or natural language processing? What do you want to do? Do you want to take a course? Do you want to write a kernel? Do you want to participate in a competition? Write a plan because we know that people are not good in following the plans, but at least when you write a plan you, you get a sense of the steps which are required. So just taking the first step, making a plan and just get your hands dirty with all the problems is the first step, which everyone should do. "
44:15,Sanyam Bhutani,"Awesome. Also, if you could tell us, how could we best follow your work? Kaggle is there of course, where else are you active? What platform?"
44:22,Shivam Bansal,"Yes, I am very active on LinkedIn, and Twitter as well. So maybe we can link."
44:29,Sanyam Bhutani,"We'll have all of those links in our cards, and the description. And what's next for you now that you're already a kernel Grand Master and you're also about to complete your masters?"
44:39,Shivam Bansal,"Yeah, so definitely from Kaggle I will try to improve my profile in terms of competitions, like I have not very focused fully or dedicatedly participated in any competition. Maybe I'll try to do that. In terms of my work experience, in terms of my next opportunities, I will be working full time in, let's see, I have a couple of options that I want to pursue in. So I'll be deciding on that. And at the same time, I want to keep a sense of research in me. I want to, parallaly I want to do different research ideas and see if maybe something new can come up."
45:20,Sanyam Bhutani,Got it. Alright thanks so much for all the great advices and for all the things you been doing for the community and all the amazing kernels.
45:28,Shivam Bansal,"Thank you so much. Thank you so much for inviting me as well. And it was also a great experience to talk about all my experiences that I gained, so hopefully the community may be benefited."
45:40,Sanyam Bhutani,Thanks a lot.
45:52,Sanyam Bhutani,"Thank you so much for listening to this episode. If you enjoyed the show, please be sure to give it a review or feel free to shoot me a message. You can find all of the social media links in the description. If you like the show, please subscribe and tune in each week to ""Chai Time Data Science""."
