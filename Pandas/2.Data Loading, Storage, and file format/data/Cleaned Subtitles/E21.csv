Time,Speaker,Text
0:13,Sanyam Bhutani,"Hey, this is Sanyam Bhutani and you're listening to ""Chai Time Data Science"", a podcast for data science enthusiasts, where I interview practitioners, researchers, and Kagglers about their journey, experience, and talk all things about data science.

Sanyam Bhutani  0:46  
Hello, and welcome to another episode of the ""Chai Time Data Science"" show. In this episode, I interview Bart who has a computer science undergrad at the University of Waterloo. Bart has just finished his software engineering internship at Google. And in this interview, talk all about his internship where he worked on swift for TensorFlow and contributed to the project. We talk all about his experience interning at Google, swift for TensorFlow, and open speed. This is a part of the swift for TensorFlow really series, with the next episode being a interview with Dr. Marc Lanctot to a research scientist at DeepMind where we, of course, talk even more about safer TensorFlow research at DeepMind and of course, AlphaGo so do subscribe, or stay tuned if you'd like to check that episode out. For now, here's my interview with Bart. Please enjoy the show.

Sanyam Bhutani  1:54  
Hello Bart thank you so much for joining me on the podcast series."
1:58,Bart,"No worries, pleasure being here."
2:00,Sanyam Bhutani,"Pleasure to have you on the show. So you just finished your internship at Google, which was all about swift for TensorFlow, which we'll just talk about. You've also worked as a data science intern at a healthcare startup. You mentioned this, you know, offline conversations. Can you tell us how did you get started with machine learning or data science broadly speaking?"
2:19,Bart,"Sure. I can even go a bit further back where, when so when I enter university, I think I'll discuss a little bit later. But with our diversity, we got the opportunity to do a lot of internships. And my goal with all my internships where I wanted to try something new, every, every term. First, I tried full stack. And then I tried iOS as my second ship. And then I really kind of saw my friends and others kind of get into data science. And I kind of saw the buzz behind the unassigned and I was just thinking to myself, like, let me try this for a semester. Let's just see how it is. And because I did my iOS internship at the health startup, I went back to them and be like, Is there an opportunity for me to try Data Science. And they said, yeah, and that's really how it comes to data science was just kind of the already existing connection I had with previous employer. And just try it out myself and see how it is. I did previously also do some like little side projects and like Udacity courses on myself. Those were my first kind of professional experience. "
3:19,Sanyam Bhutani,"Okay. Got it. So before we talk about swift for TensorFlow, could you tell us what so you have an interesting set of at university and program? Could you tell us, the listeners more about it, and what internships requirements do you have? Because you mentioned this and it's pretty interesting to me at least."
3:36,Bart,"Sure. Yeah. So I go to the University of Waterloo in Canada, and with the University of Waterloo, I'm under I'm in the computer science co op program. And our device has a really intense co op program co op being just like internships [Okay} where we do six, four month internships and our undergrads additionally on our;"
3:59,Bart,"Ours is a five year undergrad because of the six internships. [Okay] So total like we did two years of internships and how it works is after the first year it's like you do four months of school and four months of co op four months of school four months of co op school co op school club all the way till you graduate. We have no summers off. [Okay] Sometimes it's sucks because like, Friday, I fly out on a Saturday. I stay home on Sunday and get moving back to school on Monday, or Tuesday. So that's like no, no breaks. "
3:56,Sanyam Bhutani,Interesting. But I'm sure the bills totally worth it at least maybe after you graduate.
4:33,Bart,"Yeah, definitely."
4:34,Sanyam Bhutani,TDo help us set a set the stage for swift for TensorFlow could you tell us how did you end up applying to Google and why did you end up choosing the sweet food TensorFlow project that you worked on.
4:44,Bart,"Sure so those are familiar with the Google intern hiring process. You apply to Google like as a general intern, you don't interview with a team you interview for like Google [okay] and it consists of like two interview two interviews like over the phone like 45 minutes each, which are just the basic data structures, algorithms. And then you get to know whether you pass that stage. And I passed that stage in July 2018. And I had to get an internship for the fall just because of the club, my car program had to get on a trip the fall. And I did not have enough time to find a team. As after you get accepted to Google and used to go through host matching, people's matching can take a while and I didn't have enough time to do it for the fall. So then my recruiter was like, let's just move this to the next term, so you can find an internship for the summer. So while I was doing my data science and their ship in San Francisco, I was going to post matching process and the first person to reach out to me was my host, Richard from Super TensorFlow and in total had to it to introduce the second one I wasn't too interested. It was like objective C iOS [I see] and and I didn't really want to go into back to iOS because I did that before. I will try some new what Richard was looking for was someone who had iOS experience who knew swift. And he was also interested in data science. And through my resume, he saw that I had both. And we talked and one of the big things I got, I think was convincing points was that I wasn't really during my data science and worship, I literally gained a huge I don't completely enjoy pure data science, like with the models, data pipelining all the sequel, you know, I really liked and was trying to look for position which has more like the software engineering, like creating frameworks, things of that nature. And I kind of told him, I was like, I don't like today's science, but I still have to be involved in this field. And that was kind of a perfect match for the project because that's what that's exactly what we're doing. We're kind of creating these tools for machine learning. Researchers instead, and that's already kind of found a match for that [Got it] like I've got the;"
6:54,Sanyam Bhutani,"To linger on to that point for a little longer. Could you tell us how did you prepare for the because I know the interviews are difficult, and the question might be under NDA. So generally speaking, how did you prepare for especially the data science and algo questions?"
7:10,Bart,"So with the like the data structure and algorithm so with the way dependence, but for when I was interviewing for the like, host faction, like kind of the team was not technical at all, it was just like me and potential hosts talking about like, oh, this the projects are interested in this do you know this would you;"
7:31,Sanyam Bhutani,More of a conversation rather than; 
7:32,Bart,"Yeah. However, the previous interviews, the one which is like that initial screening with the two interviews, that's pure data structures and algorithms. And what I've always practice was, a lot of my friends use like the typical cheat codes and practice neat codes. What I do is, I have this book called elements of programming interviews, specifically the Python version. And I like how it's basically it's sets of all these units like first it goes into string, manipulate questions and the res binary search, search recursion dynamic programming. And I generally go through the questions and read the solutions and understand the solutions as it very well sets up the solutions and the way that you actually want to answer in an interview like for example, it goes into the naive approach the brute force approach, discussing how would work why isn't efficient and then it kind of goes further like okay, how can we improve on this and create the better final solution which is the best and that's exactly what interviewers interviewers look for in an interview not so much they got the right answer, but can you explain how you got there? And it really kind of sets up well the solution so explain how she got there."
8:43,Sanyam Bhutani,"So I don't remember all of these topics. Do you think this also good beginner recommendation incase they are new to these terms, the book? "
8:51,Bart,"Uh, I think it's I actually went through that book even before I took some of the courses that even taught me at University ends. [Okay] It definitely doesn't. Like it's definitely not like heavy and like the theory, but it nicely kind of shows you like, how to implement it. And even the codes are really easy to learn. Like if nothing less than a programming through the book, you might be able to kind of really learn it. But also, it's you can pretty much search up on like geeks for geeks, which also has a bunch of explanations of what dynamic programming is and things like that. It's very good. beginner book, I got a mic night thing, my first car as well."
9:29,Sanyam Bhutani,"Okay, I'll make sure to have it linked in the description in case anyone wants to check it out. Now, coming back to your internship, before we talk about what you worked on, could you help me set the stage by telling us what swift for TensorFlow is all about? And what promise does it hold in your opinion?"
9:45,Bart,"Sure. So I like to think of like so as far as like, I think what the key manager of Brighton always comes that says we want to create an infinitely hackable platform. [Yeah] In a sense of the weight, the current data science Machine Learning ecosystem is is you have this very like thin Python layer, and then just a bunch of c++ code underneath. And c++ can be very complicated to write. And even through my internships, talk to people who write c++ code at Google, they're hard to find a person who really enjoys ranks. And and what's swift trying to come and do is you're going to break the top layer and swift and every layer underneath and swift. It's entirely in swift. So if you, for example, wanted to write your own layer, or you wanted to look at implementation, you just simply like command click and go to definition. And that automatically puts you the definition of where this where the competition layer is defined. And you can exactly look through it. And you don't need to learn a new language and understand any more context because it's hard to jump to the Python code and c++ because they need to get familiar with the c++ code but with swift, all in one hands. [Yeah] And additionally surpass the benefits of being just as fast c++, it's statically typed on like Python. So it's all typed checks are not gonna have like some error three hours in saying your pass the string, and they're trying to add a string, and then it's your three hours of training or something like that. [Yeah] Additionally, one of the goals that I think I was working on was also was making the first differentiable programming language. So being able to just take derivatives of any arbitrary function."
11:24,Sanyam Bhutani,"Got it. But one of the things that I sort of am concerned about is c++. It's maybe okay for researchers, but really, for the practitioners who don't have a programming background, they're comfortable with Python right now, do you think swift would be easy for them to pick up or that might be sort of a challenge for them?"
11:44,Bart,"So I think the what I think the biggest that people are most excited about, I think, the super technical project, I think it's like two groups, iOS developers, and some of the people who are implementing like the c++ code. The people are the reason why is first for iOS developers, the way you write models or iOS apps isn't very smooth in that you start to write your Python models, train your Python models, export it, and then basically just dump it into the, your iOS application. And with TensorFlow, you can write the entire model in Swift, put it on your iOS app, and you can do on device training and all that. Similarly, c++ developers are excited because it's no more c++. The Python, I think, is gonna be some trouble mainly because it's, it's not as like, he's not as easy to read mainly because it's statically typed. However, it's ignored like this, how it the fact that he has types it can be just as easy as writing Python codes. Additionally, because swift is known as primarily a iOS, Mac OS, programming language, and even though still general purpose and it works on Windows, even works on Android. I didn't know that it's it's yeah, work than enjoy as well. There's someone opens up computer, we're supporting that. The problem is that there's not a big, I guess, data science community behind it. And as such, some of the libraries that exist in Python like NumPy, matplotlib, escolar, Pandas doesn't exist yet in swift. [Swift] And as such, it's hard for I think, right now, Python people to move over to swift just because they're the community is not there. However, over time, I think we can really build a community especially once we get this differentiable programming feature into the swift programming language."
13:40,Sanyam Bhutani,"Also, given the promise, do you envision that developing the Pandas and NumPy analog would be easy compared to the efforts that it took for Python? Once swift reaches that stage, of course."
13:55,Bart,"I'm not I'm not too sure. But like just the I think just the fact that like I'm not sure what Pandas final NumPy for sure is implemented all in like, see, it could be easier because again, like with swift, it could be just as fast as C or c++ code. It could be much faster to implement, of course, though, those libraries have been working on for many years. So it could take some time to increase. really bring it up to today. Yeah, I really think the c++ and swift developers will use it will take some time to really convince those Python programmers to move over."
14:31,Sanyam Bhutani,"Got it. Now coming to the part of development that you're involved, could you speak to that and virtual aspects of the project were you involved in while you were interning at Google?"
14:42,Bart,"Sure. So I was working on like one of like the sub teams where we were basically making swift a special programming language so adding automatic differentiation into the compiler. And for those couple of familiar with like automatic differentiation, you can define your own function, let's say foo. Which takes an afloat outputs afloat. And all it does is that say returns x times x, you asked for the gradients, you asked for the derivative, and it will generate a function at compile time, which is the derivative function, or it will be the function that gives you the gradients. So, I was working on a couple aspects of that, because when I was coming to my internship, I didn't really know compilers and also how to create this, like how trade libraries and I literally came from a background of being a complete consumer of libraries and never even worked in compilers. I started off working on making standard library types differentiable. So in swift, there's a type called ??, and which is kind of like this fast vector that can execute really quickly on processors. [Okay] So made that differentiable. I was also making complex numbers differentiable, because we don't investigate how the complex numbers behave in our system because there's a bit of intricacies to whether a complex number or complex function can be differentiated. specifically regarding Koshi rain equations, [Okay] and then I kind of went into the compiler work. And one of the things that we want to do with our kind of final system is have functions defined as differentials. So like if you have a function x, hence why the differential is dx times y plus d y times x, because in our implementation, you define all these primitive derivatives. But the thing is that that's kinda like this forward modes differentiation. However, for example, in backpropagation, with neural networks, you use reverse no differentiation where basically you are have the scalar loss, and you're taking the river backwards, because with four mo you can think of if you have a function x, y, z and output some a you're taking in four modes of respect to x, respect to y, z. What reverse mode You just take the reverse back to eight your output and one pass it gives you the reverse. So but the thing is reverse could be too hard to understand. So what we implement are these things called the transposes, [Okay] which are like the are like the transportable functions. to kind of explain what half transportable functions are is, they're basically like linear functions. If you have function, let's say y equals mx plus b, the derivative everywhere is m, it's at x equals a million x equals five, everybody's just M. And that's a linear function. And that's a transpose of function. But when you have something like the quadratic function, y equals x squared through this two x and the derivative, it's not the same everywhere. at x equals negative five, it's different than what it is that positive five. And that's not a transportable function, because it's depends on that original input. And what we can do is because the derivative is basically your tangents. Let's say if you have x squared, it's just the tangent line at some point. This is a linear line. And what we can do is we take that function which is linear, because it's just a straight line tangent, we can reverse or transpose it. And by transmitting all these linear functions, we can get the reverse mode and the reverse, but we get a really efficient backpropagation for your neural networks. So what I was adding was I was adding the type checking for whether a function can be marked as different mark as transportable with respect to all these different variables. And because the function should function signatures can change, like if you have a function x, which takes in the float opposite flow and just does x plus y, let's say, you know, the respectable or sorry, the transpose respect to both inputs is a function which takes one input and two outputs with back to just one of them. It just takes two inputs and one output still, its respective just a single input. So it's doing some attaching their [Got it] and finally, I was working on implementing the four modes eight because at that point, we only had reverse mode ad, mainly because we wanted that efficient gradients calculations for the backpropagation of your the neural network models. But we want for mode because it's just more intuitive and easier to understand for users and people who would use swift in other areas other than deep learning wants to use it and like ray tracing or something like that. So I was implemented at the forward modes, which basically is looking at the original program and spitting out the differential. I have I think I probably some news after I have a couple of, I think, resources to anyone interested in how I implemented this. I did I think a one of the open design meetings I presented the implement the implementation details of how forward mode works. And additionally in there I explained as well how control flow works as control flow can be a bit difficult. And that was really my final cut projects was just a about stuff. And yeah, there's still a lot more work to do."
20:05,Sanyam Bhutani,"I'm sure about that quick shout out to the swift for TensorFlow team who's been kind enough to run these open design meetings, as you mentioned. So literally anyone, any one of the listeners, if you want, you can jump on the design meetings, and even talk to Chris lattner himself, of course, if you have the right ideas, so please do attend those in case you're interested."
20:24,Bart,"Yeah, we have a also mailing list that people can join. And in there we have announced, so what we're doing during those open design meetings, and as well in that mailing list you can ask any questions you have about any bugs are experiencing or any more information projects are highlighted here as well."
20:40,Sanyam Bhutani,"I'll make sure to have it linked in the description for anyone who's interested. In hindsight, you talked about all these concepts, which some of these would be easy, but given the background you might be undergoing at university but in hindsight, how difficult was it to understand how this is being implemented in the background and then work on it after that."
21:04,Bart,"But definitely was, it was very difficult. It was like, I took three calculus courses prior to that internship. And when I joined intership Sure, it's all about derivatives, but automatic differentiation, very difference, especially the reverse modes. Like it took me a couple, like couple of weeks to figure out exactly how reverse mode works like, what does it mean? What is the reverse the really the reverse derivative of function. So definitely took a lot of just looking at existing functions, talking to my host other mentors, all the people on the team. After that, we got a hang of it. And definitely the compiler details were really, really difficult but it was definitely like I really needed to help connect with my hosts and my mentors. To really understand it's a very tough kind of thing to get into as a new open source contributor as new open source computers. Very difficult time to get into the compiler, especially with the ad stuff. However, there's definitely I think, a lot of great opportunities, for example, in some of our other parts, like creating new models, making existing stuff differentiable, and things like that, except somewhere on the swift level, not so much the compiler level, look at the compiler level can be very tricky. For people, like I think we had actually, we did have an open source contributor, Anthony, who's a PhD student at CMU, but it was him he really has experience working on compilers before hands."
22:34,Sanyam Bhutani,"Got it. Now going through the experience of interning at Google, like you mentioned, your host, I'm sure would have been helpful while you were picking these topics up. Could you also speak to the experience in general and what did a day in your life look like while you were working there as I think they call it a noogler, I'm not too sure."
22:53,Bart,"Yeah. Noogler yeah. So yeah, for any new full time or they call them like nooglers. "
22:58,Sanyam Bhutani,Okay.
23:00,Bart,"Terms of the day in life. Like, what? I think generally speaking, one thing I really liked about my internship was the lack of meetings. There's a longer fewer meetings and I was expecting, or at least I had during my previous internships. During the day, I had a lot of time to work. And generally what I did was I lived nearby, so I took the bus to work that Google provided or I also had an electric skateboard, that I rode to work. Just had the breakfast and;"
23:26,Sanyam Bhutani,Boosted board?
23:27,Bart,"Then yeah, boosted board. And then just have breakfast sometimes by myself and sometimes someone else and then just generally, depending up there's no meetings or meetings. I work to like lunch, and then with my team, or some people like grab lunch and then we kind of either sit outside or sit at the common tables in our building with the right people. Then back to work and then I think around like six or something we went out for dinner with with the people even from some other teams. Like I went a lot out for lunch with someone called Mike burrows And he was really funny, his stories."
24:08,Sanyam Bhutani,What one thing that I really envy from this point of yours is you don't even mention the lunch at Google. So this is derived from the point when I interviewed for the a residency and you don't even recognize that the lunch is so amazing at Google. So that's something I really envy.
24:25,Bart,"Yeah, it was it was I think I was on Kaggle you saw even like, because like a lot of the it's kind of like, a lot of those companies in the Bay Area have like if you don't provide lunch or something. You're not the barrier company. So even like with my previous interviews, I had lunch provided as well."
24:39,Sanyam Bhutani,"Makes sense but still, Google wasn't the best also compared to others. "
24:44,Bart,The food? 
24:45,Sanyam Bhutani,Yep.
24:47,Bart,"One thing that's really cool people say is the Google complex like the Googleplex, which is where I was working has not the best food. [Okay] Example when I went to like DeepMind in England, they had really really, really good food over there. That was much better [Okay] than what they have like on Google Docs campus."
25:04,Sanyam Bhutani,Interesting. You also mentioned and I also found this image on Twitter. I will try to Photoshop it into the video after I edit it but you got to meet Jeff Dean and Geoffrey Hinton himself. Could you tell us more about that? And can you confirm or deny Jeff Dean is an AGI or not?
25:21,Bart,"In terms of AGI it's kind of hard to say cuz it's got turn tests, right. So he is an AGI then, how am I supposed to know? [Yeah] That's good AGI. [Okay] But terms of background. So this was during my first week of my internship still, like orientation was going on and everything. And at the time, I was at my desk, I think just setting up my computer just setting up everything. And I think my, my mentor was like, oh, there's a celebration for Geoff Hinton for his Turing Award. Let's go there and just check it out and see what's going on. And I went there with everyone was with everyone and kind of saw like, Jeff Dean. He's talking about and celebrating or taling about what Geoff has accomplished and it's been okay. And then I was like, okay, this is nice, took all the pictures and then I went back to the desk episode that's like a man I was like, not going to go back there and look at a picture with them. So went back there. And then I was looking around I saw Geoffrey Hinton, Jeff Dean, Sergey Brin, And then Mike Burrows all setting in circles is like, okay, let me go back up a little bit and see if I get a picture of them. And yeah, it was, it was perfect, but right time, all of them were just there together. "
26:32,Sanyam Bhutani,Got it. So you also mentioned you go to visit the DeepMind office. Could you tell us more about the visit? And maybe how was the office experience in general?
26:41,Bart,"Sure. So I think in July, my team and I went to DeepMind for a little trip, and it was like, some stuff we worked on. Now everything I can talk about, like one of the things like definitely talk about is what's was released and the blog is called Open Spiel, I'll talk about OpenSpiel in a little bit after [Sure] and that was some of the stuff my team got to work on with me because of just the internship kind of timeline, I was very much focused on my project and getting forward mode at implemented in terms of like the I guess the office experience it was I really like to Google's England office I really like England and London especially and what might be for London, England and like San Francisco or New York or Toronto, it's definitely my favorite city. [Okay] What else got yellow dot talk also like bunch of like people's lists and engineers on like, who made AlphaGo. Also, I saw like the room with kind of the alpha star stuff going on. I was gonna talk to some like, like the CTO, Dan Bella was locked on top of things to talk to and know people and also you can talk to some existing PhD interns, because I was really interested in like determining whether the PhD is right for me, so kindly talked to a lot of them and be like, should I do a kind of a PhD? Is this the right thing for me? [Okay] Yeah."
28:09,Sanyam Bhutani,Did you get to play with the bot as well? So go or [Oh no] Okay. And can you confirm or deny if researchers at DeepMind are from completely another dimension? Can they just read equations and turn that into code in the back of the head?
28:25,Bart,"There, everyone's very much even like with Google and like talking to Chris and everyone, everyone, even like just google brain, everyone just very down to earth and very much as very open to talking to you and they're not like, it doesn't feel like everyone had above your source. It feels everyone feels just like very normal sorts. [Okay] Yeah."
28:44,Sanyam Bhutani,"So to talk more about openspiel, could you tell us what that project was all about? And I think it was also presented in a open design meeting. So I'll have that link in the description."
28:53,Bart,"Yeah, it was presented there as well. So what it is, is it's kind of like open AI's gym and that it's a reinforcement learning environment. However, there's a lot more I guess, a variety of environments. They're not just kinda like this atari and games, these like perfect permission games. There's a lot of these like imperfect information games like poker, ladoo poker is another kind of board games are like tic tac toe, things like that. It's all these different types of games to board to get the researchers in both reinforcing learning but also like game theory, because with reinforcement learning, reinforcement learning doesn't always work, for example, in perfect information games. So it's scraper researchers kind of looking at how do we handle and solve these imperfect information games. And also, so what we we kind of did was some of these existing algorithms. That's the deep my team has some of in Python, we kind of ported over to swift so I think we had like Tic Tac Toe, Koon poker, poker, Texas Hold'em and also couple algorithms like exploit the ability to sense, which is a really good algorithm which tries, which kind of like is based on game theory, which tries to emulate the Nash equilibrium. And it's really good. And these are imperfect information games like poker. [Okay] And there's also a lot of work to be done porting over some stuff to swift for anyone's interested."
30:21,Sanyam Bhutani,"For sure, I also want to drop a quick plug. So I actually interviewed Dr. Marc Lanctot to who's also on the open spiel team and is a contributor to AlphaGo. I think that episode will be out after your episode goes up. So for the listeners do stay tuned for that in case you're interested. Now, coming back to the internship, if we could maybe zoom out a bit and if you could talk about how was the experience in general, while working with the amazing engineers and researchers at Google, any mindsets or personality you take away that you might have heard from this working with them?"
30:59,Bart,"Sure. So one thing is that like who are really become the so I think like every interns experience is different. So like, some people have a much different space than either like I think with my experience, it was very unique and the places I got to go people, I got to talk to the work I got to do. And with it with the thing, the biggest thing I got out of it was, even though come up as an even though I'm kind of young and an intern, don't be afraid to really make an opinion and really kind of try and make a face like an impact on the projects in that. Try working on these small projects, these new projects that are coming out and see if you can like really influenced the project and really work with some of the developers as an intern to steer in the right direction and really give your input. Don't be afraid to just yeah, criticize what's going on and be like, I don't think this is the right approach. We should try something difference. Doesn't want what the big biggest thing I think of if it was really making my opinion [Got it] acting on it."
31:59,Sanyam Bhutani,"Now when when you were working with the team, you were already familiar with swift but for anyone who recognizes the future of swift and is maybe excited to jump on board with the contribution, do you have any favorite go to resources for beginners who just want to get started with swift specifically?"
32:17,Bart,"I forget the name of the book of the, There's definitely a lot of resources out there like terms of like, if you're, if you're a kind of more of a reader. And there's like a ray Wunderlich"
32:26,Sanyam Bhutani,Ray Wunderlich.
32:30,Bart,"Which really kind of goes like I'm really intro in swift and how swift is and some of the syntax for those kind of more just kind of curious, like, just the overview we made, would put it over, I think, some tutorial which kind of goes into how arrays work, and things like that, as a colab tutorial on our GitHub, our TensorFlow, swift GitHub."
32:54,Sanyam Bhutani,"Got it. Also, it's again, I believe, an open area of contribution in case you'd like to create more sources like Python has this amazing wide variety of resources. So once you pick these up, maybe come back to the community and give more resources if you like. [Yeah] So my final question to be a to you would be a good advice to have for maybe freshman part or someone who's just starting out with open source contributions, and somebody wants to contribute to swift for TensorFlow. "
33:23,Bart,"Sure. So thank you like for coterminous with TensorFlow. I think the biggest thing, like the best area is kind of to do it as take a look at some of the existing started bugs, either on JIRA or the issues tab on some of our repos like we have, if you, for example, are more interested in the API's, like how is convolution implemented, and maybe you want to add another cup type of layer, you can look into like the swift API's repo. One thing is if you are required to have existing backgrounds with deep learning and want to let's say, implement a model in Swift, what we are doing is if you implement a model in swift, like a new model and it works and I think it's great, you can you can bring it into the swift models repo and really kind of these existing couldn't bring it to like our model garden and have these examples written in Swift that people can use. So there's kind of a variety of areas I can crank the models you can create pretty old models with bring it here, you're similar and API's and looking like this with API's is good as well."
34:30,Sanyam Bhutani,"Got it. Alright, this has been an amazing conversation before we end the call what would be the best platforms to follow you and follow you work?"
34:38,Bart,"I think my best will be my Twitter, which is on all like, all lowercase bart_chr."
34:46,Sanyam Bhutani,"Okay, cool. I'll also have it linked in the description in case you all want to check it out. Thank you so much, Bart, for joining me on the show and talking all about swift for TenSorFlow."
34:56,Bart,"That's great, to talk to you."
34:58,Sanyam Bhutani,"Likewise, thanks again."
35:11,Sanyam Bhutani,"Thank you so much for listening to this episode. If you enjoyed the show, please be sure to give it a review or feel free to shoot me a message. You can find all of the social media links in the description. If you like the show, please subscribe and tune in each week to ""Chai Time Data Science."""
