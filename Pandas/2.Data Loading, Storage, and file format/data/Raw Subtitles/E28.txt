Sanyam Bhutani  0:13  
Hey, this is Sanyam Bhutani and you're listening to "Chai Time Data Science", a podcast for data science enthusiasts, where I interview practitioners, researchers, and Kagglers about their journey, experience, and talk all things about data science.

Sanyam Bhutani  0:45  
Hello, and welcome to another episode of the "Chai Time Data Science" show. In this episode, I interview the CTO of h2o.ai Arno Candel. I feel this is a very unique interview on this series, even though where we talked all about Arno's journey into the field, the comments and the insight by Arno are really broadly applicable to the field and not just limited to his journey. So I'm really excited to be releasing this interview, we talk all about Arno's journey of course, and machine learning, automated machine learning, broadly speaking. We discuss his journey from being a physicist, to eventually changing his role into software engineering, followed by machine learning and his journey at h2o. We also discuss all about h2o's vision, products and the maker culture as we call it. Note, this is a special interview that's being released on h2o.ai's YouTube channel. So thanks to h2o for letting me do that. If you're curious to check out all of the other interviews that are going on, you can find the link to the playlist in the description of this episode. For now, here's my interview with Dr. Arno Candel. Please enjoy the show.

Sanyam Bhutani  2:14  
Hi, everyone, it's a great moment in time where I get to interview if you may, quote unquote my boss, the CTO of h2o.ai. Hello, Dr. Arno Candel. Thank you so much for joining me on the "Chai Time Data Science" podcast. 

Dr. Arno Candel  2:26  
It's my pleasure. 

Sanyam Bhutani  2:28  
So you hold your PhD in, PhD in physics from ETS, and you worked across multiple roles, including staff  research scientist, senior member of technical staff, and now the CTO in a machine learning domain. And you've also worked across different domains. Could you tell us how did you get started with data science? When did you find your passion for the field?

Dr. Arno Candel  2:53  
Yes, absolutely. So, as a child, I always enjoyed programming as soon as I had access to the computer, I wanted to program especially asteroids flying around, you know, simulating nature. And I developed this joy of physics and science and general I wanted to be good at school no matter what it was, so I was good. You know, in soccer, whatever you name it, art, and I just kind of wanted to solve all the puzzles that school was thrown at me. And one of the problems later became, what do you want to do after high school? Right? Because I grew up in Switzerland, pretty much everybody can go to universities because they're free, you know, you just go to the closest University and you get a PhD, basically. 

Sanyam Bhutani  3:34  
Okay.

Dr. Arno Candel  3:35  
If you only say yes, you're good, right? So I kept saying, yes, yes, yes. I just want to continue. And I became a PhD in physics, and the thesis of my PhD thesis, you have to pick something right. So I asked one of the professors, what do you recommend? Is there anything you can tell me what I should do? Because I love simulations, I love you know, I love physics, nature and all that and he said, he was the director by the way of a particle physics laboratory that time.

Sanyam Bhutani  4:04  
Okay.

Dr. Arno Candel  4:05  
And he said, why don't you simulate our proton accelerator, with supercomputing and C++, you know, and distributed cluster computing and all that. So I said, Okay, that sounds great. Let me do that. And that turned basically from a masters thesis into a PhD thesis.

Sanyam Bhutani  4:22  
Okay.

Dr. Arno Candel  4:22  
He connected me with all these accelerator scientists, and also with a professor that was teaching computational physics and he's now doing quantum computing at Microsoft is also one of the world's leader in that field. So very, very good people had access to as a student, right, it was a privilege and basically, I got paid to do a PhD in supercomputer Linux, you know, be aware of clusters, we had access to hundreds of servers back in 2000. 

Sanyam Bhutani  4:54  
Okay.

Dr. Arno Candel  4:55  
I'm gonna lead a laptop and we have C++ compilers, templates, all the smart stuff of programming. And it was basically a hobby that turned into reality. And after three years, I got my PhD in the same room as Paulie, one of the physics Gods basically, how the rumor he was teaching and all that. So it's pretty prestigious and that almost half an hour for me, I grew up. So I would say, very fortunate to have grown up in Switzerland. Ofcourse my parents were always very encouraging to do whatever I wanted, and they gave me a great home great culture. And finally, I got basically, to have this PhD in hand. And because I was working on this physics problem, other people in the world took notice, especially once I was in Russia presented my work and someone from Stanford saw that I was doing something that they are interested in, namely the simulation of electrons in an accelerator cavity. 50 megawatts of power, jolting these electrons around that simulation. To do that on a supercomputer was something that happened existed before and to do that, well, was exactly my thesis. So they said, why don't you come work for us come to Stanford?

Sanyam Bhutani  6:10  
Okay.

Dr. Arno Candel  6:10  
And I was like, Okay, what effort? Right? I didn't know you're not literally like Stanford was. They said, well, San Francisco. Okay, okay, I got it. I basically flew from one month to Stanford to see the area and all that and after a while, I said, of course, I'll do that. They offered me a job at Stanford's  Linear Accelerator Physics Laboratory. And that was my first six years basically in the US, so I happened to be implanted into the Silicon Valley, but I was on the other side of Sand Hill Road, so for those that don't know about the road, one side is the venture capitalists. The other side is this particle physics lab. 

Sanyam Bhutani  6:45  
Okay.

Dr. Arno Candel  6:45  
Every day I drove by and saw all these expensive cars turn right.

Sanyam Bhutani  6:52  
But there was some, I believe, influence, bleeding influence, the other edge as well?

Dr. Arno Candel  6:58  
We didn't have any connection to the VC world, to be honest, it was purely research and science. So we were talking to the people in Geneva, the particle accelerator, called the CERN, this massive, mildly sized Hadron Collider and all that they were working with those people and so they weren't our customers. And we were making simulations at this particle accelerator lab called slac. Just like the chat system without the K at the end, so slack SLAC.

Sanyam Bhutani  7:28  
Okay.

Dr. Arno Candel  7:29  
That was the, they won two Nobel prizes for you know, the discoveries in particle physics and all there was two, all they were doing was research in elementary particle physics, using those massive machines like thousand microwaves on top of each other, all in the size of one. So highly energetic electric systems that were pushing these particles around in vacuum basically in some copper pipes.

Sanyam Bhutani  7:58  
Got it.

Dr. Arno Candel  7:59  
And some pipes would almost melt. And you would have to type everything just right to accelerate the particles to the speed of light after three inches, right? But they would go on for a mile and get faster and faster, because the speed of light and the ene would smash them into something. And or nickel them to create light coming out and so on. So there are lots of use cases of these physics experiments. But I would say what I was working on was always on the future. So we were trying to predict the behavior of these particles in a new regime that ever jolted around even more than before. And the question was, can you build a machine that costs hundreds of millions or up to $10 billion dollars and behave in a certain way, right, and this machine hasn't even been built yet. To some extent. Some of them haven't been built in even 10-15 years after that. So some of them are actually in production right now. Running and doing good stuff for research in biology, cancer research, and Alzheimer's. So there's lots of interesting stuff coming out of this physics research should be helped to work. But then after a while, I got my green card and I saw my friends doing the startup stuff and;

Sanyam Bhutani  9:15  
The influence of Silicon Valley.

Dr. Arno Candel  9:17  
and I basically, I got pulled into the machine learning field back then when it was not yet called data science, right, there was just barely coming out. Most people would call it big data analytics, or, you know, just big data in general. And all they were doing were, we were writing algorithms also, just like in nature and science, and he modeled some physics laws, they would model some, some equations that some mathematicians came up with and said, in the decision tree, or you know, build some some k nearest neighbors, and those equations are simple, but the hard stuff was to make it fast, you know, gigabytes petabytes make it run in parallel systems make it;

Sanyam Bhutani  10:03  
Is a cha-challenge of sorts.

Dr. Arno Candel  10:06  
Yes, just doing something simple, really well, that it works for everybody is hard, right? And kind of the joy I got is to try to make random forest really fast or gradient boosting really fast or collaborative filtering really fast. So there was the first startup, I joined as one of the first engineers and the first hire actually. And after two years, I joined h2o, and I've been now since 2011, late 2009. Actually 2013 was when I started with machine learning. 

Sanyam Bhutani  10:37  
Okay.

Dr. Arno Candel  10:38  
So I've been in the field for about eight years now.

Sanyam Bhutani  10:40  
And I think that's why you're a, Fortune recognized you as a Big Data star and not a machine learning style because it wasn't called machine learning back in the day.

Dr. Arno Candel  10:50  
Back then it was all just like, you like the data, yes. Okay. And even today, I'm really scared sometimes when people have the data to do something with it. They might not really know what they're doing, right? There's a lot of mistakes that you can make with cross validation or validation or the wrong, you know, you have the wrong feature somewhere that gives away the future. And then your training on against all we can talk about that for endless hours. But there's lots of things that you can do that's wrong. And we're still in an early space, right? The whole world needs a little bit more help, I would say. and machine learning is still a little bit difficult, I would say, but they're trying to make it easier for everybody. So that's what our mission is at h2o, obviously, since you joined and by the way, congrats to your graduation I heard the;

Sanyam Bhutani  11:37  
Thankyou. 

Dr. Arno Candel  11:38  
The honors and all that that's awesome. So we have you on board and we are very fortunate to have so much talent and the company and and we have a great mission, right? It's really give this insight that sits inside the data, give that to the people that own the data, right it's it's almost like an exploration into the already exists in truth. It's like when you're carve a statue out of a stone, the stone is there, the statue is already there just not visible and the data is the same thing, right? There's a lot of insights. And it's hard to see from each angle, you have to look to actually see that information. And if you look from the wrong side, you don't see anything. So kind of unearthing acknowledges.

Sanyam Bhutani  12:21  
That's a great analogy in terms of machine learning as an art, so to speak.

Dr. Arno Candel  12:26  
It is still almost alchemy, right? There's like you almost say, reinforcement learning direction goes to explain it or don't explain it, you know, all these different opinions and not really been truth. Because even if you get the higher end, you see, let's say I could better model. What does it mean? It's better? It's only better than that one data set that you measured it on. Right? How about tomorrow's data set? 

Sanyam Bhutani  12:52  
Yeah. 

Dr. Arno Candel  12:52  
What is that? Yeah, sure.

Sanyam Bhutani  12:57  
We'll talk more about at school just in a bit. But just trying to connect the dots here because I remember reading that since you were fascinated with asteroids you did program. Your first hello world was asteroid simulator in basic. So trying to connect the dots for you always a coder throughout this period as you were even working in research or did you shift from physics to a coding environment?

Dr. Arno Candel  13:22  
I would say I was always a coder, yes. So my emphasis has always been on the programming part, even of science and physics and all that. So pretty much every day for the last 20 years I've been programming something so that would be true, I can say,

Sanyam Bhutani  13:36  
Okay. Which also brings me to the fact that you previously were called a physics and hacker at h20.ai, so broadly thinking, do you find any parallels in physics and data science?

Dr. Arno Candel  13:50  
Absolutely. Yes. So physics, teachers, one thing is not many more things, but at least the teachers who run thing which is to think critically about what to do because you're in, physics, you have to, like, take it out by the hydrogen atom behaves the way it does, you have to do path integrals, or quantum electrodynamics or Quantum chromodynamics. All these theories are super complicated. Takes time. So it's, it's so crazy that if you don't know what you're doing, you might as well give up because there's no point in going down that rabbit hole, I guess. So you basically learn to take every step carefully and make sure you have the basics right? And if you're a data science, you kind of don't need to do it. Sometimes you can just say, yeah, let me just sit there and forest and she looked at me. But if you want to do it, right, you should say, well, what was the foundation that I have behind? It wasn't actually doing that I sampling first or not? Or, you know, which column does it take? Which decisions does it make? How does it make decisions when it makes a split in a tree? What does it mean? It means that split which goes where? What is next to your building? Is it isn't correlated with liking gradient boosting? Or is it independent? Like you asked all these questions and actually implemented from scratch, every single line of code has to be right. Otherwise, the whole thing is wrong, right? And basically asking yourself constantly out of these 12 things I could be typing, which one should I type, right? In the end, the keyboard doesn't have path integrals, or the keyboard just has plus minus and, you know, delighted in times and all that. So you have to figure out how to write it in such a form that you can present the this is hard storytelling with those simple keyboard keys. 

Sanyam Bhutani  15:37  
Yeah. 

Dr. Arno Candel  15:39  
And you have to say, Okay, I'll let me do some kind of feeling or let me do some kind of, you know, tree structure to represent the data. And then when I do sort on, it becomes this and this complexity deserve to think about the cost of everything we're doing so that it becomes fast and gives output, right? And the physicist kind of has this this big big picture thinking about you're thinking the magnitude only so is it like 10, or hundred or thousand physicist, all those things and those kinds of terms, they don't care of itself. 12, right. It's like, what order magnitude am I talking about? And in that picture of magnitude to worry about the next order thing, once you are sure that you're in the right frame, then you say, well, what can I do next to improve? That? I would say that's the secret of a physicist working in any field really is the big picture and the small picture at the same time.

Sanyam Bhutani  16:34  
I think it's again, like you said, thinking of this culture while looking at the analogy

Dr. Arno Candel  16:41  
Yes, yes. And obviously there's other people that can do it. It's not just physicists, right. I'm a little biased here. But scientific background who spent years thinking about simple stuff like you know, derivations of some mathematical terms of whatever helps a lot right?

Sanyam Bhutani  16:56  
Yes.

Dr. Arno Candel  16:56  
To get the skills get get further And the more you're distant from that, the more you're likely to say, I don't know, you need to know that let me just play it out and become the alchemist. If you really want to understand it, it's definitely helpful to have gone through this exercise once at these courses forces you to actually go deeper than just alchemy. 

Sanyam Bhutani  17:22  
Yeah. Also thinking of it right now that the science and data science really comes from that fact that it's an experiment first versus theory first subject, if I may.

Dr. Arno Candel  17:33  
Yes, yes, definitely. And it's lowering the bars with all these platforms that are out there, you know, from TensorFlow to Pytorch as sklearn, and even our products, they make it so easy, like one button, you just immediately you get a solution, right? And you get a number and that number is pretty good. So you might be tempted to say, oh, let me just put that introduction without thinking about what it actually means. And I think if anything, you should think first do a couple of experiments and then see if your hypothesis holds, right. And if that's the case, then you can be more confident. But you should not just run one experiment and trust it blindly. Unless you are in that framework. When you've done it before. And this data is the same, everything is the same, then you can just do one more like it. Let me just start afresh, you should spend a few weeks always on a data set.

Sanyam Bhutani  18:25  
Got it. So coming to your current day job. Can you tell us what does a day in your life look like? Do you spend time on Kaggle all of the day? Or do you have chai with Grand Masters as to HQ?

Dr. Arno Candel  18:39  
Well, a little bit of all actually, so I'm on Kaggle the last few weeks, maybe just a few percent of my day, right? And only 4% of the whole year. So it's very little unfortunately, I like Kaggle a lot I would have preferred if I could like to spend weeks on eight and just tell them one problem. What a good debugging tool if your software doesn't run on the Kaggle problem, there's probably a reason why doesn't and often it's because we didn't exploit the leak, or you didn't have the test set abused as your training or something that you can like learn everything about the future, even though you're not supposed to actually know that, right? So we have a couple of things who are maybe stretching the truth a little bit or essentially, the arms of what's possible for an enterprise. Sometimes they don't have future transactions, right? And kaggle you do get them. So let's assume you don't have any future information. It's all fair. Still, Kaggle helps you right? Because the very first time you press it, and you see what happens. You say, oh, wow, I'm so much worse than the leaders on that leaderboard. Give you some kind of feedback and, and be they do that a couple times successfully, right. Like, for example, there was this Kaggle days. We need to see you I think when Google's automail came out for the first time and we did play next to it in the leaderboard, I'm on it there. And I;

Sanyam Bhutani  20:03  
I believe you're fourth on the leaderboard.

Dr. Arno Candel  20:06  
I was using driverless AI right. And I think there were other people that we know from the community. They were like third or something. So they were only there was very little gap between us and Google. And I think that data set was mostly noise anyway, so it's kind of hard data bars must have been way bigger than the actual differences that I feel pretty good. That one was one that we did well at. And there are some others that were doing well, but often it's about the framing of the problem, right? And just thinking about what is it that made my solution not work right out of the box, helps to make it better and generalize more because it doesn't have to just work for that Kaggle problem. It has to work for everybody's Kaggle problem in the whole world, but every every industry, right? We have a very broad target here. We want to be a general purpose machine learning platform. And that's a good It's a good stomping grounds for sure. But my typical day, I would say is mostly talking to people and then programming right and picking out what's customer feedback. So I'm involved in customer discussions and an internal discussions. And once we know what's going on, program, basically fix the issues or talk to other people and then fixed issues. I really love to be doing one on ones of various people. So I talked to Grand Masters a lot, that's for sure. Now that we have been at a store, I switched over the I, 30 Grand Masters is a lot to digest, you can talk to them all day long, and you always learn something new. So the ability to quickly get feedback about any topic. And that's all this expert feedback. That's so much input into somebody who needs to program. So as as programmers, our engineering team has so much to do. And they're all amazing, right, not just the Grand Masters also the engineers. This team is so great that they just listen to what the Grand Master has to say. And then it becomes a a solution inside the product. And often the Grand Masters are programming themselves, right? Which is even better, because they've done it for all these Kaggle problems in Python. Why not do it for driverless AI, for example, which is also in Python. 

Sanyam Bhutani  22:13  
Yeah.

Dr. Arno Candel  22:13  
So our Recipe architecture makes that kind of easy. They can, they can prototype their own ideas in minutes. And then when it works, you can just ship it to the customer basically, after minimal modifications and making sure that it's actually robust and all that.

Sanyam Bhutani  22:29  
That's one of the highlights of it. Just mentioning it for the audience is bragging if I may, that I get to sit right next to SRK Sudalai Rajkumar I still pinch myself every day, but that's really a highlight of my everyday.

Dr. Arno Candel  22:44  
Absolutely, yes, the talent pool is just amazing. And the ability for us to tap right into those Grand Masters because they all talk to each other and say go to h2o. All right. So should we should say the same thing if you're really good at data science and offer to doing that really all there I want right here into this not for anything but enjoyment. We all love it so much that there's only two, right everyday even in the flow. That ability needs the demand on us, oh, you're always able to deliver but needs to be delivered.

Sanyam Bhutani  23:16  
Yeah. 

Dr. Arno Candel  23:16  
You're never stressed that you're like two weak or so because we're not asking you to implement TensorFlow on a laptop or something. You know, it has to be it has to be something realistic. But if you're a Grand Master already then kind of nothing is too hard for you right? 

Sanyam Bhutani  23:32  
Yeah.

Dr. Arno Candel  23:33  
To do going through this pain until you make it on the other side. And I think the same is true for the engineering in our department. We have a lot of really well you know, proven engineers that have shipped all these solutions on like power PCs in Docker, you know, Kubernetes, is that on spark or not all the solutions within this security, database connectors all this company acceptance of the real world, it's far more than just machine learning, right? It's, it's shipping this key. What is it called when you can turn it turn key it or something just into the hands of the data scientists. And they don't even need to worry that this whole thing is is virtualized or whatever, it just kind of works. And that's really the strength of this team is the middle layer for the AI. 

Sanyam Bhutani  24:24  
Yeah.

Dr. Arno Candel  24:25  
And obviously, the Grand Masters have added some of the smarts inside but there's a lot of building like onion layers if you want that make this, this whole software product consumable. And there's a lot more than just data science, I would say at least two or three x in overall terms more than just data. But of course, the data science core, this the smart sampling, the smart model, selection, tuning feature selection, you know, and also being able to deploy the final model after you made an ensemble with feature engineering and all that super complicated Kaggle style pipeline, you push a button and you get a Java pipeline out. Surely standalone in Java, absolutely no Python and you get the whole thing as a jar that you can deploy, right? That's almost a miracle and be able to pull that off because somebody painstakingly re implemented every single transformer and model in Java enabled for it, right. And this is also non trivial, right? So I think we're ready, proud of the team. And it's fun to work with all these different aspects. It's, it's really, it's really fun. And every time there's some accuracy issue where we say it's not quite smart enough, the Grand Masters obviously have plenty of ideas about pytorch, TensorFlow, all these new technologies that obviously we've been doing deep learning for years, but not to the extent that you will need to do for like NLP, for the images. Now, we have image Grand Masters, NLP Grand Masters just like SRK, and others but they're like Sudoku champions of the world, right. And this is so amazing talents that basically just building an NLP model, it's almost like you have to always keep asking them for a little bit more and keep them stimulated and keep them involved. I think that able to do that that's why he was such a good place.

Sanyam Bhutani  26:19  
I think it's really a privilege for me at least to be on such a awesome team. Can you confirm or deny the fact that you ever sleep because I've seen you active on slack throughout all times of the day?

Dr. Arno Candel  26:33  
Yes, I do have two little boys that jump on me at night. So I don't sleep because of that, but I do get some sleep. But as you can see, I have a computer mouse right here right? This is all no matter where I am. I always have a computer with me and I would say I'm pretty much thinking about something that's running in the background all the time. So I have like two or three computers, two two at home and one at office that are constantly running some tests, you know, knows something and every time I have an opportunity to check and make a decision based on facts, basically and I'm trying to, to optimize my time, right and every day time time like never enough. Sometimes you sit sit here at five in the morning and the sun comes up in the like, I should go to sleep I, I need to go to bed. So that's true. It sometimes gets into the thick of things. But I would say overall, it's a pretty healthy life, especially because I'm happy, right? It's important to be happy. If this was like forced upon me, I would say, oh my god. It's actually what I want to do. That's my choice.

Sanyam Bhutani  27:41  
I think the passion so giving some insider info, if I'm just scrolling through this lag, the passion is shared throughout the team. I think it's as we call the maker culture, it's present across everyone on board.

Sanyam Bhutani  27:54  
Exactly. And I think it's important to state that again, like if you're not that kind of person that wants just do what they want to do on their own path, be creative and be know trying out until it works. And then say yet I did this training, if you're not that person, if you want to get into, I want to be told what I should be doing, and I want this role and I want to fit into this year of the overall system and this is my position, then h2o might not be the best place, right? Because we don't have as much bandwidth to constantly tell you what to do or what not to do or to check you. So that's why kind of the, the makers place for each maker is the veal, but it's organically forming, right. It's like when you push an avalanche forward, it's not going to each each snowflake isn't going to ask the artist where should I go, right? 

Dr. Arno Candel  28:43  
Hehe.

Sanyam Bhutani  28:44  
Well, and they all roll and they all move and I think that's the key. So even if the story changes, let's say there's a new product we ship or we have a new idea of somebody came up with a great prototype suddenly we say that's that's pretty more horses behind it, then it might happen overnight, right? Tomorrow, we might say let's do something new. And that's the joy like you get the good people and then you forget I want to do later and just, you just do what you feel like is right. And obviously, it's not single person's, it's always the team. It's always, as a whole, we kind of figured out what to do there is a lot of discussions going on, even though not everybody is always involved. But you know, I would say I am not fully involved in most of these. I just hear from the peripherals, but I hear enough. And then when it gets important, only somebody asked me what do you think and ask them ask them anything? And then they asked somebody what do you think it's a very liberal system and again, whoever trust someone else asks them what you think. And if the overall sentiment is that it's not a good idea, it will come up. And if you over implement this, yeah, sounds good. But I don't have time right now. And you still don't do the old stuff. But a bunch of time or you feel like yeah, actually the momentum shifting let me do a little bit more. The new stuff suddenly you're on the new stuff. And that's because you feel it's a good thing, right? It's not because someone told you to do it, it's because you know, I think it's the right thing. And this is the culture that Sri, our CEO has put out to us right is he's always said do what right, basically do you know you decide I just give you ideas basically. 

Sanyam Bhutani  30:19  
Yeah.

Dr. Arno Candel  30:20  
And this is the power right of the maker culture it's very visionary to to let everybody be a maker and not just be told what to do right? You're not making it for him. You're making it for yourself this is our careers. It's our company and we all together are building something that if you want to ship PyTorch's NLP models. You're welcome to hack it in and in a few weeks it shipped right and and that's exactly how it works. So you think it's very liberating to be able to deliver at any level and this this meritocracy definitely works for us.

Sanyam Bhutani  30:54  
It also speaks about the cutting edge of machine learning really lies at the engineering level if you're facing people for example, you will already be talking about these onion layers of engineering that go into play. So it's also about building products and shipping them really fast as engineers are supposed to do but in this domain.

Dr. Arno Candel  31:15  
Yes, definitely. It's the speed is something we we are very, very known off by basically a quick vote and our challenge in quotes is to make sure that still robust and stable so sometimes we shifted it so fast that there are some obvious bucks left right it's almost like saying there early Tesla had some battery issues or something and then we have to fix it and after a while, it gets better and luckily, because it's software and you can fix it and our customers are usually flexible enough to just upgrade when you have a new version. And I think over the two years it has matured a lot and now I would say it's it's really good, we random attacks all day and night to make sure that no bug escapes right. And it's not easy because it's such a complicated beast. But I would say definitely, the product owes have gotten a lot more stable the last few years and that's been the reason why our products are so widely adopted. So the open source h2o three by the way, which which is really widely used hundreds of thousands of people are using it right. That's that's a great workhorse and it's amazing product it can scale to like thousands of nodes and terabytes of data and just around so gradient boosting machine, right? And driverless AI, for those who don't know, is basically the single node solution at the moment. But it's a a super smart calculating the box base of it. There's all kinds of feature engineering. So one thing is the feature engineering, green, tries different experiments and keeps it the single best model on the data. And the other thing, the is the workhorse that just chews through data like nothing in a distributed system. So if you have a really big data in vegetable, and also system sparks, it's called sparkling water and if you have up to say hundred gigabytes or so smaller data, not terabytes, then we can use driverless AI there, we will get most likely a slightly better model, if not a much better model depending on waht the problem is, and also MCs, TensorFlow and all that stuff. So because it's based in Python, right, you can do anything. So I think the beauty of Python really is that every data scientist now that's in Kaggle, doing well, right says, oh, yeah, I wrote all this in Python. 

Sanyam Bhutani  33:26  
Hehe.

Dr. Arno Candel  33:27  
We can just take it as a recipe and plug it in while it's running. Right? 

Sanyam Bhutani  33:31  
Yep.

Dr. Arno Candel  33:31  
And so this this recipe architecture in the make our life a lot easier, because now everybody can be contributing code and not just a few program et's say that.

Sanyam Bhutani  33:44  
You already mentioned a bunch of products that h2o.ai is shipping both open source and commercial. Could you help us distinguish between these and understand because all of these are currently in active development?

Dr. Arno Candel  33:56  
Yes, yes. So they're open source distributed worker machine that's amazingly scalable and and, and performant. That's called H2O-3. And that's open source, hundred percent open source, but customers still out of buying the license to get support and so on, because we're helping them to make the most of it and we help them to deploy it. And that is different products around like sparkling water and steam that help you run this in a multi tenant setup on spark and Kubernetes, and so on. And then driverless AI isthe  Kaggler in a box if you want a dimension that does a lot more feature engineering than anything on the planet. 

Sanyam Bhutani  34:37  
Super Kaggler in a box.

Dr. Arno Candel  34:40  
And that's all know all these stratified splits and all kinds of, you know, smart ways of phrasing the data into new data when we can extract information from other roles across, you know, cohorts across, you know, time all that with with time series of air modeling and so on. And it really is, is also taking advantage of multiple GPUs on a box. It's designed to be highly parallel and fast. And so there's hundreds of models thousands of features, all while you're just, you know, going for lunch or something. And then you come back, you get this job artifact fact that is the standalone scoring pipeline. And now we have also a C++ artifact. That's also standalone, which means you can call it from art and Python without having meals and all that stuff for Python. So you can have the super lightweight, low latency Python and R and C++ and Java scoring. And for those who have custom recipes, you can always get the Python version as well. The pickled version, basically the normal version of to call it but again, quotes all the feature engineering of a Grand Master. And every single pipeline prediction step has all the steps in so it's pretty well you know, geared towards production deployment if you just take it and put it in production and with the right predictions and also has interpretability and visualization components to make sure that the models are not as an apples and Goldman's case right now, slightly critical right in terms of who they allow to be favored by the model. So you can at least back those models to get out there who's who's been given credit or not and why it is and for which segment of the population the model speak differently and so on. So all these model, the backings is part of a driverless AI as well.

Sanyam Bhutani  36:36  
I'd like to mention to the audience because I know a lot of them are students. If you're a student, you can go and check out driverless AI. For academics, it's free of course license. So just go to the website linked in the description of the podcast. And all of these techniques that Arno's mentioned are already there. It's not a upcoming feature that he's mentioned.

Dr. Arno Candel  36:58  
Yes, absolutely their academic program is open to any academics. So you get that for free, and you get the full feature product. So there's there's absolutely no limitations. And it really does work well for Kaggle. 

Sanyam Bhutani  37:13  
Hehehe.

Dr. Arno Candel  37:13  
For it, it gives you the feedback that you need to know which features are important and which interactions matter. It will help you quickly go through your features and tell you whether they are useful or not, and so on your idea, so you can throw in a bunch of ideas in terms of recipes, transformers or models. And you can figure out much more about that on our website, h2o.ai each. And I mean, there's so much in there, you could probably studied for two weeks and still not know, half of what's actually in there. And that's one of our challenges, right? It's, it's hard enough for us to know what we should be much less, you know, what's actually in there. So our challenge now is to put another layer on it to make it easy to consume and say just works for you what that obviously then has to be a specific vertical. It's not easy to say is a general purpose machine learning platform, and you have no control. People don't want that either people want to have control. But once that is a vertical, like, let's say it's specific to solving one issue for one factory somewhere, then you can frame it as just push the button basically, like give me data and I'll tell you the future or something. And that's something that we are now working on with the next generation called Q, where you can make smart applications that are AI enabled applications where they're all in Python, you can offer a full GUI experience around the actual Driverless back-engine right, So it's a it's an application build of kit: if you want that is coming in coming months and that will be super excited for the world. I'm pretty sure that that will find a lot of good use cases.

Sanyam Bhutani  38:53  
Subscribe to "Chai Time Data Science" for discussion on that whenever that will come out.

Dr. Arno Candel  38:58  
Yes, definitely. Yes. And we have some amazing people on our team that are bursting with ideas and prototypes and so on. So it'll be fun to announce that in more detail.

Sanyam Bhutani  39:09  
Coming to another aspect of auto ML automated machine learning, can you speak to do you think it should be a one click everything solved situation or like we were talking with you a human in the loop or data scientists in the loop for solving a data science product with auto ML situation?

Dr. Arno Candel  39:29  
Yes, I would definitely say human machine interaction will be the strongest asset of humans, right? Like you don't want to be alone with a robot taking control unless that robot really is good, right. And in case let's say, if you're if you're in a car and the car is driving itself, I would say it's okay. At some point, it will be fine. At some point, you have enough radars and LIDAR and all these optics and you know, systems that can detect this insistence on from what objects probably will be safer to let them drive them up. Falling asleep or something or somebody. So I would say, self driving cars, I can live with self driving data science decisions for very, very important business problems, I would say it's not the best idea, right. And as we just saw, big companies can get in trouble. And they make wrong predictions or give credit to the wrong people or the right people in the wrong amounts and so on. And you have to pay back this stuff. And you have to think about what it means to have feedback;

Sanyam Bhutani  40:33  
Because humans are at the end of humans do receive the consequences of such situations.

Dr. Arno Candel  40:40  
And even in the driving self driving car, so you can say it should always be a human involved, yes, in the training of these models for at least right. So we're not talking about the scoring of the model should be done by a human we're saying the training of the model. So once the training of the model is done, I'm fine running the predictions through the algorithm, right? And that's basically what a self driving cars doing it saying given the situation what should I do? And if that model was trained properly then it's all fine. Now the question is what is good enough right? You want to have you know, you want to have 100 different models all doing some voting and then you know when they all say turn left then you turn left and otherwise is a PPP. I'm not sure what to do. Or be one I like you know, say that's good enough if 80% say turns left, you know, So at what point is good enough good enough and that's again, data science, right? Like how do we know as an organization good or bad? Obviously, initiative anyone hold out, but is that enough? Hundred holdouts? What? Do you have time since you don't have 100 holdouts? How do you do it? You know when things are shifting interesting and so on. So it's so funny. There is no answer. You do not know what you do best model is right. That is why now;

Sanyam Bhutani  41:52  
What haooens when you become the state of the art, where do you go from there?

Dr. Arno Candel  41:55  
What if it snows and it's windy enderpearl is falling over extrapolate that it's gonna fall, right? Should you step on the brakes or should just push the gas pedal? So it's not easy to say what's right and what's wrong. And in data science for businesses the same, right? It's always a question of what's the best price performance payoff. And I would say, humans are smart enough to make these kinds of decisions, what is valuable to them. And so as long as money is involved, some human should think about it, right. And then the algorithm will take care of statistics, basically, of course, the bias in the statistics. So if you have, if you don't like the facts as they are, and you want the model to not behave like the data says you should behave, then you need to fix it right? And you need to change the data or change the model to behave in a certain way that you like, again, and that's the art of a data scientist is to basically take the horse and control it with the directional input right? And you don't just say, go wild and just slap course on the back end. It's going to be controlling, right? And, and I would say that's the real art. And if you look at Kaggle, some of the Grand Masters are doing like super deep ensembles and all that stuff, and others are just thinking about the data and nudging it slightly the right direction. And suddenly it's the best single model right now. Okay, people can they make one good single model are almost more respectable, let's say in terms of Kaggle achievements, then those who can stack the most because you're stacking the most by itself doesn't mean it's it's the it's that hard to do is work. However, if you can program the stacker that's also great, right? But for example, who knew StackNet, and he was years ahead of everybody.

Sanyam Bhutani  43:49  
Yeah.

Dr. Arno Candel  43:49  
Right. The whole framework for stacking, that he bought all the competitions just because so it is an art everywhere, but if I had to trust somebody for my business, decision, I would say, it should be somebody who understands the data. I think that will be the hardest part for our future. Because the data grows so fast. Humans brains don't grow that fast, right? They are actually the same as they were thousands of years ago. So you know, how do we deal with this growth and complexity, you have to find some kind of layer of abstraction, which we can talk to that system, and machine will get smarter and smarter at fitting, but not necessarily and knowing what to fit right and building to tell it what to fit. So at some point, the whole thing will stagnate. And we'll just be where we are and our ability to know what to do will be the limiting bottleneck, right? 

Sanyam Bhutani  44:43  
Yeah. 

Dr. Arno Candel  44:43  
What to flow into the system physically. Then creativity comes in where people can maybe figure out new ways of mixing data. And Sri, always makes these examples of one company has data exhaust and the other company could use that right. For example, a company that fills in your your salaries, doesn't know that they're, they could be selling that information to a bank, right? The bank knows, like, who's gonna buy the house or something, and it's a mortgage and so on. So these kinds of interactions of data, either lead to single companies becoming monopolies. So like Apple, and Amazon will be the bank of the future. And then they know everything about you. That is one option. The other option is that there will be a marketplace for data somehow where these companies jointly figured out what's best for everybody. Right? But there is a danger that companies will act only their interest and not in the humans interest. So we need to figure out what's the right political thing for everybody so that the outcome is optimal, not just for the capitalists in us, but also the the people. And that's probably the biggest challenge. 

Sanyam Bhutani  45:56  
I think that's where a transparent and effective to lewd comments to play with a human in the loop who's also the to double check on it.

Dr. Arno Candel  46:04  
Yes, yes. And then there should be some kind of a fairness Kaggler right not just the accuracy Kaggler there. The overall system is measured by its goodness and score and statistical level. So there's a lot more to be rounded off in the overall government. And one number is definitely not enough. Like always make that joke when I say in the Oh, in the beginning, you had a terabyte and then outcomes, what do you see right now you're saying I want or something like how do you know that that's actually the best model. So it's, it's still interesting how you can actually know a little bit more about the steps in between. 

Sanyam Bhutani  46:43  
Yep.

Dr. Arno Candel  46:44  
That's missing, I would say the field as a whole.

Sanyam Bhutani  46:47  
Quick plug. We just talked about GrandMaster Kazanova, I've already interviewed him on this series. So check out the link in the description if you'd like to read that interview. But coming to your journey at h2o.ai, we're already talking about future facing ideas. You worked as a physics physicist and hacker, then as a chief architect, and now as a as the CTO, is the product still not up to your vision? Did you already envision such things when you got started? If you could talk about the journey, the products that you worked and how like, it changed over the years?

Dr. Arno Candel  47:27  
It's actually I never thought we could get viral as AI going to this extent, right. When we started even the Grand Masters, they had no idea basically that this was possible. So I think we overachieved in a way of technical abilities, but maybe our, our, our brains were not able to extrapolate to that extent, maybe six years ago when we started. So at the beginning, it was all about h2o three just writing algorithms from scratch, making them faster, making them even run debugging, what is cross validation, how to do that right. Our what is isn't that what is only stopping what is all these different parameters, detects the leaves the columns happening, right? The whole something they know the number of rows in a leaf for each sprint all these parameters, we have to implement them. Right. And;

Sanyam Bhutani  48:13  
I was reading your five year old discussion on Kaggle. And even then that day, h2o three, it's h2o three now, but h2o was the fastest library back in the day.

Dr. Arno Candel  48:25  
Yes, yes. I mean, it's still is super fast if you have big data, right? If you're running on hundreds of gigabytes, there's nothing that can beat it, I would say is it's hard like maybe like GBM maybe h2o loses in certain conditions. But overall, if you want a Java pipeline coming out, this is the best system unless you want to do deep learning more, than you need TensorFlow Pytorch so I would say and if you don't really care, you can do anything else right? You can run a scanner and you can emulate you can any algorithm is fine if you just want to fit something about but if you want the highest accuracy and superfast I would say h20 three has some nice corners. You know, what's really special is that when when we started the Kaggle years ago, obviously we were like thinking about, you know, how can we use h2o to solve Kaggle? And we were not able to get there, right? And we were trying, okay, one more parameter one more thing, but without stalking it wasn't possible, so then you auto ML in Kaggle, in h20 three, which went, it's stacking, right? So suddenly you had stacking and then suddenly become, it became a lot more accurate, but then still wasn't enough to win Kaggle so we had to bring DriverlessAI, to, to basically feature engineering, right. And there are some competitions in Kaggle that we can place 10th place out of the box out of 3000 teams, right. And that's without pushing any other button, but go right, it's really crazy. So these teams spend two months on it three years ago, and now we just basically the same as the winners. And and that's pretty remarkable. And it's it's something that if you ask the Grand Masters ever said no, no, I'm smarter than the system. Chess players, just like all these video game players that now are being beaten by the systems. And if you just parameterize every choice and and make it a algorithmic decision, and that algorithm gets smarter over time, then it will at some point learn to to calculate and that's almost basically where we are today. Except that it doesn't do all the systems and all the possible things right out of the box. Sometimes you do join little sets first, or you need to do work in image problem. There are adding image by the way as a category, in addition to NLP. And so we have some tremendous image progress as well. Now we can almost have any image problems out of the box. Thanks to all these smart you know, neural architecture searches and single work cycle and you're talking to Jeremy Howard soon I heard so that's he's gonna be happy you're using his insights from fast AI. But yeah, basically there's a lot of great stuff going on in, in the field. And with these insights, you can now automate those things, right? You don't have to re implement them every time for every single Kaggle problem, you just put in once into the stable code base. So in effect, what we did this, we took what the best Kagglers do, put that into software and keep reusing it right? And it could have been one Kaggler did it for himself or herself. But it's just this is 20,000 commits, right? It's a lot more like, reiterated, tested and tested and tested. So it's hard to do it alone, but as a system as a company that does nothing else with dozens of people's everyday and our brains on it 24x7 , it really helps to get to that point where we kind of automated and I think that's cool and the next step will be to automate the creation of business insights. Right and that's cute. I think every every step is another step and; 

Sanyam Bhutani  52:01  
Yeah.

Dr. Arno Candel  52:01  
They're all, they're all natural. And for me the last six years, nothing has really changed every day. I'm still coding and I'm still involved in the important projects in the company, and I'm just doing what I can every day to make it better. And try to ask others, what would you do? What would you think? How can you help? Right? What do you think we should be doing? Is this something you expect or not? You know, delegating work, we're just asking for help, basically, and everybody is willing to offer their expertise because they are experts at what they're doing. And they want to own that piece, because that's what they enjoy doing. Right? Just like tapping a kid. I need to go slide down this hill of snow. I have a slide you ever slide yourself or can I go for you? I want to go right so obviously they will go down the hill. And the same thing for for this is kind of collaborative work. So that's the secret if you want this to have people who enjoy their work. Be able to contribute in a meaningful way. And then own that piece all the way to production, right? Everybody who makes a piece of code owns that QA part two, we have to test that code, we can just say it's, it's like someone else's problem, we actually have to make sure that works.

Sanyam Bhutani  53:19  
Also, thinking of it in this terms that this essentially even though we automating all of this Kaggle stuff, for example, will eventually allow us to think of broader problems, bigger ideas, because that's what is our end goal with all of this automation or machine learning going around.

Dr. Arno Candel  53:37  
Yes, yes. I think the the queue approach we're taking with the start with the data and then figure out insights about the data and then let the machine give you a bunch of ideas and then you can basically interact with it and say, Well, what about this, what about that, and then you see different views of the data. And if you that if you combine that with driverless, for example, other models. And then you can take the residuals of the model on a holdout prediction, right? Like you can see what was wrong with my model. And then you can plot that as a function of the data. And you can say, for people in this zip code with this many cars, what are the other distributions? And then suddenly, you can see Oh, wow, it's actually only this zip code that's wrong. And you can automatically show that to you. Right? So this is basically the the next level it's not just to say, Oh, I figured this really well. And here are predictions, but I can see where my model is not good. And I can tell you where this and almost made me why it is right. Because you can see that people with this many cars in this zip code I totally misspredicted.

Sanyam Bhutani  54:43  
Yeah. 

Dr. Arno Candel  54:44  
But why the model is wrong. It's not it's not as easy right? That that needs a little bit more work. But I would say this will be our next frontier is where we can give general purpose insights about any data set and don't trade stories out of and help people, you know, understand the data and not just make good models. 

Sanyam Bhutani  55:05  
Yep. 

Dr. Arno Candel  55:06  
Yeah.

Sanyam Bhutani  55:07  
Now coming to Kaggle your competitions Master, could you tell us what made you sign up for your first competition? And how did you get started on Kaggle?

Dr. Arno Candel  55:16  
There I was when I joined h2o actually, what I do is the company is actually called so when I joined the road, a few data scientists in the company very early days and and she has telling me like, why don't you go and Kaggle and see if it works, right. And I'm going to turn it out to some competition. And I basically started doing HTML models on Kaggle. And, and then that's how we met Mark Landry because he was not yet a digital. He basically joined, he saw that I was at H2O, I was writing these algorithms that he liked to use right because he he was an is an R user and we started to an R algorithms in the in the early days and not Python yet. But now we have both on we get back to those all R. And these are algorithms are so powerful that they would be much faster than the built in GPS. Let's say your bar is HTML gpms faster. So my granddaddy was a really good data scientist at a different company, and he used this h2o GBM and said, oh, wow, this is cool. They are know, since you made this, they want to work with me to get a mechanical problem. Right. And only a few weeks later, he was on our Kaggle Grand  Master panel in 2014, first H2O World. And then he joined us actually, right as as one of the first data scientists, actually no really good data scientist. And and he made he's now a Grand Master. But he also was a master back then. And he made me a Master actually, when we joined up together. So thanks to him, I became a Master because he gave me some good insights and showed me what's possible outside of just fitting an algorithm, right. He was the one that understood the data, and I was the one who just understood the algorithm and I, I fit it well, but the data was bad, basically. And he made the data. And then he fitted on it with a good model together that was powerful. So that gave me the insights that something like driverless was necessary. 

Sanyam Bhutani  57:17  
Can you;

Dr. Arno Candel  57:18  
He was the guy who made;

Sanyam Bhutani  57:21  
So you've also competed both solo and in teams with Mark Landry and others: Can you talk about the experience of teaming up with them on Kaggle versus teaming up with the Grand Masters at h2o.ai?

Dr. Arno Candel  57:37  
Yes, yes. So teaming up with the Grand Masters at the workplace obviously, is a privilege that not many have to that extent. And that's really amazing to you can you can basically see their creativity and their their insights, whatever code they deliver is usually very accurate and very useful. And I would say I don't get enough of the Kaggle secrets from them, yet. Something that's missing I that they're not sharing all the secrets that they still want to win in Kaggle. And if you fall into drivers right away, they're not here to slide, but I'm not quite sure that's really true. I think they're, they're giving us all the generalizable things. And then the specific insights for specific problems. Sometimes I like left on the table. And sometimes by talking to them, we can brainstorm and I have ideas, they have ideas and we swing them around. But then in the end, nothing gets implemented because it doesn't quite fit the framework or it's, it's overly too much, right. It's like it's a crazy feature somewhere that only is useful in like 1000s of cases. It might not be worth it, but it's still a good, good ??? experiment how to do something with a given problem. And I think that's what I enjoy the most is this ping pong ping of ideas and I would say at Kaggle I don't know do many joint team efforts anymore usually do it solo because I want to just see if I can do it. But I did one with John, he was a really good engineer at h2o.ai and who's one of the main committees of driverless AI as well as the repair program almost every day. And John and I teamed up for this, this IEEE fraud problem that just finished and now driverless with just two extra features in the beginning ends up and 14th place out of [total]

Sanyam Bhutani  59:28  
Wow.

Dr. Arno Candel  59:28  
It is pretty useful. So we basically learned a lot after spending a few days on that Kaggle problem. So I think teaming up is a good idea. But I don't have enough time to actually do them service, right? I can't lease the Grand Masters reputation by sitting on their team and not two months on it. So since I only have a few days for competition, if at all, I would say they're better off on their own. And I I would have liked to know what they're doing at least not sharing because that's against the rules.

Sanyam Bhutani  1:00:05  
Can you talk more about, broadly speaking, how Kaggle has affected your professional life? If I may, because we constantly you in submit to Kaggle, we have driverlesss AI and you do, not often but still submit to Kaggle, I believe. 

Dr. Arno Candel  1:00:22  
Yeah, yeah, let's say it's a very good benchmark, right, because the overall quality of the data is quite high, even though there are some leaks from time to time, but the data sets are ready to be run on. And if you take 10 data sets and just run it against it, and you see how we doing on it, that's a good measurement stick. And I think that's probably the biggest value that we get from from Kaggle is the crowd sourced opinion of what's possible compared to driverless AI, right. And if we can do well against the sheer mass of brute force attacks in the world, then that means you're actually good in it. You have refresh data set from a customer. And they say they get point eight, driverless gets also point eight, then that doesn't mean anything right? That doesn't mean that they're good or they're good or that we both bad doesn't mean anything because someone else could have gotten by .9 or .7. And depending on the metric, you don't even know if that's good or bad, like it's all open. But if you have Kaggle competition for two months, and you get to that point, you know, that's, that's pretty good, right? So I would say, just the sheer crowd sourcing of ideas, to milk, every last bit of juice is something that keeps us a good or a better benchmark than just one company's internal ideas. Let's see. Some companies depend on their models to be accurate. So if you are a fraud prevention team at the large bank, you probably have a good model too right. Yeah, but they won't give us that data. So Kagglers, they actually do give us the data. I would say that's there's already two benefits, right? You have access to data and you have access to the crowdsource.

Sanyam Bhutani  1:02:08  
So speaking in terms of company, I believe you're one of the very few Fortune magazine recognized Big Data stars. But aside from that, one of the very few great software engineers also happening to be a data scientist, if I may. What are your thoughts about where should we draw the line for thinking in terms of individual practitioners? how good of a software engineer should I be when I'm working on data science practices because there's some overlap but data scientists aren't recognized for the best software engineering practices most of the time.

Dr. Arno Candel  1:02:41  
I would say if you want to be a better data scientist try to become a better programmer first a better software engineer because it is silly to rewrite for loop that does cross validation over and over right for every single competition. Copy Paste, 1000 things over and over. So it's better to write a library that kind of works, and then just use it, it's a lot more time saving, if you trust it. If you don't trust it, then you should worry about what you did. Basically, why did you do that? If it's not trustworthy? So I would say, the like asking yourself critically is kind of being a software engineer, right? Because if you're a real software engineer, you have to test your code. And that means you have to question yourself, yes, it could work. And once you do that, then that's a good foundation for being a data scientist. You have to be a good software engineer to be a good data science, I would say, unless you're, let's say, able to just juggle a lot of balls and try all these open source frameworks. But even then you have to copy paste code or something, you have to have a lot of time if you're a bad software engineer. Save some time I would say so if you want to be an efficient, good software, good data scientist and you should be a good software engineer.

Sanyam Bhutani  1:04:01  
That's great advice. Do you think driverless AI can help someone become a comp- competition Master  or Grand Master?

Dr. Arno Candel  1:04:08  
Absolutely. If you follow what driverless does, you're at a good starting point.

Sanyam Bhutani  1:04:15  
This has been a great interview, my final question to you would be what best advice do you have for someone for who's just getting started with Kaggle? Or machine learning data science, broadly speaking?

Dr. Arno Candel  1:04:27  
Well, if you're on Kaggle, that's already good. If you're not on Kaggle, then try to get on Kaggle. That's always my advice. But I would say in general, probably think more about the setup, than about the number that you're getting right, think more about, think as if you are the algorithm, what data is given to you? What do you see? And then think again, and then think again? Like what actually are you getting? Gonna get the what are the features? What are the meanings of the features? Oh, you're getting the answer from tomorrow. Well, that's not what you really would get in production, right? So you have to think about it. You should only get stuff that's available at training time. And then also test time, you should think about that kind of stuff. And what does it mean? You do cross validation? Does it really mean that each split is somehow, you know, given to you. In what sense? Like, is it? Is it over time? Or is it random shop for the stratified? Or is it certified by city or by you know, ID or by age groups? Or how do you want to split the data and sometimes just splitting the data that it really makes a huge difference to the outcome, right? Imagine if you have pictures of the same people, and then use a random respect to data set. That's a Kaggle distracted drivers problem for all state. You make huge mistakes if you just do a random split, right. And I would say, just trying to learn about those kinds of issues is the first step I would do if I had to do it all over again.

Sanyam Bhutani  1:05:56  
Learn how to think as a data scientist before you work as a data scientist.

Dr. Arno Candel  1:06:00  
Yes, that's the hard part, right? How can you like you need to be careful not to make these mistakes, but most likely, you should make those mistakes first. So do some Kaggle problems. But I would say the best thing you can do is take 10 old Kaggle problems and just try one per day or two weeks or something, and then see how you're doing right and then read the winners posts. And then like, think about it for the next two years, by ??????? your model still make all the mistakes again, use these tools to make you a better scientist.

Sanyam Bhutani  1:06:35  
That's great advice

Dr. Arno Candel  1:06:36  
???? is like yours, right? All your podcast you probably know a lot more. So I would say it's good to learn from others.

Sanyam Bhutani  1:06:45  
Thanks for that great advice before we end the call, what would be the best platforms to follow you?

Dr. Arno Candel  1:06:50  
Oh, I would say Twitter. LinkedIn is a little bit more slow. Let's say I just stick to Twitter, Okay, sometimes you get my personal opinions as well.

Sanyam Bhutani  1:07:04  
We'll have both of them linked in case you all want to follow Arno. Thank you so much, Arno again for joining me on the podcast and all of your contribution.

Sanyam Bhutani  1:07:19  
Thank you so much for listening to this episode. If you enjoyed the show, please be sure to give it a review or feel free to shoot me a message. You can find all of the social media links in the description. If you like the show, please subscribe and tune in each week to "Chai Time Data Science".

