Sanyam Bhutani  0:13  
Hey, this is Sanyam Bhutani and you're listening to "Chai Time Data Science", a podcast for data science enthusiasts, where I interview practitioners, researchers, and Kagglers about their journey, experience, and talk all things about data science.

Sanyam Bhutani  0:47  
Hello, and welcome to another episode of the "Chai Time Data Science" show. I have to say I'm really honored to be interviewing Dr. Marc Lanctot in this episode who is research scientist at DeepMind and also one of the contributors of AlphaGo. Marc has done a PhD in computer science with a focus on sampling algorithms for equilibrium computation and decision making in games. And his current research interests include general multi agent learning and planning, computational game theory, reinforcement learning, and game research. In this interview, we talked about deep learning, research, and alpha go research at deep mind as well as about the open spiel project, which is a framework for reinforcement, reinforcement learning in games. We also talked about all about swift for TensorFlow and the promise it holds. I'm really grateful to mark who is kind enough to do this interview and share many great advice as well. I hope you enjoyed this conversation as much as I did. And if you'd like to know more about swift for TensorFlow, there's another episode that has been released about so for TensorFlow. So do check that out if you're interested for now here's the interview. Please enjoy the show.

Sanyam Bhutani  2:16  
Hi, everyone. It's an absolute honor for me to have Dr. Marc Lanctot on the show, Dr. Marc Lanctot, who is a research scientist at one of the world's best, if not the best research institute DeepMind. And thank you so much, Dr. Marc, for joining me on the interview series.

Dr. Marc Lanctot  2:34  
Yeah, no problem. Thanks for having me. I'm super happy to do this.

Sanyam Bhutani  2:37  
It's an absolute honor to have you. So are you currently a research scientist at DeepMind and you've picked if I may, traditional path in the research community? Could you tell us what got you interested in? broadly speaking, machine learning and AI and what made you pick up this as a career path for yourself?

Dr. Marc Lanctot  2:59  
Yeah, simply games, I'm very games focused person. I've always really been interested in games from the start, like an early age, I was interested in games and the Commodore 64 played a lot of games. And naturally, I was curious about, you know, how do you implement these games. So I became interested in programming from an early age, and I played a lot of games, starting, of course, with video games. But then as I got older, like, looking into other kinds of forms of games, so like, you know, role playing games and, you know, collectible card games and board games and all kinds of games. I think one of the main things that got me interested in artificial intelligence general is, you know, playing against these computer programs when I was younger, and wondering how are they making those decisions? Right. So like in chess, you know, playing against a chess computer chess program. How what's going on in the background there? How is it possibly deciding to move this on here? Yeah, just getting really curious about that from like a really young age, you know, before I learned anything about computers officially, I was already starting to think about that. And I think, you know, working with these playing with these computers and seeing what they could do, I thought to myself, wow, if they can do something as you know, as amazing as beat me a chess and this is, you know, there's, this is quite amazing. So I just naturally got interested that way.

Sanyam Bhutani  4:29  
What was your favorite game? Maybe for today and of all time;

Dr. Marc Lanctot  4:35  
Favorite game of all time? I would say there's, there's really three that kind of tie in for me in a category. [Okay] So, Magic the Gathering, I think was probably the one that I played the most. [Okay] I think if I had to choose one, I would choose that one, mainly because it was the one that I really spent the most time playing and I really, it's kind of at the intersection of board games. And, you know, fantasy style playing games, which I've played a lot of. So Dungeons and Dragons is my other one. It's one of the other top three. And I think I have to choose a board game. I think Diplomacy is really nice.

Sanyam Bhutani  5:12  
Got it. I'd also love to know, so you actually ended up in the research part? What made you pick research over industry as we call it?

Dr. Marc Lanctot  5:23  
I think so. I think I was naturally just interested in the question of why. So, I just needed to know the answers. It was I think that's what really drove me towards towards research I did. I didn't actually think I was going to end up in research. When I was younger. I think I was going to do something more related to like, developing games, because I was so you know, interested in games. And I think what happened was through just having to know the answer why, you know, I was when I was young, I really I was one of these kids who asked why why why all the time, and it was never satisfied. So this is a continuation of that.

Sanyam Bhutani  6:13  
Ask these questions, so it's it's definitely a continuation.

Dr. Marc Lanctot  6:17  
Yeah. And and it's just a naturally gravitate when I mean, when I found out that I could mix my interests with games, and artificial intelligence, and the pursuit, you know, of knowledge and, you know, artificial general intelligence more broadly. I thought, wow, that's something I I would really like to do.

Sanyam Bhutani  6:36  
Did you also end up programming any game or did you want to do that just out of all;

Dr. Marc Lanctot  6:42  
I mean, I've programmed a lot of games. I haven't programmed any games that got shipped. So I I but I've done a lot of games myself. So before, I mean, in high school, before anybody was learning anything about programming, I was actually developing games just on my own, because that's what I was interested in. [Wow okay] And so you know how to develop a chess program and how to develop, you know, into programs where you can walk through rooms and open doors and these kind of things and pick up keys. And, you know, that's the kind of thing that was always.

Sanyam Bhutani  7:17  
This was the pre databasing very, very cool graphics era.

Dr. Marc Lanctot  7:22  
Yeah, very much the pre very, very cool graphics, because I actually, you know, one of my favorite games is, was released on the TV. It was called Advanced Dungeons and Dragons treasure of terman. And this is actually a 3d perspective game. That was released very early. Before before yeah, before Nintendo.

Sanyam Bhutani  7:46  
Sorry, that that would be before I was born there.

Dr. Marc Lanctot  7:49  
Oh, yeah, it's very good. So, you know, when, when the research was coming out on deep reinforcement learning and it used Atari, as as the games as the platform for which was winning games and its policies and I that really that that I could relate to that in a way, because I played a lot of those same games, so a lot of the Commodore 64 games and early platformer games are still like Montezuma's revenge, for example, so when I watch an AI playing Montezuma's revenge, I could say, wow, I played that game. I know how to play it and I can completely relate to what it's learning because I learned that when I was younger so so yeah, it was it was really those early games that got me started and I think like the whole story was deep reinforcement learning stories there were like, you know, general game playing and Atari. I think it's just WOW!

Sanyam Bhutani  8:44  
Got it. That's that's an amazing story coming to what you're doing currently. You are at DeepMind, which I'm sure all of the listeners are familiar with. Could you tell us what does a day in the life of a research scientist at DeepMind look like? How is it different maybe your water cooler conversations complex math differential equations.

Dr. Marc Lanctot  9:03  
Yeah, so some of them are some nice so welcome to the amazingly comfortable environment. So we get to do like a lot of it, I feel like it's just a continuation of my PhD but like, just surrounded by, you know, an amazing group of people that I get to have conversations with on an everyday basis. So I, I work I collaborate a lot with, with London and Paris. So I'm in I'm in Deepmind, which is an Edmonton so it's a seven hour time difference between London and Paris. So I have a kind of an interesting workflow, which is you know, I wake up I wake up in the morning and I'm already starting to think of, you know, can I contact people who are you know, during their, in their work hour day that I can get like, you know, an answer back from them, you know, before I get to work and then I can start thinking about problems, but I mean, the the environment is really, it is really amazing. So like a lunchtime conversation you asked about water cooler, water cooler. I think really the setup, one of the really nice benefits and setups about the our work environment is is it has always been modeled around, you know, the ideas come from the really a bunch of putting a bunch of passionate people into our lunchroom having lunch and talking about ideas. And really a lot of our ideas come that way. Not always, they're not always intricate or complicated, right or or complex, like the first time they come around. You know, some of the ideas are really, you know, have formed, you know, oh, I had this idea. This, like, why, you know, I read in this paper that, you know, it takes like certain approach, why can't we do it this way, right? And then, you know, three or four people respond to that. And a lot of ideas are born from the fact that you know, that conversation that conversation itself has shed light on the idea that that person hand, and then they go back, they take that feedback. And they that's sort of what fuels their passion towards working on that.

Sanyam Bhutani  11:08  
Got it. So what does a resource pipeline for you look like? do get these ideas doing these discussions, maybe while reading a paper? And how do you approach a new idea once you have a good foundation or theory in your mind?

Dr. Marc Lanctot  11:23  
Yeah, so it all starts with, like the hypothesis and for me, it's a lot of like incremental improvement. So you know, really where I want to get to is solving the large problems, the general problems. You know, that's why I really like the kind of style problems that we work on the deep mind which is about you know, generalizing it's artificial general intelligence or really generalizing across different domains. Right. So Atari really appealed to me and now we're doing this in 3d worlds. And, and, you know, I think, you know, the games are no exception to this. You can you can think of developing artificial intelligence. For a, for a general setting, right. And one thing I mentioned was this incremental improvement. The way I approach researches, I kind of I'm like, constantly self critical. So I, you know, when we, when we put out a body of work, we have an idea. And of course, we're very ambitious, and we want to, you know, solve everything all at once. But, you know, then we think about it, and we're like, we realized, you know, that's not going to be as easy as it sounds right? Or as I'd like it to be. So we go to, you know, we go to try, we just, we try a small versions of it just to test some of the hypotheses right. At the end of the day, once we've done enough sort of iterations on it, at the end of the day, we believe we have like a solid piece of, you know, research work that we can go and put forward.

Sanyam Bhutani  12:53  
So essentially a baseline for for your project or idea.

Dr. Marc Lanctot  12:57  
Yeah, like a little. I mean, this is the way I think do it, we, I have a concept, I have an idea. And the idea sounds hard, right. So, and I can answer the question of Will this work right? Or will this work at scale? What I can answer are smaller questions like, if I develop a small enough environment that I can just quickly test on, just to test a few, like, you know, if this big hypothesis has any merit, then at the very least that should can satisfy condition, you know, x y&z and I can test those out in a small environment and then it can I can get a green light for myself right and decided, okay, it's acting the way I expect. That means there's some potential here. Now, let's just go, you know, let's go forward with this and push it, try and push it up [Got it] and, and eventually that process kind of leads to not just collaborations but like a bigger you end up tackling bigger problems by sort of kiff carefully identifying your own hypotheses along the way and your own and learning constraints, right. So things you didn't think about will come into play. And you know, the results will, will follow that. Oh, you know, that's not quite what I expected on I have to read, I have to think about this. And I think, I guess I'm trying to give this example as a nice depiction of what my entire research career looks like. Because one, you know, what we do is, so we take something that we're happy with, we bundle it up, and we, I don't know, presented somewhere, write a paper about it something. But at the end of the day, it you know, you have to have made some form of like restrictions or environment, you know, constraints so that you can make progress. And, for me, what drives me is undoing those constraints over time. So, quarter, you know, if you, if I've made a bunch of constraints to say, look, we have to get somewhere we have to just, you know, we, you know, we can't just follow it all at once. In a day, exactly. It's very, very incremental. And so when I say I'm self critical, I look back at my own things that I've written things that I've presented internally. And I say, okay, you know, this was nice, but there's this asterisk that I kind of want to get rid of, right? You know, we've made these kind of assumptions, and I want to undo those costs slowly over time. And the whole reason for that, is that over time, we're just making our algorithms better and better. we're dropping our assumptions. We're making everything more general. And, you know, that was the story with with you know, my involvement with AlphaGo and then AlphaZero and AlphaZero, right. It was it was really like that, you know, AlphaGo started. And, you know, we, we looked, we looked at one game, right. And, you know, we use a database of, of moves, theaters, you know, start the supervised learning, start the policy from supervised learning, and then it was like, That wasn't, you know, we question to ourselves, right? Like was can we get rid of those expert demonstrations? 

Sanyam Bhutani  16:06  
Removing step by step again 

Dr. Marc Lanctot  16:08  
Exactly right. And it turns out like, yes. And it's like, wow, that's amazing. Okay. Could we do other games? Yeah. So you know, challenging ourselves just, like incrementally over time and just striving to get more and more general.

Sanyam Bhutani  16:28  
And I have a request please don't become superhuman at Counter Strike. That's one game that I really enjoy playing. And I'd be I really hate to be beaten completely by a computer program.

Dr. Marc Lanctot  16:43  
It's, yeah. That's a lot of what I think. Yeah, it's a really interesting dynamic right when you're when you're first beaten by an AI. [Yeah] Because you know, you have mixed feelings about this, right. So like, I gave the example of chess when you play a chess game, and you get beaten by a chess AI, and you realize I'm not as smart as this thing, right? And then later on in life, I found out what minimax was and what heuristic search was. And I realized, and there was something just unsatisfying about, you know, how the computer BB, right because it was exactly it was somebody else who put heuristic knowledge into this program with with a good search algorithm. And I thought, oh, that's it. I was really amazed by the fact that a computer beat me a chess, but it didn't learn to beat me a chess champion, my thought about a lot more possibilities than I can keep in my head. And as a result of that, and being in chess, right, and I think that's really where I got started, which is, you know, I want to I want a learning algorithm to learn from scratch. How to beat me at chess was not enough to beat me up chess with many maxon heuristic?

Sanyam Bhutani  18:07  
What what's your take on maybe like the motivational or the emotional aspect of getting beaten by a computer program. So you also worked at Ubisoft, which is a major major gaming studio for those who aren't familiar. Or if you could give us some insight information, maybe Demis played with the test program, and if he was beaten, what was his reaction with it?

Dr. Marc Lanctot  18:32  
So so amazingly, I've never actually seen Demis play the the program, but I would say it's very unlikely that he didn't play it. I the funny part was with me and my interaction with the AlphaGo project was, I am not a goal player. And it was a new experience for me to work on artificial intelligence on a game that I was not familiar with. So and you know, I did the best that I could to try and learn to play go, but even then it was making moves that were far beyond my level of comprehension of the game. So, you know, I, I could never play it. Because there was no, I didn't understand enough about the conventions of the game about how to play styles. And yeah, so I found that dynamic kind of interesting.

Sanyam Bhutani  19:27  
I think that's also one of the challenges that DeepMind took up because go is one of those beautiful, wonderful games that has so many complexities. So that also speaks to;

Dr. Marc Lanctot  19:39  
Yeah, yeah, exactly. Like, I could relate to, you know, when, when we were watching the games, you know, I could relate to people surprising reaction towards, you know, how that, you know, the moves that were being made, because, you know, that's how I would debug my say implementations of Monte Carlo Tree Search, right? I would play it on a team. And I would put it in situations where, okay, well, clearly it has to do this. Otherwise, there's a buck. And like that would that that part of it wasn't so easy for me when we were when we were using go, but I mean, I learned a lot about go in the process. And it was, yeah, I really wish I had been able to, you know, follow everything from the start having, you know, been more of an expert in the game, but I can completely relate to when people were seeing the things it was doing, and being surprised by it. And, yeah, that that part, that part is game independent, like it was just, you know, when you're surprised when you're looking at something, you're looking at a system that you've built, that can completely just, you know, completely learned from scratch a new way of playing right. That was the You know that, like, people have played these games for thousands of years, nobody would predict that it would make a move, you know, number 37. And, you know, people call it this creative movement, I can, you know, I can completely see that. And I mean, that was just incredible. You know, it was creative.

Sanyam Bhutani  21:20  
Yep. So, would you think of this as a creative way? Or would you in hindsight, would you have anticipated this that this would, this is totally possible.

Dr. Marc Lanctot  21:30  
So I definitely would not have anticipated things like that, you know, completely new ways of playing because you think when, you know, people have these conventions in these sort of adopted protocols, right? In certain games, like a years, because people study these for years, right? So here's a here's a, here's a chess book, you read it and you if you're in this situation, this is the right move. So you would think through self play, you would encounter like a lot of the moves that You know, traditionally have been reached through.

Sanyam Bhutani  22:03  
Model was trained on these moves. So this would have been a rare occurrence and most of the cases, I believe.

Dr. Marc Lanctot  22:09  
Yeah, that's right. So but then there's the self play element that happens after that now you just let now that's where that's where things get really interesting, right? Because you are now your teacher almost starting to your teaching this things through human made moves. It's acquiring the knowledge of go through supervised learning. And then you let, and I think that's, you know, self play reinforcement learning in games. And you know, that whole the whole story with the sorrow and backgammon when I was in my undergrad and learning all this, that that fueled me, like, I thought to myself, I want to do that. Because I wanted to see this happen. I wanted to see the thing learn on its own, in a way that, like we, you know, maybe wouldn't have anticipated and so I don't like I will would have expected. The reason I, I would have expected it to learn a lot of the conventional moves is because it would have went into you know, those positions that were well studied through self play. The the other thing, like after, you know, having thought about it for a while, if you look at it now we're combining techniques that had never been used before. So we're taking deep learning, as function approximator is to evaluate, to use as an evaluation function. We're training them using self play reinforcement learning enhanced with Monte Carlo Tree Search. Right. So that had never been done before. [Yeah] So, you know, you can argue that, okay, well, in retrospect, if you're combining these new methods and learning how to play in a completely different way, maybe it can discover these entirely new strategies that you, you know, didn't anticipate. Now, that's not something I would have, right that I would have thought of ahead of time. But I think it's really this idea of These two technologies that we've, we've put together that have just blown me away over the years that kind of like, are leading to this new kind of artificial intelligence that we're seeing now.

Sanyam Bhutani  24:13  
Yep. So one question that comes to my mind is, there's always this aspect that should I continue exploring this idea because at the time, no one had done this combination of techniques, even though now sounds very familiar. We also have a Netflix movie that explains it very nicely. But so how do you decide if you want to stay obsessed with the idea continue exploring or maybe it's not worth it? You'd like to end the experiment there. How do you decide on that?

Dr. Marc Lanctot  24:39  
Oh, yeah, that's, that's very dependent, I think on the individual and how, how persistent and how, you know how much they get stuck on one particular problem. So for and this has happened to me oftentimes. So there's, there's a kind of problems that I really get stuck on. And if I have a hip hop says that I know must, must must be true, or I have no reason to think otherwise. And I'm running results and I'm not getting what I expect. I might spend, you know, days to kind of just, I need to understand. There's there's there's a gap in my understanding here and I just need to push myself enough to understand what's happening. And so of course, there's a trade off there between how much time you spend trying to figure out what's going on and why your your intuitions don't match.

Sanyam Bhutani  25:35  
Things don't work at all until they do so.

Dr. Marc Lanctot  25:38  
Oh, yeah. Oh, yeah. I mean, yeah, exactly. And, I mean, that that's research and, and, you know, I can relate to a lot of these times where you could spend, you know, more amount of time than you would like, and at the end, you don't get a satisfying answer. So, but it's a real trade off. So some problems I've gone off and done, you know, spent a lot of time because I was really bothered by the fact that I couldn't answer the question. And, you know, a lot of those times I've come up with an answer that felt satisfied. And there's sometimes I had to say, look, you know, I've spent a lot of time on this, I need to shelve it for now. But it's still kind of at the back of my head. And, you know, maybe I'll come back to it at some point through another means, and that comes sometimes happens. So, yeah, it's really a mix. And that depends really on the person and how the kind of problems we're working on to like there's kinds of problems that lead to those dead ends more than others. And you have to be, you know, you have to be conscious of what you're getting yourself into.

Sanyam Bhutani  26:47  
For you is it a parallel set of ideas that you're working on? Or do you zero down on just one single zone or domain like you're working on?

Dr. Marc Lanctot  26:56  
I zoom in and out regularly different rates. And I always have, I always have a list of ideas. And and the group, you know, whatever group project we're working on, I think that's also true. There's always sort of a list of, we would like to do all these things. But you know, at the, we have to choose what's most important and, and push on that. And it's, it's a, it's a dynamic between yourself and between the people you're working with, right? So there's a project and you want to make progress. You may, you know, you have to make sure that you're working enough on like you're contributing to the, to that project so that the program can move forward. And at the same time, you have to give yourself enough time to like get away from the project, just for small amounts of time so that you can work on like, things that are still, you know, that could still be related to the project, but sort of items that you can never have them. So it's it's yeah, this is something that like a lot of different researchers do different at different levels of abstraction. And I think it's a matter of, I think I've switched on how I handle this over time. So now I kind of keep like a to do list, right? And I just check it over. Like I check it frequently and asked myself, am I doing enough on these students are progressing? Or am I spending, you know, too much time on one thing, and then you just make sure that you;

Sanyam Bhutani  28:25  
But once you maybe think of an idea for and fail experiment, you might even go back to it and again, give it another try?

Dr. Marc Lanctot  28:32  
Yeah. And you have to just be careful that you don't switch context too much, right? Because there's a cost to switching back and forth all the time. And you just, that also is not satisfying because you can make just incremental progress on like many projects, but then at the end of the day, you know, you're not pushing each one enough. Or it's kind of you have there's a balance you can it takes a bit of training right. And and I think that just you get People sort of figure out what that balances what what's best for them over time. 

Sanyam Bhutani  29:03  
Yep. Switching context now back to AlphaGo and AlphaGo zero. So I actually tried to watch the movie again twice as a fan moment, and I couldn't find you in the movie. So are you in a Netflix movie or not? 

Dr. Marc Lanctot  29:17  
I was in a Netflix movie for about half a second. [Okay] I'm, yeah, I teach I have you. It's, I think the camera has its back to when I'm teaching a good friend of mine, Mark Bellemare about something interesting. I remember. 

Sanyam Bhutani  29:35  
I think it's on a glass panel, if I remember correctly, was that you?

Dr. Marc Lanctot  29:40  
No, it wasn't me. It was on a it was on a whiteboard. [Okay] There were several shots on it. I thought there might have been more than one shot, to be honest. But I don't I don't quite remember. I think the the one really obvious one that where I noticed was I was teaching I was teaching a colleague on the whiteboard, but it was really just this snippet shot so [Okay] I'm not on IMDB or anything.

Sanyam Bhutani  30:08  
The coming coming back to the research aspect of it did you anticipated to get to the superhuman level that it is now and once you got involved in the team, could you tell us what led you to it and what parts of the results were you working on?

Dr. Marc Lanctot  30:27  
Yeah, so when they started working on this, I you know, I, I didn't, I was still a bit of a newcomer to depart on myself. But the, like, the progress on Atari really blew me away. And so, it was interesting for me because I had, I knew we had a good combination of technologies. But I had also watched you know, the the go in the games community, actually try to crack go [Okay] for like, you know, 10 years before that. And so, you know, I knew that this was not going to be an easy problem.

Sanyam Bhutani  31:12  
Were you familiar with go before, I know you mentioned;

Dr. Marc Lanctot  31:14  
Oh I was familiar with yes. I mean, I was not I didn't really know how to play. I mean, I knew the very basic rules, but I wasn't good. Like, I didn't actually know how to play very well. But I knew like go was a was a game that, you know, after the test results in the late 90s. And people from IBM was that, you know, it was kind of the next game, right, like it was, well, you know, it was a hard game. I mean, I guess there were a few candidate next games, but one that was kind of embraced by the community was, was go after a few years, you know, sort of like mid 2000s. So I had been watching the games community try and practical and you know, Monte Carlo Tree Search was, you know, a big milestone in the, you know, approaching go. And, you know, seeing all that happen and realizing how hard go is that, you know, I knew that I can expect good things. I didn't realize how good things were going to it was going to get. And the new thing and the other thing was, you know, the deep the whole algorithm. It's very easy to like, if somebody were to pitch me that algorithm like at the time actually, I mean, this happened really, um, you know, and I'm like, I'm thinking to myself, oh, my goodness, why haven't we done this yet? Of course, this is going to work. But I really didn't know how well it was going to work. Yeah, so so seeing it all happen, I think was really was really, really amazing. I was mostly involved with I think you asked how I was involved. What I worked on. So the first AlphaGo I had I had come into the one with a lot of experiencing and some Monte Carlo Tree Search, not necessarily in go but in other games. And so we needed kind of like a distributed version of Monte Carlo Tree Search. So I worked on the like, initial prototype, distributed version of Monte Carlo Tree Search. And I forget what that third part of your question was. 

Sanyam Bhutani  33:35  
Uh, it was a, again, uh sorry. So once you got involved, how did you see the growth of the algorithm and;

Dr. Marc Lanctot  33:45  
Oh, yeah, yeah, I mentioned that like the oh, yeah. And that comes back to the kind of iterative improvement thing where I really enjoyed seeing the process. Go from AlphaGo to AlphaGo zero to AlphaZero. That just blew me away. In fact, like, I want to tell the story because I think it's something I'll never forget. I was in a meeting with with David Silver, and I was only sort of after AlphaGo I was involved with the the multi agent learning team. And so I came back to to alpha alpha zero after alpha zero, so I wasn't really a part of alpha sir. But I was kind of going to the meetings and, you know, watching all the progress, right. And I thought to myself, while they're removing the expert demonstrations, that's going to be hard. And then, like, it was crazy, because each week, we had a meeting where Dave was presenting an update on on alpha zero, and it was just getting better and better and when fine I had this meeting with Dave. Um, you know, when he he told me okay, you know, he, he they got they got to what they believe could be close to superhuman intelligence with no with no features with no expert features, no knowledge, I could not actually sit down. I was so excited by that, that I had to walk around the room and paced back and forth because it was mind blowing. I that that I'll never forget that to this day that that was something that really changed. Like how I thought about what I was going to do with the rest of my life because up to that point, I hadn't realized we were going to get this far this fast. And, yeah, that was just a very exciting time in my, my career.

Sanyam Bhutani  35:45  
I think it's still very beautiful. Now, in hindsight, we have this amazing blog posts all over the internet that explain it nicely, but if you do truly understand it, it's still mind blowing even in 2019 with all of the research.

Dr. Marc Lanctot  36:00  
Yeah, no, absolutely. It's still even hard to believe, like, you know, and when we did it on three different games, using, you know, the same hyper parameters like disbelief again after this. It's just incredible to see how like how far we've come I mean, then this goes back to exactly what got me into, you know, machine learning and research in general, right, that comes back to, I wanted to play against an algorithm that I can feel had learned from scratch. [Yeah] To play the game that I was playing. And that's really like what we had achieved right, like so yeah, exactly. I had to sit there and what now like we just achieved my childhood dream. Back to the drawing board.

Sanyam Bhutani  36:54  
Coming back to that, hat'sdefinitely amazing, coming back to when you were working on the problem I had, I'm also curious, how did you split the work between the team? How would the experiments distributed? For example, in engineering, you have the sprint planning to decide what to work on what not to work on? What did it look like with the size of;

Dr. Marc Lanctot  37:16  
So that that was, like, very organic. So, you know, we'd meet once a week, the whole team, look, maybe we would have small meetings individually, over over the week. And, you know, we put things on the board, and we decide on priorities, and we'd say, a lot of the A lot of what we did next, and how we shaped our work was based on, you know, the ideas that we had on how to like what we thought would push it forward the most.

Sanyam Bhutani  37:43  
And sorry was this a distributed team or all were in the same area, just out of curiosity.

Dr. Marc Lanctot  37:49  
The original I am talking about the AlphaGo in general or specifically?. So it was distributed from the start, but mostly so I think so Ilya Sutskever was also like involved in the first [Yeah] first meetings, he was always attending. So, but the three people I mean, most of the people were from DeepMind and Google mostly DeepMind actually. So you know David silver, Chris Madison you know, Arthur Guez, so the most of the composition of the team was was internal. So these;

Sanyam Bhutani  38:27  
Just because time zones out slight amount of annoyance to how do you set up the meetings and collaborate? 

Dr. Marc Lanctot  38:33  
Oh, yeah. I yeah, that it's, it's difficult with the video conference sometimes to to work on that. But I think we made it work. I mean, the team worked really well, via the GVC. So when you know anyone would come in, like, joining the meetings. It was it was easy enough to discuss the like the the details. Through GVC I think that were that worked fairly well. Most of the team kind of grew, there was a lot of people internally who joined the team after that. So like, I think I was maybe number five or six in the original AlphaGo. Team. And then it kind of grew grew after that. And yeah, at your home as well, right. So he was, he was in turn, you know, he would him and and Dave and Chris, kind of, you know, originally made like the first version of the, of the go program. And, and then it grew kind of after that, but we really, yeah, we stand, we stood around the room looking, writing up things to do, and kind of each deciding, okay, I'm most interested in that all going to go off and do that. And then a lot of the, it was a lot of progress driven, right. So it's like somebody would come report the results and say, oh, that's great. But you know, the networks taking too long. So can we have a smaller network and then we go off and try and make it small.

Sanyam Bhutani  40:00  
For you, I think your PhD research was also based on Monte Carlo Tree Search. So how much of a challenge was this for you? Because I think you took up the same problem for AlphaGo as well.

Dr. Marc Lanctot  40:13  
Sorry, I didn't hear the first part of the question.

Sanyam Bhutani  40:15  
So I'm sorry, your PhD focus was also around Monte Carlo;

Dr. Marc Lanctot  40:22  
Yeah, part of my PhD was Monte Carlo Tree Search. In fact, I didn't. I had kind of been just I would never say that I was like a, you know, a sort of a mainstream machine learning guy. I always kind of labeled the stuff that I was doing is machine learning, because it was kind of learning. I worked on two separate things. One of them was Monte Carlo Tree Search. And another one was Monte Carlo CFR so CFR is an algorithm that is used in the imperfect information games, like poker. So I had an interest in computational game theory, and in games themselves, so searching games, And computational game theory and algorithms for producing with Nash equilibrium. So I always felt close enough to the machine learning community that I would, you know, I would go to all the conferences, I loved machine learning from the start. I would say that I gained a lot of experience after talking to people and learning things from people at DeepMind. So, my thesis, I wouldn't, I would go back and say, you know, there's still I can still call that machine learning. But, you know, not the same kind of machine learning and doing.

Sanyam Bhutani  41:39  
Interesting. We talked about meeting so I was lucky enough to join one meeting. It's called Open design meeting by the swift for TensorFlow team, where you present it open shield, we'll talk about open shield, but maybe to help us set the stage. Could you tell us what in your opinion is swift for TensorFlow all about and what do you is promising about it?

Dr. Marc Lanctot  42:01  
Yeah, so swift for TensorFlow, I'm entirely new to and I should put a disclaimer that I'm I don't know much about swift for TensorFlow, but I can I've been talking to Brennan Setta, one of the leads of swift for TensorFlow, who became interested in open shield through it like a mutual contact. And so I can tell you a little bit about what he's told me and sort of, like what the, what the promising parts of swift for TensorFlow is. So the idea, as I understand it, is to have one language where you can interact with TensorFlow. And if there's any use cases where like so, for example, in open school, we have a mix of C++ and Python. And there are you there are times where that's required, right, if you need really fast search, so like Monte Carlo Tree Search, you might want to do this in C++, rather than in Python, that now requires mixing two languages. So that's uncomfortable sometimes right? And you know, can lead to a whole set of other problems,

Sanyam Bhutani  43:08  
Frameworks, but I'm sure the developers had to go through some heroic efforts to just to prepare the API like that.

Dr. Marc Lanctot  43:17  
Oh, yeah. I've sat in on a few of their meetings. And you know, I have to admit, I mostly don't know what's going on, like when they talk about compiler internals. And you know, how the scenes like Yeah, cool. That's that's magic. So, yeah. And so the idea would be that the idea behind swift for TensorFlow, as I understand it, is that you want a fast language, right? So you want to avoid the latency of your host language, like your sort of your primary language, so that you can avoid switching back and forth between, say a compile time language that runs really quickly. And, yeah, swift lets you do that, because you can code in swift, you know, which is fast and you can directly interface with, with TensorFlow without paying as much of the latency, for example, as Python but, yeah, I mean, I just want to clarify again, like, that's my surface level understanding of it. [Yeah] You know, I don't know all the details, but that's sort of what I understood from the conversations.

Sanyam Bhutani  44:29  
Got it. I think it's also to me even as a computer science undergrad, so I've done my undergrad in computer science, but it is this language that is sort of everyone's favorite right now even to practicers who aren't coders, swift might create a challenge there because even to me, I would like all races in gold and everywhere.

Dr. Marc Lanctot  44:52  
Yes. So. So again, so an open shield for example, we have this mixture of languages again. In we decided to do that we decided to design the code that way for exactly. Well, for two reasons to be honest, the use case that I mentioned earlier where you might want to drop down to a fast language and do fast search, right? There's another piece of open shields, like another reason that we went with C++ as a core for the for the environments. And that's because what I think what we're trying to do with open shield is get we're trying to okay part of my mission with open shield is to to get to communities talking that don't always talk so like the computational game like games and search community and competition game theory community and, and the RL community and the machine learning community. And what I would like to be the case is that this one package that we're open sourcing can be used by both people by sorry by both communities. And you know, that leads to the potential to learn from each other. So you know, somebody who wants a fast search algorithm that's doing heuristic search in games use open shield for that, because they don't have to touch the Python side of the code. People who only want to do machine learning and reinforcement learning can entirely only use the Python silent code. So we it's almost like we have two versions and are mirrored, right. So we have implementations of algorithms and C++, that, you know, interact directly with the C++ API. But you can treat open shield as if it doesn't have any C++ in the background at all. Because you can just look at all the Python examples and just work with Python, we knew that this would be something that we needed to address ahead of time, because you know, not everybody's comfortable with hopping back and forth between two languages. We don't want to, but that's not an easy thing to do when you're trying to do research, and so we have these two branches, but we wanted to cater to both crowds. And so that's, this is sort of our compromised.

Sanyam Bhutani  46:59  
Got it. You maybe give us a 50 foot overview of open shield? And how is it the other thing that comes to mind and how's it different from open AI gym, as they call it and if you could also tell us is the swift for TensorFlow brands ready to use compared to the other ones?

Dr. Marc Lanctot  47:15  
Potential TensorFlow ventures ready to use it. It's smaller than the rest because it had comparatively less effort put towards it, but it's absolutely ready to use. It has a real implementations of, of algorithms that are in the main open schpeel. And it was actually really easy to do because swift for TensorFlow, while all the Python most of the Python implementations use TensorFlow, and so it was really easy to translate some of those algorithms straight to swift. The the overview of shield open shield really, the way I like to talk about it is I want it to be the Atari learning environment of multi agent. So what you know what did the Atari learning and do for us. It allow it, it allowed us to get one interface to several different types of tasks or environments or beams with a consistent API, or a consistent observation format. Right. So that I think that's really important for AGI right? Because we're, we're, we're tracking you know, we, we, what do we do we, we make, we decide on things based on what we see, right? 

Sanyam Bhutani  48:26  
Yeah.

Dr. Marc Lanctot  48:26  
Everything is through our eyes, we have a consistent portal to the world, or a consistent observation that we base our decision making on that was really important for the entire learning environments. Or sorry, that was something I think it was critical that the alternative learning environment had because now you can take algorithm and with one line, you can switch the environment that it's working on, right now you got but you all got it in, you know, a frame buffer that was consistently sized. [Okay] So I'm really interested Multi Agent RL, and games, you know, as I've said, and so I, but I'm also very much interested in this breadth style approach to, you know, having algorithms that are completely general. And so open shield was really about that taking a simple API for games. And, and giving it an allowing algorithms to interact with that general API. So that you can literally just switch one line and change games, right and make general assessments of your outcomes across domains. So that's what opens feels really intended for. Now, there's, there's so that said, answering the question of, you know, how does this relate to other RL API's? There's a few tricky things that you have to think about when you're when you're looking at multi Agent RL. And in games in particular and so for example, and they present a bigger problem than you would first expect. So for example, when you play a game, your action space is not consistent across states. So it could you could have a subset of legal and illegal whoops. So and that presents a bigger problem than you would expect. Because if you have an algorithm that is described, as assuming you can always take actions like zero to, you know, number of actions minus one, and then you arrive in a state where you don't have like only a subset of those actions are possible. This actually changes the algorithm in a very subtle and like on paper. It's a very minor change, do it. But if your API's are making those assumptions, it's sometimes hard to take, you know off the shelf RL algorithms, and modify them to account for those use cases. So like, legal moves, being a subset of the actions is one is one turn based games is another thing. So you know, a lot of people and the literature does this on multi agent RL starts with, you know, the assumption that agents are all acting at the same time. And so you know, but it's sometimes convenient to describe the algorithms on a turn based fashion. Right, a lot of the a lot of the algorithms I'm used to from my thesis and a computational game theory, community is all turn based. And so you know, there's a few little of these kind of seemingly very small things that get in the way when you need to apply algorithms on games, and that's why we have like a custom version of dq n in the repository because it has to be a dq and that's aware of these like, use cases that you encounter in games.

Sanyam Bhutani  51:50  
Got it. Coming to a hardware aspect of research. So this question also originates from Facebook's I think it's a Poker bot called Pluribus, what are your thoughts in terms of pushing research with limited hardware? Because RL is hardware demanding for maybe small labs or independent researchers who have limited hardware scale compared to DeepMind. Do you think innovations are still possible? And how can one think on these restrictions? or How should I think? 

Dr. Marc Lanctot  52:25  
I think it's very important to, like so sample complexity and the ability to do research on a small scale, I think is is is also important. We do we do a lot of kinds of research and at DeepMind like there's a there's a lot of people who care a lot about the foundations and, and, and sort of testing hypotheses in in like a, in a, an environment that's kind of easier to test hypotheses in you know, I think of things like the you know, the AI safety grid world says like a something that we open it I you know, those kind of packages I think are really important to look at the, like the foundations, and I don't think, I think I'll use an example. There's a paper that we there's a collaboration between brain and DeepMind, on proposing a challenge for a game called hanabi. And I think so in that paper, we, we talked about these different training regimes. And, you know, there's the unlimited, we call it unlimited data regime, which is, you know, you can interact with the environment as much as you want. And then you report your results, you know, based on the achievement or the, you know, the number of points that was able to collaborate with other players and learn at the end of you know, how many frames you got, but then we also oaid, Okay, let's think about another setting where you have a data limited regime, right where now you have a limit on A number of the on the yeah, the number of episodes that you can that you can use for compute compute, because those are two questions. Those are really two different questions. And I think answering those two questions like tackling both of those, I think is important. Like, you know, it has to be. I think so. So my opinion on this is, I think if you, if things are reported clearly, then we avoid the kind of problems with mix of like comparing apples to oranges, and that we have to be very careful with that in the way that we disseminate our research. And I think if we get that right, then it's perfectly fine to have these two regimes and then talk about them and compare results in the proper way.

Sanyam Bhutani  54:46  
Got it. So you mentioned and I think many people miss out on this, but DeepMind is also working on many amazing broad domains. AlphaGo zero is what gets most of the spotlight. Could you maybe talk about a few that you excited about? Maybe not as excited about the results from earlier, but some things are some upcoming results or current even that you excited about.

Dr. Marc Lanctot  55:08  
Yeah, so I mentioned that I was on the multi agent team before, like anything multigenic just really, really, really gets me excited. So, you know, when I think of artificial general intelligence, I can't really separate it from you know, the fact that from the multi agent problem that would be present, if you put you know, many of these agents together in a single, you know, in a single room and now they have to interact and you know, do they have to think about each other? Do they have to take into account how the rest of them are going to act on these things, these are very important problems that we, you know, should have answers for or should have, you know, should anticipate. So, you know, when we looked at, for example, capture the flag, I think that was one that project is really cool because it gets it gets out of my comfort zone in two ways. It's it's a very rich visual environments, right. And it's a 3d environments where you're acting so that already that's that's very hard. But the other thing is, it's it's not just the competitive environment, it's a cooperative one as well, right? Like you're acting with other team members. And you're trying to coordinate. So there's two, there's two multijet problems there, there's the cooperative one. And then there's the credit one. And I think what I mean, what I like about capture the flag is that, you know, you can watch these videos at the end, and you could, you know, you can attribute agency to these things and say, wow, they are cooperating, right. And they played against humans, the cooperative with humans like that, you know, the playing against or with your eyes, you know, brings a whole new level of excitement right to that. And I think I think what and one of the things I think that was quite nice about that research to was it was kind of trying to understand what the AI was thinking. Right. You know, when it saw the flag, say, oh, wow, the set of neurons fired. You know, these are the flag neurons. You know, you know, that kind of research I think is important to understand, like what our models are learning. Yeah, that's one example. I brought up hanabi earlier. And it is a really interesting game. It's a cooperative game. So I have like less experience with that. But it's a really, really unique game. Because it's a it's a cooperative card game, where you're trying to put down carbs in a certain order to achieve a certain number of points. And you're quite restricted on what you can say about your, you're not allowed to communicate freely. The only way that you can communicate with your partners, it's a cooperative game. So you're trying to you know, achieve the same goal, but it's imperfect information right? So you don't see your own cards you you you play with your cards and it's facing the other player, your your cards are facing the other players, so you can only determine what your cards are based on the hints that over other players I've given you what really makes it interesting to me is you have all players in these positions, all making inferences about the intentionality of their actions, right? So if I say, you know, the hits take the form, okay, you have, you know, a one here, one here, and one over here or you have a green card and a blue car, a green card here, here and here. 

Sanyam Bhutani  58:25  
Okay. 

Dr. Marc Lanctot  58:27  
And through those set of hints, you not only have to determine what cards you are will hard to have and what you've put them down. You kind of have to reason through why certain agents decided to tell you these things over other hints, and because that gives you more information. And so it's a very unique game that way, and playing playing well at hanabi requires you to think about you know how other agents are making decision. So I think that's a very unique domain as well. I like I really like, like I mentioned the the safety work, I think that's really important. And the adversarial examples. Sorry, the yeah, but that's but also the, the adversarial training, right. So as we learn models, we're learning mappings of observations to either actions or observations to classifications, right? Yep. And now, okay, when we poke at these observations that we sprinkle a few, you know, nasty pixels, right? Yeah. And suddenly all it thinks it's a banana or something. You know, that I think that's really cool, right? Because the more that we, the more that we're putting effort into these machine learning techniques. The more they're going to be used in practice, and then more important, like the it becomes more and more important to make sure these are robust to the kind of, you know, like, you know, tempering that people will do and of course, I think to make sure you can for that, keep that.

Sanyam Bhutani  1:00:01  
I think it could turn into a literal attack in the sense that if a cell ran car is driving across the road and someone loses those pixelated attacks, or another research paper that talked about how do you generate toxic comments from boat and similar models by again, address a dealer tag. So I imagine a tag board a service tag board, which faces in a tag and starts giving out aggressive comments is, again a possibility.

Dr. Marc Lanctot  1:00:29  
Yeah, it, it's, it's scary to think about, you know, the kind of things that this these technological technologies would be useful. And I think, understanding the foundations and how things like this could happen as a result of how we're mixing these algorithms together and kind of training with them. It's an important thing to keep in mind when these are getting deployed more and more,

Sanyam Bhutani  1:00:52  
Definitely. Yeah, talking about one thing that's pretty common nowadays is MOOC education. So David silver has this amazing reinforcement learning course as well. What advice would you have for someone who's seeking a path as a researcher, but is only MOOC educated? Also, do you think being having worked with David Silver is his knowledge in real life as rich as the MOOC or MOOCs? Maybe not, might not be the best resource.

Dr. Marc Lanctot  1:01:24  
No and we have, we have people also at University of Alberta, who just recently gave reinforcement learning MOOC as well. I think MOOC it I think MOOCs are great. I it's really great that we're, like, teaching people through, you know, entirely free or close to free, you know, resources, like, like, like MOOCs, so that a lot of these concepts and ideas become sort of like accessible to everyone. [Yeah] So I think I mean, I really think that's good. And I mean that I'm coming back over and over again. But, you know, open sourcing, and it's a lot of the same flavor. So I became interested in, in Linux and open source. And I thought, wow, this as soon as I understood what open source was, to me, that was just to me, it's just naturally the way forward. In fact, when I was learning computer programming, somebody was teaching me C. And they told me, you know, you know, you never show your source code to anybody, yours or it's sort of accepted. Like the, you know, your, your source code is kind of, like private. And this was, like, early 90s, when, you know, software was being developed and sold and, and, you know, open source was not really a thing, right. And, and my first reaction was really like, what, why would you do that? Because that would prevent sharing of like progress really. Like the first thing I wanted to do when I was you know, 12 or 13 was You know, write a piece of code, log into a BBS because you know, the the internet was still like around the corner. And and upload it. And hopefully somebody would download it and say hello, I use your program. It's really cool. And like I added this thing to it. And you know, I've, I couldn't really relate to the what they were telling me. So I think MOOCs are kind of like the the research and the teaching equivalent of that, right? It's just like, well, now we're going to take all of our expertise, we're going to teach it to like, basically everybody. And and we're going to, we're just going to make it all open. And I just think this is strictly bothered;

Sanyam Bhutani  1:03:39  
Any, sorry to interrupt. Any advice that you have for a person who's an aspiring researcher, but taking moved MOOC education, so what things should they keep in mind while going through that process?

Dr. Marc Lanctot  1:03:54  
Yeah, so I would say, become involved. Get it get surrounded by you know, People who have similar interests, you know, write on forums, like I read a lot of stuff on Reddit. Go on Twitter, like, you know, all these things are free. Just but the more you talk and ask questions, the more you communicate with the with people about your your interest in kind of pursued the, like the you know, once you've taken a course in a MOOC, you can go out there and just post questions and get feedback. One thing I like to encourage is, you know, workshops, I mean, you should feel you should go to the, you know, if you can go to a lot of the conferences and actually just just talk to like, as many researchers as you can. And I like to encourage workshops because I feel like workshops are really a nice way for people starting to get into the field to ask, you know, kind of, you know, it's a it's a place where, you know, constructive feedback is is highly encouraged. And it's it's a way to get some of your ideas out in the open and get real feedback from, you know, on a particular topic and you can meet other people. So I think, you know, networking networking is is is an important way to learn all kinds of things from from the community. And the conferences and workshops are just a great place to do it.

Sanyam Bhutani  1:05:33  
I'd also like to also giving a plug about a community that I'm active in but all of these courses also have now these amazing slack communities also the fastAI forums, for example, and in India, we am active in a community called Data Science network. For the listeners, please go to dsnet.org if you'd like to join. These are also places where beginners are welcome and these words Be the ideal this because everyone is also starting to learn not in terms of research, maybe but broadly speaking in terms of machine learning.

Dr. Marc Lanctot  1:06:08  
Right. And I would I would echo something I saw in one of your other podcasts, I think there was a, an answer, like, don't be afraid to ask questions. That that's very important. And I see I see a lot of questions on on the on the on Reddit, R reinforcement learning R machine learning, and the very basic questions and I there's nothing you know, there Don't be shy. I love answering those questions. Because, you know, I was there once and I just, you know, the you know, things like the difference between on policy and our policy. It took me a surprising amount of time to understand why the that subtlety it felt very subtle at the time when I was learning it. And, you know, I finally have a good understanding of it now. I you know, this question came up and I was able to communicate on the Reddit thread. I said, Look, this is why here's I think actually wasn't quite on policy or soft policy, but something like the bias variance trade off when you do bootstrapping versus just doing Monte Carlo. You know, and it took me a while to get that right. And I could explain, I felt like I could explain it in a way that was understandable, even to somebody who doesn't have like that much experience. And that was just fun. Like, I just actually just liked doing that. So won't be so please like don't yeah, don't be afraid to ask questions, go and join all the free source resources that we have available and ask questions and more who are really want to answer them.

Sanyam Bhutani  1:07:35  
This is another example a simple question as why does BatchNorm work also created this chain of research that has been still going on for this day?

Dr. Marc Lanctot  1:07:44  
Absolutely. There are going to be some very important questions that take some time to answer properly and lead to big research past. In fact, we've gotten a few of those in open field as well. You know, there was a few, there's somebody who's looking into an adapter for a general game system. [Okay] And we're, you know, we're, we're going back and forth and communicating. And there's a few questions that just completely didn't anticipate. And and I thought to myself, that's actually a bit of a research problem. So, you know that, that's great.

Sanyam Bhutani  1:08:21  
So, this, this was great advice. I'd also like to ask you one last question for beginners, broadly speaking, what best advice do you have for anyone who's starting out in machine learning or deep learning broadly speaking? What how should they get started on any best advice that you would have for them?

Dr. Marc Lanctot  1:08:40  
Yeah, go. So I would say a combination of two things. Go look at all the open code that is being put up there and play with it. And and be active about asking don't don't be scared to ask questions. You know, if, if there's something you don't understand, you know, put an issue on We get her or contact the author by email. That's the first thing. The second thing is I would say, you know, read a lot of papers. Now, you know, that's easy thing to say and kind of obvious, but a lot of, you know, a lot of the knowledge and ideas actually are going to come from reading, reading the papers and interacting with with those authors. You know, my experience has been and I mean, this is true for DeepMind. And every other place that I can think of people are quite receptive to answering questions about the research. I really like when people contact me and say, oh, there's something I don't understand about this. Can you explain it like that? Yeah, sure. Like, I'll definitely explain that. I really liked doing that. My experience has been that that's the case for most people, most researchers. So yeah, I mean, don't stop it reading the paper, if there's something you don't understand. Write in on the forum, and if you don't quite get an understanding from that contact the others or; Yeah. 

Sanyam Bhutani  1:10:02  
That's amazing advice. So before we end the call what would be the best platform to follow you and follow your work?

Dr. Marc Lanctot  1:10:11  
Probably. So I maintain two things. I mean, I think Twitter's probably the best. @Sharky6000 is my is my handler. My website is probably the next one.

Sanyam Bhutani  1:10:27  
We'll have the links in the description as well for those who would like to check it out. Again, thank you so much Marc for joining me and having this amazing interview and thank you for all your contributions to the community.

Dr. Marc Lanctot  1:10:39  
Cool thing. No, thanks a lot for having me. It was really fun.

Sanyam Bhutani  1:10:53  
Thank you so much for listening to this episode. If you enjoyed the show, please be sure to give it a review or feel free to shoot me a message You can find all of the social media links in the description. If you like the show, please subscribe and tune in each week to "Chai Time Data Science.

