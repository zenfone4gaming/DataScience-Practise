Sanyam Bhutani  0:13  
Hey, this is Sanyam Bhutani and you're listening to "Chai Time Data Science", a podcast for data science enthusiast where I interview practitioners, researchers, and Kagglers about their journey, experience, and talk all things about data science.

Sanyam Bhutani  0:48  
Welcome to the "Chai Time Data Science" show. In this episode I interview the king of Kaggle kernels, kernel Grand Master Andrew Lukyanenko, also known as Artgor on Kaggle, spelled as ARTGOR. That's kaggle.com/artgor. Andrew is currently ranked as number one in the Kaggle kernels rankings. He is also a discussions Master and competition expert and is currently working as a senior manager for big data research at Tele2 In this interview, we talk about Grand Master's journey into data science, his current projects at work, his pipeline for writing the Kaggle kernels, and he says many advices for beginners to get started writing the Kaggle kernels and insights about his EDA kernels. Enjoy the show.

Sanyam Bhutani  2:00  
I am excited to be talking to one of my machine learning heroes. Grand Master Andrew, also known as Artgor on Kaggle. Hello Grand Master, thank you so much for joining me today.

Andrew Lukyanenko  2:11  
Hello, and thanks to you for inviting me.

Sanyam Bhutani  2:15  
So currently you crowned the king of Kaggle colonels with the rank one, and you're also discussion Master, as well as a competition expert. So, could you tell us a bit about how you got interested in machine learning and how you got started with Kaggle?

Andrew Lukyanenko  2:30  
Sure. Several years ago, I was working in consulting companies as an analyst in gear pieces to implementations It was quite interesting and useful, but very stressful, and had quite a bad work life balance and many repetitive tasks and so on. I was looking for some other occupation and in some 2016, my one of my former colleagues told me about such thing as big data. What can we use data and analyzing it was always interesting. To me, so data science seem to be a good choice. It took me quite a long time to land my first data science job. But now I can say that it was worth it. Kaggle was a well known platform for machine learning competitions, even three years ago, I have started to make a goal journey with designing the site as many as the people but after this, I abandoned Kaggle for more than a year spending time on learning other things because I and I saw that Kaggle isn't this useful. But some people in ODS society especially Ternaus, known as what the Vladimir, Iglovikov regularly wrote, that taking part in Kaggle competitions is a really great idea and everyone should it should do it. And so I decided to try it and I left it and I do it now.

Sanyam Bhutani  3:48  
We're all grateful that you did get started so the community is grateful for that. 

Andrew Lukyanenko  3:52  
Yes. 

Sanyam Bhutani  3:53  
And you currently working as a senior manager for big data search at Tele2. And I think you've been working in the data science space for for a few years now. So can you tell us like, where does Kaggle come in the picture for you? Is it related to your other projects at work also?

Andrew Lukyanenko  4:10  
I think that there's a lot of debates about Kaggle in the last years about its use is about its usefulness for people in real world, because a lot of people say that model like and Kaggle is only a small part of data science projects, that you never get clean data and that you compete for some kind of small, small minuscule increase in score and there's no needs of it in real business. I completely agree. And this is true, but Kaggle also brings a lot of other important things to the picture. I won't speak about the elements which people say, but I will say what exactly I got from Kaggle for my job. First of all writing Kaggle kernels help me improve my skills in creating minimum viable projects fast. And sometimes in business this is already enough, you made a simple model and it's already solved the problem. Competitions also show that setting up a correct validation scheme is very important and it will make working late with data easier and it will help you correct the, compare your solutions. Also;

Sanyam Bhutani  5:29  
With the real world data.

Andrew Lukyanenko  5:30  
Yes, yes, and Kaggle also let us take part in different competitions which we would never be able to try in real world so it gives us a lot of experience. Also, top winners usually poses solutions in forum and reading it is really, really useful and it could be helpful in real tasks. Also, I think everyone agrees that in competitions featuring portrait feature engineering is much more important. And during models, of course it works. But we see that fishes are much more important. And this is completely true for business. And yes, and of course, a couple of last things, some tricks which we meet on Kaggle like three and four. So there are several validation and other cool ideas. And of course, a lot of people amazing, great people who are on forums who write kernels, who take part in competitions; 

Sanyam Bhutani  6:26  
People like you.

Andrew Lukyanenko  6:27  
Hehe, thank you, and they share their knowledge and it really helps to people. So this is like this, Kaggle was very useful for me.

Sanyam Bhutani  6:36  
So like, there are negative aspects to it, but you think overall, the positives outweigh in general.

Andrew Lukyanenko  6:41  
Yes, especially is a competitive aspect because it's when you indeed do task and work. You have some kind of problem like Churn prediction, you might have a model and you don't know you don't know whether its good. But in Kaggle, there are hundreds of people and you will know that what you did is good or not, and you will want to become better.

Sanyam Bhutani  7:04  
As well as in real time so you get to understand your position. Also, could you tell us about Tele2 and the current projects that you're working at at your current job?

Andrew Lukyanenko  7:16  
Sure. Tele2 Russia is currently one of the top communicate telecommunication companies in my country in Russia. It has a lot of data, as many such companies and the result needs a strong data science expertise. Our team solves a wide range of business problems, and we always try to improve our approaches. I have worked, for example on such projects as fraud detection, journalitics, text analytics, and many other things. And our team is comprised consists of great people and they think we will do a lot of better and interesting things in future.

Sanyam Bhutani  7:53  
That sounds amazing. We'll have the website linked of, in the description for the viewers who haven't heard of the company before. 

Andrew Lukyanenko  8:00  
Okay.

Sanyam Bhutani  8:02  
Now I want to come back to kaggle. So you've also been a competitor, you hold a few great silver finishes on multiple competitions. So maybe if you could tell, pick one competition, or maybe a few that have been your favorite. And will you be competing soon since you're already the king of kernels now?

Andrew Lukyanenko  8:21  
Okay, let's see, I think I'll talk about two competitions, which will show that Kaggle is really a platform where different things could happen. The competition, which I try and remember the most is a Avito demand prediction challenge, because it was the first competition where I took part seriously. It was, it was very interesting because we had tabular, tabular data, text, data and even images so we could try a lot of different things. There were four people in our team and we tried really, really lot of scenes and not a lot of interesting topics, even though we got only bronze medal, it was fun, interesting and very useful and the first experience. And just to compare in this competition, we spent a lot of time ?, it was tough and only bronze medal and a steep contrast. There was competition with good from Google Analytics last year. And it had it was strange, it had several leaks, it gets strange data and so on as a result isn't so it's the end of the competition. I simply submitted something near zero with smaller random values and got silver medal. So this is a contrast and this shows that Kaggle competitions can be quite strange. And that's for now, I take part in competition named predicting the molecular properties. It presents a very interesting problem and a very interesting data. I am a part of an amazing team, there's great people and they hope we will have success in this competition.

Sanyam Bhutani  10:05  
Indeed, we hope so too. So I also wanted to ask you that you mentioned you bought a bronze medal on the competition and many people think of Kaggle winners like, they they are the knowledge holders, but as you mentioned that even with the bronze you gained a lot of insight to the competition. Do you think a person who's just got a bronze medal even like they just started competing, they might have a great knowledge for that competition?

Andrew Lukyanenko  10:28  
The main problem is that when I'm, I look at the competition as in some kind of external person, I have no way to say whether this bronze medal was gotten well, after a lot of efforts or it was some kind of lucky submission. So, yes, so if we take say, whether bronze is good or not, the only way to say it is to talk with a person who has this bronze medal and to ask him, what did he do for it? If the person is able to talk about his efforts? Yes, this is great. If he can, they can say anything that maybe he simply took a public kernel and submitted it. And there was no efforts, and not any knowledge acquired.

Sanyam Bhutani  11:19  
Yeah, but like, I want to clarify the question that not just Kaggle winners are the real knowledge holders, even people who try to compete and don't win the competition might also be knowledgeable. 

Andrew Lukyanenko  11:30  
Yes, absolutely. Even there were a couple of competitions were spent a lot of time and a lot of efforts and it didn't get any medal and still, I got a lot of things, new things. So medals doesn't matter in the sense of acquiring knowledge, you will get knowledge even without this.

Sanyam Bhutani  11:50  
That's a that's a great comment. So going back to submitting from kernels, you're the king of kernels, we all love your kernels and I think this is almost like a second unpaid job from our offline conversations. So could you give us an insight of what sort of efforts goes into your kernels? I mean, now now it might be a little little relax for you. But what is your workflow like for writing these kernels and the amount of efforts that usually go into these?

Andrew Lukyanenko  12:18  
Well let's see, usually I write several types of kernels. The most common and I suppose my most popular type is EDA Kernel. And sometimes I write other Kernels, when I write EDA, I write this kernel as soon as possible. So as soon as I hear is about the competition;

Sanyam Bhutani  12:39  
Usually within a few hours of the competitions luckily for us.

Andrew Lukyanenko  12:42  
If I have not a currently don't work in a not in my job, then I try to throw away all the things which I do if I they're not some urgent and seek to try and write the kernel. Usually the first version is ready after one or two hours. So it usually contains some kind of some kind of overview of the data set, basic modeling, maybe plots for some interesting variables. And this is right here. And of course, this is only beginning. In the next version, I usually make it for all features, create some better feature engineering, better models, maybe some kind of oil interpretation and so on. So I suppose currently, in general, kernels take around, maybe eight, up to eight up to 16 hours of pure working time. Of course, some competitions, have less data and maybe some good a good took a couple of hours away before I was in total. And of course, I want to point out that I have a lot of experience writing kernels. And when I started writing journals, it took me much, much more time. So usually, no one should be discouraged in the fact that it takes a lot of time to do something. When you do something for the first time, you will make a lot of mistakes and it will you take a lot of time. And after this it will be easier and easier with each time. And sometimes, yes, yes.

Sanyam Bhutani  14:12  
That's an amazing comment, we all think of Grand Masters, they can write kernels and use, it still takes you a couple of hours to do that. So a beginner definitely will take a lot lot longer time than that. 

Andrew Lukyanenko  14:23  
And it's okay because experts and not me, I mean not Kaggle experts. So people who are experts are better because they made more mistakes. I think this is an amazing idea because really, you are expert because you made a lot of mistakes and learn from them.

Sanyam Bhutani  14:43  
I think it takes back to the old saying that a master has made many more mistakes than a beginner. 

Andrew Lukyanenko  14:48  
Yes, yes, this is like this.

Sanyam Bhutani  14:51  
Yeah. Also, I wanted to mention that EDA to a beginner friendly listeners. EDA stands for exploratory data analysis, which Artgor has many kernels upon so we'll also have his profile in the description would recommend checking those out for sure. 

Andrew Lukyanenko  15:06  
Okay. 

Sanyam Bhutani  15:09  
So I'm also curious about two things that what is your motivation for doing these exploratory data analysis. And also, now that you've read the first rank in kernels, what's next for you on Kaggle?

Andrew Lukyanenko  15:24  
So at first, I simply wanted to test my skills in data analysis and visualization. As I said, at first I rocked in some atmosphere and I changed to the sense after this, and I saw had little less experience and I wanted to see how my skills measured as a people, each time I saw that, people give me good feedback. They liked my kernels, and they say is that the my kernels really helps them so we think it's a great idea to continue writing kernels and pure selfish benefit is that people give me feedback. Sometimes they find errors in my kernel, sometimes they give me new ideas. And so I continue improving my work. And still one of important things is sharing knowledge. Because I think that sharing knowledge is quite important. And when a lot of people you know, some things, usually the general level increases and people start doing some better things. And this is some kind of positive a feedback loop. And for about two, what will I do next? I'm not sure. I suppose I'll continue writing kernels in a more relaxed mindset. And I think I'll take part in competitions more seriously. Because well, I have nothing holding back, nothing holding me back anymore.

Sanyam Bhutani  16:53  
That's great. So we can keep continue expecting great kernels and also we will be seeing you on the leaderboard more often now. 

Andrew Lukyanenko  17:00  
I hope so. 

Sanyam Bhutani  17:02  
We do so, we do hope so. So, also if you could like many people think of machine learning as you have your data you do model fit something amazing happens. But here we are talking about EDA. So could you tell us because a majority of your kernels are indeed EDA and you do enjoy it, you do emphasize on it, but why is it important? And I think since the world also on multiple problems as a data scientist, do you think the skill of being able to tell stories from data has helped you? 

Andrew Lukyanenko  17:33  
Yes, I have a strong opinions that EDA is a must be a first step of any project. Sometimes you will spend less time on it. Sometimes you will spend much more time on it. But it is vito to understand your data. You could discover some patterns, for example in data and use them to build your model. You could find some useful insights and create something which will surprise the businesses users also you could simply find some more interesting relationships which will help you to generate new features. But anyway, exploration your data is important because simply fitting algorithms is already not enough. It was could be it, maybe it was enough several years ago. But now you must think anyone can make fit and predict. But if you want to be a strong professional, you need to think first.

Sanyam Bhutani  18:31  
Yeah, also real world data as we know, it wouldn't always been the best format. So we will have to sort of explore it every time.

Andrew Lukyanenko  18:38  
Yes.

Sanyam Bhutani  18:41  
So like if for a beginner who'd want to become maybe someday, kernel Grand Master, what tips can you say to write for writing great kernels similar to yours?

Andrew Lukyanenko  18:53  
Well, let's see. In fact, I could say a lot of things about this and I in fact even planned to write some kind of blog post about writing kernels. I wrote a couple of posts on Kaggle about this, we could include them in the text version. And I think that's the main, the main idea when you write kernels is to make something useful, which you would like to see. And to write your own analysis, because I saw a lot of kernels when people make a lot of plots and write nothing. Well, cool plots are great, but you don't show you know, one analysis, you don't show nothing. And well, people won't like it. And if this isn't, this isn't really useful. So even if you write some kind of short kernels, maybe one or two pages, if you include your own analysis, your rotations of the data of the plots, it will go right in a great start.

Sanyam Bhutani  19:56  
Yeah. So I think like what you're trying to say like those beautiful plots are not the juice, juice of the problem, but plots are, are a central part to it. But there's also the story that goes around.

Sanyam Bhutani  20:08  
And some I saw several great kernels which contained all the plots, but they may be there are only some of them because really good characters contain not only plots, but your own ideas. Because you need to show that you can not only draw some cool things, but you can use these to generate some new insights and kernels.

Sanyam Bhutani  20:38  
That's a great comment. So like, as as you know, like it's all about asking the right questions about the data. So what do you think what sort of questions do you think one should ask when approaching a new competition or a new data set or a problem on;

Andrew Lukyanenko  20:57  
Really many ways to start working on a problem, for example, it's a good idea to start with understanding the problem itself and the data which is available. What is the business domain of the data set? What is the target variable and metric? What kind of problem we're trying to solve in reality, then we are usually interested in the quality of the data. Are there any misssing values, are there any outliers, are there any features which you look around are different from others, then you will start exploring variables, interactions with other variables, their relationships, how do they influence the target variable, so on. This is, I suppose a great start. And after this, you could try to do something specific to a project.

Sanyam Bhutani  21:44  
Awesome. And also, I think it's an iterative process that one will definitely learn by, as you said, making mistakes over time and from the feedback from the great community. So I also believe that like. Now that we know how to the right questions, there's also this skill I believe of being able to tell a story using a kernel. So how do you think can one share a story via kernel or code in the best manner. If you could give a few insights on that. 

Sanyam Bhutani  22:14  
We talk about stories and storytelling then I really love kernels written by Heads or Tails, he is also Grand Master of kernels, and he writes amazing kernels in R which is quite rare in Kaggle. First thing he does, he hides all the code. Anyone who wants to read it can read the code, but it's hidden by default. So they said it doesn't distract users. And other thing is that he writes a company comprehensive and structured analysis which starts from some simple things and goes deeper and deeper and provides good insights. And of course, he makes amazing visualizations. He often combined several uploads to show one variable from several points of views. I think that his kernels are an amazing example of such thing.

Sanyam Bhutani  23:07  
Right. And it also shows us that if you're a great coder, you can also be able to tell these stories to not just a coder, but also business person because, as you said, he does hide his code. And if you just scroll through the notebook directly, they'll tell the story not just to a Kaggler, even a Kaggle Grand Master, but also to someone who doesn't even know to code usually. Yes, this is true. 

Andrew Lukyanenko  23:30  
And this is, I suppose, a great skill for the real drop. 

Sanyam Bhutani  23:34  
Indeed, indeed. Now, I also know that you're very vocal about the bad practices that happened on Kaggle. You're also very vocal about it on our slack community. So I think it's it's a must know for a beginner how not to fall into this trap. So being the king of kernels, could you share maybe a few words on how can someone who's just joining the Kaggle scene, respect the work of experienced Kagglers and not fall into this trap or sort of toxic practices that are developing, such as paginating and similar ideas.

Andrew Lukyanenko  24:11  
I think that the main thing is the mindset. If you have the correct mindset, then you won't have this problem. I saw that some people want to get medal so much that they would do anything to acquire them in. Yes, in fact, I a couple of times, maybe I was somewhere at the border, but I usually try to write good and correct kernels. So I suppose that the main problem is that people want to show something cool, but they don't know how to do these things. And they take parts from other kernels. If they would leave simply reference for original kernels, then it would be enough but sometimes we saw people which completely copied some notebooks by other people and tried to to show it at their own. So we think that people should try to make their own work. And if they want to maybe take something from other kernels, then references would be a good idea, because there are a lot of people in Kaggle now and they will be easily find your cheating. And well don't do this reputation is a very expensive thing. It's very difficult to acquire it and very, very easy to lose it. 

Sanyam Bhutani  25:31  
Indeed. So always expect the work of experience Kagglers, always give credit where it's due, and don't just fall into the trap of gamification. Also, I mentioned about a slack community which brings me to open data science, also known as ODS dot ai. Also the thing that usually occupies the top few are usually the top of the leaderboard in almost every competition. So could you tell us a bit about ODS, also many people think of it as a Russian only community. Are other people also welcome people that don't speak Russian?

Andrew Lukyanenko  26:08  
In fact, I think that open science community is the most amazing thing which I ever found. Because when I walked in another sphere, there was no such thing. You walked in your company, sometimes there are a couple of conferences where you talk with some people. And that's it. You usually you're usually on your own, or maybe you are with your team as a company. But here, this can be, I suppose I can say now is it. It's only thanks to these communities that I'm at the place where I am now, because there are currently there are more than 30,000 people in this slack community. And I think more than 7000 people use it each week. So it's great immunity. You can get information about various spheres of machine learning like deep learning, classical machine learning, network analysis and some other things. You can ask questions about career development, you can cause you can ask helping some courses and so on. So this community really motivates and encourages people and to use Kaggle is only one of activities. And I suppose only a small part of our community takes part in it. But it's one of the most experienced part of community.

Sanyam Bhutani  27:31  
We have many Grand Masters from ODS for sure.

Andrew Lukyanenko  27:35  
I think that one of the seen interesting things about this is that on one hand, data science sphere appeared and became hype in Russia and not so long ago. But on the other hand, there is quite a high competition here. And if people if Russian people want to show that they're better competitors or that they are good, or even in the whole world, then it is necessary to somehow prove your skills and Kaggle is a great opportunity to do so. So there are a lot of strong people who change their career to data science, they want to prove that they're good, and they use Kaggle and well, they have success. And so we have really a lot of Grand Masters. And of course, such successful community may draw some attention. And for a long time, we had admins here like inversion and some other people from Kaggle team who can access any, any discussion about competition and see whether there is something strange here. And of course, our community is open to everyone. Well, most of our community is Russian speaking. So most of the posts are in Russian, but if someone asks a question in English, we always answer in English. And of course, there was a course. And when the course is open and free machine learning course, which attracted all the attention, there were a lot of people taking it. And of course there are a lot of English speaking people and it's going well, I think.

Sanyam Bhutani  29:19  
That's that's great. I think I also want to drop a warning to beginners that indeed all all beginner questions are very welcome. But please do make sure to always do your homework before before asking anyone experienced or please don't ask StackOverflow questions in the community, make sure that you do your part of research and then approach anyone in the community.

Andrew Lukyanenko  29:40  
Yes, I think well, just one thing about this question is that I suppose the Russian community is usually stricter than English speaking communities because I suppose there are high expectations of people. So if someone doesn't want to make some effort to get some knowledge and simply asks simple questions, people will answer him a couple of time and after this, there will be some kind of negative reaction because our community has high expectations of data scientists that they're highly motivated and willing to study things. And so we usually expect that people try to do something by themselves and ask questions when they come to something. And if they chose it, they made some efforts, we will gladly answer them.

Sanyam Bhutani  30:30  
That's that's a great point. We should always do our set of homework before covering the experienced people now that we have the warnings out of the way. Could you could you share a few advises on for the beginners and the noobs that are going to become better Kagglers? What would be your top advice to them?

Andrew Lukyanenko  30:49  
I said, first point is try to use kernels and discussions for your benefit because kernels not only mine, but also kernels by other people provide a lot of knowledge, a lot of great information and they will help you acquire not only the base code, but a lot of your skills and your experience. And if you look in the forums, you will see that a lot of people talk about their models, their approaches, their scores, and the many other things. And this is amazing that people share so much things. And just, we can remember that in several past competitions, Chris started sharing a lot of things and it was amazing and helped a lot of people. So use forums and discussions, be in the information niche which other people share and you will have success or at least you will acquire a lot of new skills and knowledge.

Sanyam Bhutani  31:53  
We'll also link Chris Deotte Grand Master Chris's profile. Indeed, he has a lot of great resources. He is also one of the most active Kagglers I think, right now. Also, the usual job descriptions require one to be one to have a PhD with 10 years of experience, maybe five years of experience, insane amount of expectations even for from a fresher. So could you could use, say, what do you think about how can one who's fresh in the field, become better prepared for a job? Also, do you think like, maybe Kaggle would be a good point on one's profile if they're looking to get a break into this field?

Andrew Lukyanenko  32:38  
In fact, I think that it really depends on the country. In some countries, expectations are high in some countries, expectations are lower. So I can't speak about all the countries but I think that getting the first position is always the most difficult after you get your first job in data science and things will be much more it much easier for you. So if you want to get the first job, you need to show that you are better than other people. And they think that then going through a lot of courses isn't a good idea, because it's usually enough to go through one or two good courses. And what really should put you out is some kind of personal project. It could be some, for example, you could make somebody to website to be your host the model and everyone could try it. Another idea is to make a GitHub and throw your analysis and skills. Another idea is really Kaggle. When the, here is the problem is that if you've got low, low scores, low medals, then when the, when recruiters simply look at your profile, they won't be able to say whether you're good or not. And so I suppose that either high level medals can help you all writing good kernels because you will show your analysis skills, your coding skills. And often this is enough.

Sanyam Bhutani  34:09  
So the the infinite learning loop, as I call it, where you go from one course to another because you feel like you don't know one thing and another course teaches you saying that instead of doing that one should just jump in on a project period as simple or even get started on Kaggle. Try to get feedback from the community.

Sanyam Bhutani  34:30  
Yes, I agree, because practice is the main thing. Well, I suppose some people can learn from courses and receive great benefits from it. But for example from about me, I prefer to study something and then apply to practice at the if we don't apply it to practice. I will forget it very soon.

Sanyam Bhutani  34:51  
That's that's a great insight. So please follow Grand Master's advice on that. I also want to ask you about how keep yourself updated with the explosive growth of machine learning, all of these papers blog post all of these amazing knowledge that's coming out. So how do you stay on top of it?

Andrew Lukyanenko  35:11  
Well as a lot of people, I make out of bookmarks and never read them.

Sanyam Bhutani  35:18  
Like those people using Chrome.

Sanyam Bhutani  35:20  
So, more realistic approach is that I subscribe to several, I suppose several sources like data machine data edexcel and similar things. And also I use this community which has a lot of links to important research, but I think this is really important. You need to decide what is interesting to you. If you are interested in classical machine learning, you will use our resources. If you are interested in state of the art deployed in motion the models you will use our HIF. So three are different on what you want to accomplish, because it isn't possible to follow all the developments, it isn't possible and it isn't necessary.

Sanyam Bhutani  36:10  
Yeah, so we shouldn't rather just focus on what we're interested in and let let the tabs or the bookmarks remain there.

Andrew Lukyanenko  36:18  
Yes.

Sanyam Bhutani  36:20  
Also, what are your thoughts about the hype versus reality of machine learning because we at this state of the art state of the art stage, and do you think there's a hype to the machine learning or is it still real?

Andrew Lukyanenko  36:34  
Let's see. So people say if you see a code, then it's machine learning. If you see a presentation, it's artificial intelligence. So yes, I suppose some parts of machine learning are a lot of hype. But what is important is that machine learning is a tool which is which is simply a tool, it helps you to do something, but it isn't means to and, and really in my opinion that maybe in 10 or 20 years, machine learning will be used in all or almost all companies, it will be changed. Of course, maybe it will be easy to use, maybe it will, there will be more programs which will provide solutions. But machine learning is reality, it will be used, you won't, we won't run out from it, there won't be some kind of cold winter. It made people understand that it is a reality. It isn't magic. Because sometimes people think that machine learning is magic, it can do anything and so on. I think that people will understand that machine learning is a necessity, it can't do everything. And the one more important thing is that programming skills are very important. So machine learning engineers will end up engineers who will be maybe do have maybe even higher, will be more than one then simple society to me.

Sanyam Bhutani  38:07  
I mean, they might be even be the rock stars of the future, one day.

Andrew Lukyanenko  38:10  
Yes, I agree. Yes. Yeah.

Sanyam Bhutani  38:14  
So before we conclude any tips for beginners who aspire to be like you someday, but feel completely overwhelmed with the amount of knowledge that is there by all of the Grand Masters on the leaderboard, too scared to just compete even?

Sanyam Bhutani  38:29  
I think that one of the most important things in this is persistence and not giving up because I just want to say is that when I was changing my career, I left my job in consulting and it took me eight months to get my first job in data science. It took me eight months and it was really tough and even tough mentally because I wasn't sure I would succeed. So I think that you should the decide whether you want to do it or not. And if you decided that you want to work in data science then you should do it without doubt you should work on it you should pursue your your dream. And someday it will come through.

Sanyam Bhutani  39:17  
That, that thank you for the great comment. It's indeed that you only learn by mistakes. And I think you you are example to the world that keep keep competing, and eventually you will make it. 

Andrew Lukyanenko  39:27  
Yes. 

Sanyam Bhutani  39:28  
So thank you so much, Andrew, for joining me today. We're also from the community and myself. We're all grateful to all the things that you do on Kaggle and even in the community. And we hope that you keep sharing those most amazing kernels with us and now hopefully when competition insights. Before I jump off, could you apart from your Kaggle and medium profile, how can we best follow you work? Is there any other place?

Sanyam Bhutani  39:56  
I suppose not. I only seen, I also write these in this community. So maybe you could also join it because I repeat that audience community is open to everyone who is willing to learn data science.

Sanyam Bhutani  40:13  
Great. Thank you so much for joining me today and thank you for taking the time.

Sanyam Bhutani  40:20  
Thank you also for giving me this opportunity.

Sanyam Bhutani  40:36  
Thank you so much for listening to this episode. If you enjoyed the show, please be sure to give it a review, or feel free to shoot me a message, you can find all of the social media links in the description. If you like the show, please subscribe and tune in each week to "Chai Time Data Science."

