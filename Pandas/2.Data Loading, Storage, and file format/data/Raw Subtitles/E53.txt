Sanyam Bhutani  0:13  
Hey, this is Sanyam Bhutani and you're listening to "Chai Time Data Science", a podcast for data science enthusiasts, where I interview practitioners, researchers, and Kagglers about their journey, experience, and talk all things about data science.

Sanyam Bhutani  0:45  
Hello and welcome to another episode of the "Chai Time Data Science" show. In this episode, I interview one of the inspirations of the complete Machine Learning Community Dr. Erin Ledell, chief machine learning scientist at h2o.ai. Erin holds a PhD from UC Berkeley where her research was focused on machine learning and computational stats. And she has worked in the software industry before joining h2o. We talk all about her journey into the field into starts machine learning and her journey at h2o. h2o.ai and open source, in the open source world. We talk about h2o's open source products, h20 auto ML. And Erin helps me clarify the question of the difference between h2o, h2o three and h2o auto ML, so please stay tuned if you're curious to find out the answer to that. We discuss about her work at h2o.ai and Erin says many great advisors and opinions about auto ML and software or software tools for data scientists or humans generally speaking, we also discuss her community contributions. Erin is the (co)-founder of Rladies and women in machine learning and data science. We talk about her contributions to the community and how can the people who are just starting to recognize this personally I am sadly one of those, Erin shares advises on how can outsiders or just newcomers contribute to this, so I'm really excited to be sharing this interview. Quick reminder to the non native English speaking audience please remember to enable the subtitles on YouTube for a better watching expedience. And for now, here's my interview with Erin Ledell. Please enjoy it.

Sanyam Bhutani  2:54  
Hi everyone. Today on this show. I have a inspiration not just to me, but I believe to the complete machine learning community, chief machine learning scientists from h2o, Erin, thank you so much for joining me on my interview series.

Erin LeDell  3:06  
Thanks. Thanks for having me. I'm glad to be here.

Sanyam Bhutani  3:09  
Really excited to be talking to you. So I want to start by talking about your journey. You you hold a PhD from a bio science background and you've been working at h2o for a while. When did you first discover your passion for machine learning or starts, I know you had an interesting debate with detail already about this, but when did you become passionate about it?

Erin LeDell  3:31  
Um, well, I didn't become passionate about statistics until a little bit later on. I was a math undergrad and and more on the the pure math side. So I was into combinatorics and graph theory. And then I started a math PhD immediately after undergrad and after about two years, I realized that I was spending more time on the computer, then I then with my pencil and paper, I wanted to kind of, I got I guess I got excited about computing and programming. And so basically I exited that program with a masters degree and then became a software engineer. And then later, like, a couple years later after that, that's kind of when I started to learn about machine learning. And then, when I first learned about it, it was kind of presented as this computer science thing. And so I didn't understand at the beginning that's really actually more like just statistics, which is something that I could, you know, feel more comfortable with. And so yeah, that I that was back in like 2007 or so or eight or something like around that time and then at that time, there wasn't, there weren't any boot camps, there weren't any, like, you know, online courses, like none of that existed. So I just figured that the way to go more deep into machine learning was to get a PhD. 

Sanyam Bhutani  5:15  
Okay.

Erin LeDell  5:16  
So then I started to look around and applied programs, and then I joined or, you know, started my PhD in 2000. I forget if it was 2009 10 or 11 at Berkeley, so.

Sanyam Bhutani  5:31  
I think in one of your other interviews, that you were always onto math. Was it the same case with programming coding as well? Or did you pick up these as you found your interest?

Erin LeDell  5:42  
Um, yeah, I think I think what happened was once I left pure math, and then I went into industry for a while, I realized that essentially nothing that I did was, could be used unless you could put it into code. So I think I just realized that how important it was to be able to be proficient in coding and and then I just like, I liked doing it too. So it's like a need based thing and also, like yeah.

Sanyam Bhutani  6:16  
Awesome. And you would much, much ahead of the curve you were doing ensemble techniques doing the research. How did you find your interest for this topic? And because I think at that time, this wasn't much common, I think Grand Master Marios' was one of the very few people who were working on these at the time.

Erin LeDell  6:36  
Yeah. So, um, so that just comes from my advisor at Berkeley. So this person named Mark Vanderlin. So I had two advisors and he was one of them. And this is just something that he put a lot of research into. So kind of the history behind stacking and stacked ensembles. That's kind of the type of ensemble and I tend to spend the most time doing it was a thing before before my advisor kind of got ahold of it. So it was it was something that was published people knew about it. It was a technique, but people didn't know necessarily like why it worked. Just that it kind of worked. So that was a contribution by my PhD advisor. So he proved all the theory sort of behind stalking, and why does it work and a bunch of sort of very theoretical asymptotic results that show that essentially, that the TLDR is that the ensemble should always have the better performance and the best base model inside. Now in practice, that isn't always the case. And this is because this is based on asymptotic theory as end to infinity. So if you have enough data, that should be the case, but sometimes in practice, it's that's not and that's something you know, you could maybe debug a little bit. But so yeah, that's how I got became aware of it. So there was a PhD student before me named Eric Polly, who now is biostatistician at the Mayo Clinic. And he was kind of the grad student around at the time when they really first started doing this work. And then he made a package called Super learner R and then basically when he left, I came in and then sort of started doing a lot of the same work that he was doing and started working on the super learner package and the software. And I think when I first heard about it, or maybe when I first heard an explanation of the theory, it was in a class taught by my advisor and I remember him saying like, yeah, this will be better than any other model blah, blah, blah and I remember rasing my hands. Like, why isn't everyone using this all the time? I understand, like, it doesn't make sense why this exists and that it's not ubiquitous. So I guess, you know, there are some practical reasons why people don't always use ensembles in every case. But I guess I've always just been in the camp of like, well, if this exists, and it's getting better results, you know, we should probably be using it if we care about model performance. If we care about other things, then, you know, you can make other considerations like if you care about interpretability, if you care about prediction speed, if you care about you know, complexity of the model, etc. So so yeah, me like right away sense to me that this is something that isn't people should be doing. And I think the struggle back in the day was that there wasn't good software to do it. And so part of part my research was also applying these techniques to real data sets. And that's why I chose bio stat over stat is because they promised me that I can work on real data. So I did and I would be waiting for like, I remember, at one point, there was some model that was training for like two weeks, and I was just like, this is too slow. We need to figure something out here because this is a great method, but it's not practical. And so that's what I spent a lot of time doing is improving the tooling around stack ensembles and coming up with different variations of it. I worked on something it was like an online version built on top of Vowpal wabbit because I don't know if people are still using that software a lot lately, but it was quite popular most;

Sanyam Bhutani  10:54  
Some of us do.

Erin LeDell  10:56  
2010s and then I'll techniques, there was another algorithm that I co developed with some people called sub semble, where you take subsets and so just different approaches. And then the kind of final approach I settled on was just, let's just use better software underneath, like h2o. And then we can alleviate almost all the problems that we have just that should be a given. It's just using the best software for all the base algorithms. And then we can build on top of that, and then that kind of is the path about how I got into h2o and using h2o and using each row as sort of the building blocks for my research in my PhD.

Sanyam Bhutani  11:41  
Okay, I'm sorry for the ignorant like me would say difference between biostats and stat.

Erin LeDell  11:46  
Um, well, sometimes they're kind of the same thing. But generally, they're either like different departments. at Berkeley, there's no biostat department so it's just it's called a group. So basically, I took all of my classes in the stats department, and some in the CS department because I just chose to do that. But essentially, it's just more of a focus on statistical methods that are relevant in health data or biological data. And maybe just a little bit more of an applied focus and especially at Berkeley, it's a very stat departments very theoretical. So just a little bit more applied.

Sanyam Bhutani  12:30  
Got it. Now, you mentioned software already is to creating software for for the world. Could you tell us what, what does a day in your life currently look like? What tasks are you working on at h2o.ai?

Erin LeDell  12:42  
Um, yeah, so it changes a lot like every day what I work on, but generally, like the main team that I work on at h2o now is I lead the auto ML team, so the h2o open source auto ML team. So most of my day to day work is focused on that. But because that's an algorithm that involves basically everything else inside of h2o, I get involved in all sorts of things. So so yeah, like, you know, the other day, like, let's see, I will have like a meeting with my team and we discuss like what we're going to work on. We're hiring a new person who starts next week. So we're figuring out what he could work on. And so a lot of it is like roadmaps and making sure we're on track with that. Then part of it is like just pure research. So I have some sort of research, experimentation projects going on within the auto ml world, and then I have other things as well outside. So I have some other collaborations that I'm working on working with a professor at Stanford right now on an interesting collaboration not related to auto ml, but more focused on interpretability. So it's like research. And then I spend just like a lot of the day just on email and slack and answering questions or having opinions about things, assuming people listen to them. And yeah, that's about it the other day I have spent on Monday I spent the afternoon cackling. So that was fun.

Sanyam Bhutani  14:29  
Congratulations on this expedition finish. Your team for the audience who's been sleeping under the rug finished six on the women in Data Science competition. Again, you will find the details in the description if you want but congrats to your team.

Erin LeDell  14:42  
Thank you. Yeah, it was fun to have an all women's team. For the first time it was cool.

Sanyam Bhutani  14:48  
Talking about open source, did you always have an interest in open source? Is there interesting open source during you as well? Or did it just happen as you were working through your PhD days or while you were creating those packages?

Erin LeDell  15:01  
Yeah, I mean, I think I probably in grad school is when I earned my PhD when is when I got really involved in open source community. And part of the reason that I like to do open source is the community and especially the R community. I do a lot of Python as well, like just as part of my job and in my past in consulting roles, like a lot of Python, but but I like the R community a lot. And so part of it is just like a social thing. Like I just want to like, be part of the conversation. So this is how we communicate is by software. So you know, it's kind of like, interesting to see what people are working on and see how their careers or paths or research evolve over time. And I've known a lot of the people in our community for about 10 years now. So so yeah, I think and then the other side of things is I just believe in the, you know, all of the benefits of open source. So I think in scientific research or anything related to that, it's very important to see the code. And, you know, I'm not opposed to closed source tools, but I think there always has to be an open source implementation of something, it should never be only locked up in one place. So I think, yeah, to just enable research to go forward. And also just making good software accessible is an important thing, just to sort of make the playing field fair because a lot of the like, really, you know, cutting edge machine learning stuff is happening in big corporate labs. So I think it's important and that is the case that a lot of these labs are releasing open source software. So we are kind of like on the right track there. But I think that's important to keep doing that. And and I think it will continue to do that. But when I first joined, or what I guess when I first learned about h2o, which was 2012, or 13, maybe it was 13. At that time, I worked for a company. This was during my PhD, but I had an internship at a company that produced proprietary machine learning software. And there were a number of companies that did this at the time and h2o kind of out of left field was like, hey, we're going to actually do the same thing but open source, so you know, and then and then all those companies disappeared. They I mean, they didn't disappear. They were acquired for a lot of money by big tech companies, but, but that's not the norm anymore. The norm is the best software is, you know, I shouldn't say the best software is open source, but there there's world class software where world class enterprise grade software that is open source. And so I think that I don't know if h2o had a big role in that or not. But it did kind of what was one of the first companies that put their neck out there and said, we're going to try this a different way, and see if it can work. And now, you know, h2o started in 2012. So it's 2020. Now, so eight years later, we have a, you know, more hybrid approach where we have proprietary tools and open source, which I think is, from a business perspective, a good strategy. But open source is still a huge part of what we do. And for me personally, that's the main thing that I work on at h2o, but yeah, I think it's super important. 

Sanyam Bhutani  18:47  
Awesome. I need your help with clarifying this for the audience. I'm sure you get asked this all the time, but people struggle with understanding what is h2o three, what is h2o auto ML and what is h2o because the names are synonyms.

Erin LeDell  19:00  
On purpose to confuse people I think. I'm just kidding. Um, so yeah, so let's clarify the name. So h2o.ai, that's the name of the company that well both of you and I work at. So that's one thing that's also our website address, h2o.ai. Then there's h2o, the software, so to the GitHub repo is h2o dash three. And the reason that we call it h2o three is it's the third iteration basically, of h2o. It's been rewritten. Three, this is the third time and the third time was I think, in around 2014 or something. And that had to do with when spark was invented, we sort of rewrote everything from scratch and so I don't believe there's going to be an h2o four but that's why we call it h2o three. So sometimes people just call it h2o. That's kind of the main name for it. But if we want to more specific, we say h2o three, just because it's confusing sometimes to people. So either one is correct. And what was the other thing? Oh, h2o auto ML. So auto ML is also a generic name. Many companies are starting to adopt the term auto ML. So like Google's one of them, they have some version of that where a Google cloud you know, vision auto ML or Google cloud tables auto ML. So basically, you just prepend the name of your company or something before auto ML and then you're it's like that, that version of auto ml which can be kind of confusing. But when we talk about, you know, auto ML at h2o, we could be just talking about generally automatic machine learning or we could be specifically talking about h2o auto ML, which is a function inside of the h2o package. And that's what I work on. And then of course, we have a different name, which is actually helpful for the proprietary tool, driverless AI. So, but sometimes people call that h2o driverless AI, so then, you know, but if you stick around long enough, it'll all make sense, I think.

Sanyam Bhutani  21:20  
For sure. What is h2o ML if you could elaborate, maybe on the capabilities, what does it currently allow users to be able to accomplish with it?

Erin LeDell  21:34  
So yeah, so this this algorithm, it's it's really the way that it's implemented. It's just a function inside of the h2o package. So and it's set up the same way that any other supervised modeling function in h2o is so you, you know, give it some data. You say what are you trying to predict. And you can I mean, for auto ml, we We basically stripped down everything else. So you're really what you're saying is, here's my data. Here's what I'm trying to predict. And then you can specify some other things like, like, how long do you want it to search for? How many models do you want it to create, those are two ways to control the length of the job. Then you can say, you know, if you care about log loss, instead of AUC, you can say, oh, I want to maximize log loss. Or you can specify other things related to which algorithms you want to include. So we'll just sort of include everything unless you turn things off. And by everything I mean, just all the algorithms that we have available in h2o that are supervised, with a few exceptions, some some of the algorithms that we haven't, we haven't put in there and we might do that. But like, for example, we don't have SVM in there yet or we don't have naive phase because it's not super powerfull. So things like that. And as we get new algorithms in h2o, we then add, find a way to incorporate them into the auto ml algorithm. And an example of that is extra boost. So a while back, we added extra boost inside of h2o. So it's the same exact extra boost software from that everybody else is using, but we have kind of a wrapper around it so that it can work with h2o. So once we added that, then that was a very exciting thing, because that meant I could add it to auto ml. And that's increased the performance quite a bit by having that in there. So yeah, we can just keep sort of consuming whatever we produce in h2o, and there's kind of just maybe like a one release delay of like, first we put it in h2o and make sure everything's good, and then we'll figure out a way to us that inside they the auto malfunction. So yeah, and it works for tabular data. So that's another thing like h2o in general, what it's what it's used for is tabular data so rows columns, whatever you can have, you know, non numeric columns, you can have category, etc. But that's kind of the traditional interface. So very similar to a psychic learn or something like that.

Sanyam Bhutani  24:19  
Also have your talks link from I think h2o world was the most recent one about the library. I definitely was those for my preparation for the interview, but I'll have them in the show notes. Now, coming to auto ML where do you see auto ML coming into the picture of a data scientists ,are we trying to replace a data scientist or data scientist or machine learning engineers be worried about the jobs? How do you see it coming into the picture in the longer term?

Erin LeDell  24:48  
Um, so I just think about it as a very natural like extension of trends that have been going on for a while in machine learning to link so when I first started doing this work like, I mean, there's machine learning in general, there were psychic learn did exist back then. You know, so we had maybe one example of like, and actually the the carrot package in R, I think also existed back then. So there were some examples of people making unified interfaces for a set of algorithms. But a lot of times, what you would do is you would use one piece of software over here, and then another one, and you, you know, you would end up using four or five different software tools just to try out a few different algorithms. And that was just really inefficient. And you'd have to reshape your data maybe sometimes between the tools and it's just, it was it was very messy and so that that's that was kind of the motivation for things like psychic learn or carrot in R and that made it much easier to just try things out very easily and then once we had that then it's like, okay, well, what else could we automate now? Because that that whole concept is kind of, you know, done or whatever. I mean, that was also the motivation behind h2o. It's a similar thing where it's a unified interface to a bunch of algorithms. And so then it's like, well, what else could we do to sort of make the process of doing data science more efficient? And it's really just what are the tasks that are easily repeatable, that we can wrap into kind of a function and for me, at the time, what I was doing is I was I was using a bunch of code over and over again to do the same thing. So I would train a bunch of models through you know, some sort of random search or thing or you know, different different techniques, but generally like random search, and then and then I would ensemble them together and then so I just I had this big chunk of code that I kept reusing and tweaking and changing and, and then it's like, well, what do we do as software developers, when we're reusing code, we make functions. So that just went all inside of a function called h2o, auto ML. And and so now that is, so it's really just as simple as that. It's really just a tool to speed up the process of training a bunch of models and getting getting to the right model quickly and having a lot of coverage over a lot of different algorithms and making it easy to do that just from one line of code. And yeah, so I think, like, that's where we are now. And that's kind of how we got here. And, and I think, you know, a show is not the only auto ML tool. So there are other open source tools, and I would imagine that they had a similar evolution is just like, okay, here's the thing that we do, how do we do that? This more easily. And, yeah, that's kind of the process. And I think, you know, well, we're not done yet. So we're on some big trajectory where we're always making better tools to make ourselves more efficient. So I don't like to answer your question, I don't think we're gonna replace data sciences, I think we're making them more efficient at their jobs, and we're giving them better software. And now that this exists, if you're not using it, there are other people that are using it and are more efficient than you. So it's kind of like, you know, just like now if you want it to be like, okay, I'm gonna start a new data science problem and reimplement random forests from scratch and like, because I want to do it my way or, you know, it's like, okay, that's fine, but you're not going to be efficient at your job and I don't know who's gonna pay you like five months to write that software and do all that stuff. But so really, yeah, it's just I think it'll make people more efficient and then within a business or something like that. It just means you can work on more problems simultaneously or, you know, back to back, you can just tackle more more things with AI.

Sanyam Bhutani  29:09  
I mean, also because data science isn't solved yet. So we don't have a one click anything solution. We are moving towards that. But we're not there yet. For sure.

Erin LeDell  29:18  
Yeah, that's true. And it's certainly not going to possibly, I mean, auto ML, we, we know already, it's there. You can still, with the right humans, beat auto ML. So maybe we'll get to a point where that's not true. Or maybe we'll get to a point where you just go out compute humans because you have more computing power and they get, you know, you can do it faster. But yeah, so it's so probably the next few years, we'll just see more auto ML, more focus on other things like interpretability. That's, that's just something that's kind of been on the back burner for a long time. I think people are Thinking about it, but there's so many other immediate problems that needed to be solved, that I think now we have more space to work on things like that. And it's it is important to do that. And we probably should have been doing a lot of that earlier before. Everything was, you know, optimized by machine learning. Because we're seeing like lots of backlash around. People deploying things that maybe shouldn't have been deployed or they're harming certain subpopulations, and would have been nice to think about this beforehand. But sometimes, you know, this is sometimes how humans learn, so.

Sanyam Bhutani  30:38  
Talking about that, do you think there's any research area that needs more active research? Maybe carbon neutral, machine learning fairness, exploitability I know h2o is already making a push towards that. I've already had interviews just as a plug for myself but on the series, what's what's missing from the list according to you?

Erin LeDell  30:59  
Uh, well I think everything you just said on that list are things that, yeah, we should be spending more time on, and especially the interpretability stuff, like, it's really hard to get a job being paid to work on that. So basically, there's a few places that hire for that, like Microsoft and Google h2o would be also one place where you could work on that. But there's, yeah, there's, I know, there are a few startups that are trying to do stuff like that, but we need more research and more jobs where people can work on those things, because I think they are critically important. And yeah, there have been a number of issues raised around a lot of these like very cutting edge modern like language models that are taking like a million dollars to train on EC2 or something like that. There was some paper about it and yeah, so I think like research is still very computationally heavy. And it would be good to come up with ways to reduce the computation of those things. But I think that is just kind of the process. First, you come up with the techniques and they so that they work. And then you can figure out how to make them a bit more efficient. I don't know if that's the right order. But, um, and I think actually, like, I think that's where auto ML will go in a number of years. Like, right now it is a lot about computation and just trying a bunch of things and doing that in an efficient way. But you're still training a bunch of models so but I think probably where auto ML is headed is that we're rather than actually training all those models, we will predict what that results of the models would be and then decide what what we do want to train what we don't have to train. That would be like the golden ticket, you know?

Sanyam Bhutani  33:07  
Yeah. 

Erin LeDell  33:07  
So just use machine learning to predict what the right best model would be. And then you just train that one model and you're done. But that's;

Sanyam Bhutani  33:18  
Machine learning to do machine learning.

Erin LeDell  33:20  
Yeah, no, I think um, this is a whole topic in Michigan in auto ML research. And I think probably the people that are doing the most work on that, at least in the open, I'm sure there's a lot of work in the private labs on this, but if the open ML that work group, so they have developed a platform. And this wasn't necessarily the purpose of the platform, but the purpose of the platform is to have a reproducible network basically or platform for publishing results from like running machine learning algorithms on a bunch of data sets. So they have a very sophisticated process of how they categorize all the data sets and all the tasks that you do on the data sets and how they gather all the results. And they've been doing this for a number of years. And so I think at some point like that could become sort of the training set for auto ML. Although I'm sure that the cloud companies are recording all the results of everything that people are doing. So they're probably doing something similar. So if you're running a cloud based auto ML, you first have to require people to upload their data to your cloud, which, you know, there's a lot that can be said about that. But then they have the data, then you're paying them to run the experiment, and then they collect the results. And then they could basically very easily do something like this. So I'm sure that that's happening. And I think it's important to have an open source version of that. That's why I think open ML is important. Because if we don't, what that means is that the cloud companies are going to be the ones that have this data, and they're going to be the only ones that have this data, and then they're going to have an edge that they, you know, we don't, generally for one company to have an edge over everything else. That's what we call monopoly. And that's not good. So so I think it's important for, for the open source community and the research and academic community to stay ahead of that as well. And they are there's, you know, there's a whole workshop at interrupts about this topic, so.

Sanyam Bhutani  35:45  
For sure. And to give credit for the question. This question was by Eric, including a few questions after this as well, Eric from Twitter. Thank you for the questions. Okay, talking about ensembling, emsembling is a sophisticated and powerful technique. Interpreting this can be a challenge. How do we go about doing that? How, even though it gives a boost in accuracy, how do we reasonably use ensembling?

Erin LeDell  36:10  
Well, I think it depends like how big your ensemble is. So maybe if you have like three models in your ensemble, it's a bit more easy to wrap your head around. And especially if you do just like a linear combination of those models, then it just comes down to understanding the individual models that you have there. I think that pretty much other than GLM and decision trees, like every machine learning algorithm suffers from this sort of black box issue where, for the most part, your brain can't understand what's happening. And so you put some data in, you can get it out, there's some things that you can do then like so we have all these model agnostic techniques for debugging or interpreting machine learning models. And I think the same applies to using ensembles as it does to like a gradient boosting machine, which is also another ensemble or random forest and other ensemble. So most of the really effective machine learning algorithms are ensembles. You know, they even do this with deep learning, there's a lot of deep learning ensembles, that type of thing. So I think what we need to do is just keep focusing on model agnostic tools, meaning a function or an algorithm that can work on any kind of algorithm doesn't matter if it's some 300 model ensemble or a simple random for us. We just have to keep using that. I mean, basically, the research just needs to keep going and till we get to a point where we feel comfortable understanding these models and I think the tooling around that is is starting to get there. But I think that's been the sort of the slow down of that that process is like having good tools. And some of the techniques are quite computationally expensive. So figuring out better ways to take shortcuts in the software and, and getting around some of those computational hurdles would be important. So I would just group ensemble, like big ensembles and with every other type of machine learning algorithm and just do the same, same thing.

Sanyam Bhutani  38:34  
Okay. Zooming out from that, talking about machine learning, generally speaking, what's your opinion on the future research? Where do you see the field heading towards, where do you wish the field should head towards?

Erin LeDell  38:51  
Well, I mean, I really like this auto ML trend, but I think if we want to keep moving in the direction of auto ML, I think we have to equally move in the direction of interpretability. Because the easier that it is to produce all these models, the more people are going to deploy them and the more dangerous that's going to cause. So we really need if we're going to do this thing where we're sort of accelerating machine learning research through auto ML, we need to also accelerate a lot of that other stuff that the protections that go around it like debugging tools. And this is this is kind of a thing that I have been working on. And another collaboration is trying to understand better, like, what is where are the models failing? And when is it actually inappropriate to use a machine learning model? Like maybe your data just isn't good enough and you shouldn't you know, or some other reason, but yeah, I think that that would be where I think things are headed. Just more automation, better tooling, always and Like I said around, like, where I think auto ml is headed. I think it's more of like in a meta meta learning type of realm where we're going to, I mean, yeah, the, the best way to not use compute power is just to not use it rather than to, like, minimize it. And some, you know, just, if we can just predict the results from that. That's, that's super. That's a really powerful tool. And I think, you know, there's been in the last 10 years or so a really big push with deep learning. And I do still see that going forward, like a lot of people, especially people that are new to the field, maybe even start with deep learning and don't meander into the GBM or in harness zone. I think that's not a good long term strategy, but I think I think every tool or every algorithm has its place. But I think that as we trend towards more auto ML tools we'll see less of a fixation on what is the algorithm itself. Because I think a lot of the popularity around deep learning is just this, like obsession with deep learning as a concept or a marketing thing, like people are just like, I do deep learning. So, you know, that's the best thing and I'm cool. So I think when people and this has always been the case, like, before that it was people, oh, I love random forest, and I won't use any other algorithm. And then, you know, then people like GBM, and then they won't use any other algorithms. So people get really fixated on using particular algorithms. And I think, you know, one reason is because you get comfortable with something and you want to just keep using the thing that you're comfortable with. And then you come up with other reasons about why you're doing that, instead of just saying, I just like this algorithm Because I'm good at it, but I think once we make it a bit more abstract and say, you know, let's not be so attached to deep learning versus GBM versus whatever, people will sort of loosen those attachments and then get more focused on what the real problem is, which is just solving the task with the best performance. So hope to see that.

Sanyam Bhutani  42:25  
Okay, zooming out from that. And this is an important contribution that you have been involved in, you, you started two committees that now have grown to huge extent, our ladies and women in machine learning data science. did you decide to start them? Why did you feel the need to start this, what's the story?

Erin LeDell  42:47  
Um, yeah, so both of these groups, they're very similar in their purpose. And that's really just to get more women into these fields. And it's really just a matter of being in the field, it's not very fun to be around, you know, to not have anybody that's like you. So, I think when I started so, women in machine learning and data sciences, WiMLDS and WiMLDS.org that I started in 2013. And that was just the consequence of going to the women and machine learning workshop at Neurips. I went there two years in a row and I just my I, you know, I live in the Bay Area right now I'm, you're in the h2o headquarters here, which is a mountain view. There's so many meetups here, it's like, insane. So I would just go to meetups all the time when I was first really learning a lot of data science and I would just be the only women who are like, there would be five women or something and it it just seems like an obvious thing that needed to be fixed. And so having the idea from women workshop, and the idea of like going to a lot of meetups I just felt like one way to get more women into the field is just to first of all, get them exposed to machine learning and make it community for them, where they feel excited about going to the meetups, instead of kind of like dreading them in a way. And then also what we do is like we always have female and non binary speakers. So that gives people practice at being speakers. So that's another area when you go to conferences too, it used to be the case, and it's not so much the case anymore, although it's still quite bad. There would be no women speakers either. So even if you get into the field, then you don't have people kind of in leadership positions to look up to so that was another reason and yeah, so that's and now that group is are the it's a nonprofit now and there's I can't remember the number right now it might be about Like 90 groups all over the world. 

Sanyam Bhutani  45:02  
Okay.

Erin LeDell  45:03  
I think there's 12 or 13 in India now, I can't remember the total there's always Yeah, there's, I think there's 12. And there's one on my to do list to start a new one. So yeah, it's pretty popular. And then same with our ladies. So in 2016 me and several other people there were like, six of us got together. And there were three I think our ladies chapters at that point, but nobody was communicating to each other and they kind of just existed independently. So then we all got together like the San Francisco, San Francisco people and some London people and decided to kind of make that a thing and create the support for as a nonprofit to create a lot of chapters. And that's just really, really taken off. And I think, I think that just says a lot about the R community in general. Like, we have a quite a strong community in general, and it's, there were no, I mean, maybe there were some impediments to that growth, but it grew like sort of like wildfire because the our community was so welcoming of supporting women. So it's been really popular as well. So I do spend quite a bit of time working on both of those things on on both the leadership teams for that. So yeah. 

Sanyam Bhutani  46:40  
Are Python enthusiasts welcome to the R group?

Erin LeDell  46:45  
Yeah, that's the that's like the best person because then we get to convert them. I should mention there's also Py ladies. So I'm not involved in Py ladies like directly but I know a lot of people that do you know Python as sort of their main language of choice, there's also a Py ladies network. It's not as maybe centrally organized as the our ladies group. But there are, I don't know how many chapters they have, but they have quite a few chapters and a lot of different cities as well. But they're a little bit more general. So they're not just data science. So Python, obviously, is a more general language. So yeah. 

Sanyam Bhutani  47:24  
Okay, looking, looking back in time, do you have any proud moments from from these communities, these moments that you started?

Erin LeDell  47:33  
Um, I mean, I just get really excited when I see people like in other places of the world, like kind of just doing this on their own, you know, they, they get in touch with us, so we don't do anything to try to necessarily, you know, maybe we should try a little harder to like, spread the word, but basically, people independently see us somewhere on the internet and they get the idea And they, you know, really get empowered around this and they create their own community. And, I mean, there's just so many stories that I hear, like, whenever I either talk to people in these groups, or if I go to a conference, or people are like, I mean, it sounds kind of crazy would be like, oh, this changed my life, like I, you know, was doing this before, and I have this new career and it's like, really affecting a lot of people. And, you know, there's between the two communities over 100,000 people. I don't I don't know what the exact numbers are, but at least on meetup, you can count the people in your groups. And so I think, you know, last time I checked, when will the US had over 50,000 I think R ladies has like, more than that, like maybe 70 I'm not sure the numbers but so yeah, there's all these these just big impacts and it's really empowering a lot of people especially in places where there's not as much equality, and being in the US and being in the Bay Area, I mean, I'm pretty privileged in terms of equality. And you know, I feel pretty comfortable. There are definitely moments where it's not that way. But you know, we've had people we have a group in like Saudi Arabia, for example. So you know, people are really changing the culture there by creating these groups so that it's just really rewarding to see that.

Sanyam Bhutani  49:34  
How can outsiders help with this, for example, and I just recognize this, but even on my interview series, for example, now, I think it might change now, but the representation has been one sixth of all of the interviews, it might be one fifth now, but even generally speaking, how can an outsider contribute to these communities?

Erin LeDell  49:54  
Um, well, I think the first thing is just like, like recognizing some of the differences so because when you don't see it, you don't know how to fix it or you don't know that you should fix it. So I think just like learning about, I don't know what women are saying about their experiences of being not represented or, or even just kind of independently looking around and and when you see a conference, like if you see all men maybe think, oh, that's, that's odd, like, there should be like 50% women, you know, in theory like, yes, there's not 50% of the data scientists are probably not women. So it makes it a bit difficult to aim for that at this point. But, um, but I think before you, like, I don't know, I didn't I didn't see these things either before or they were sort of pointed out to me so then yeah, just just be aware of what's going on and, and when people pointed out, let's say on Twitter, other places, just make a mental note and then just start start to see if you see some of these patterns as well. Well, and then once you see it, then you kind of maybe come up with ideas about how to fix it. Like, you have the idea now, okay, maybe I should just see if there's more women data scientists that I could interview on my podcast. And that's, that's the greatest thing that you can do is just seeing it and seeing if there's anything in your power to make any kind of change in that direction. And, yeah, and so, I mean, I think visibility is important. So if you're a conference organizer, or if you're a meetup, organizer, just make it a priority. It's not easy. I'm not gonna say like, you know, like people sometimes get in these bad situations, because it's like, nobody's trying. Well, maybe some people are trying, there are a few people that I think are trying to not have women, but for the most part, people want to do the right thing. They want to be inclusive, but it does actually take extra work. And so a lot of times once people realize how hard it is Actually recruit women speakers. They just say, I don't know, I asked like five people, they all said no, or they couldn't come. So you know, and they get overwhelmed because like organizing a conference is a lot of work. And so I'm just I guess I'm just asking people to be willing to do some extra work, because it's not going to just come for free. So yeah.

Sanyam Bhutani  52:25  
And and like you said, it all starts with first making a note of that it is a problem to be considered and just being aware of it. 

Erin LeDell  52:32  
Yeah. 

Sanyam Bhutani  52:34  
So zooming out, and I'm sure you must get asked this all the time. But if you were to give one advice to beginners who are just starting their journey into the field, what would that be?

Erin LeDell  52:46  
Well, I would bring that back to the communities again, because I think that the first thing that you should do is find yourself a community to be a part of. And you don't have to do that but it's going to make your life a lot easier and it's going to give you the support that you need when you're getting frustrated, or you're confused, or you're doubting yourself. So find a community, whatever it is on meetup on slack on, you know, it doesn't have to be even an in person, community. Maybe it's the fast AI forums, I know you like that. So whoever it is, just find, find yourself a little place. And then a lot of people get all, you know, oh, should I do R or Python, I don't know which one is better, and everybody fights about it, but like, just pick one, and just get good at one language quickly, and then, you know, you will eventually maybe want to know both. There are certainly many other languages other than R and Python that are relevant and data science, but those are kind of the main two. And then, you know, just start learning, learning courses. I mean, I would just say like, there's not one path and it depends a lot about what your background is what you're interested are, what your goals for your career are? So a lot of people ask me, should I do a PhD? Or should I not? And there's not an correct answer to that. It's just really very circumstantial. And it depends, like where you want to be in five or 10 years, well, let's say 10 years because five years old, probably still be in your PhD but 10 years from now. Um, so yeah, and you don't have to know everything, you know, even people that are like experts on whatever, like they don't know everything. So like, you can't be an expert at NLP image classification auto ml software, you can't do everything. So just pick something that's interesting enough to you that you'll keep doing it and find like personal data projects that you want to work on and that will motivate you so if there's some interesting data set, or even if somebody, like I think there are a lot of examples of this on Kaggle, like, there's data sets, and people do little notebooks and kind of just, you know, and just find a data set doesn't have to be something even personal to you, but something interesting enough. And then eventually you'll, you know, get a job. That's kind of the hard part like transitioning from, into data science, getting your first job, but that's where the networks come in handy. And don't be afraid to use your network like, it's, you know, going to help so don't be afraid to ask somebody for help, or, hey, I saw you work at this company. Could I ask you about working there and, you know, I think especially if you're an under represented person, but anyway, so yeah, just just that, that stuff. And you'll eventually get there. And you'll make a lot of friends along the way.

Sanyam Bhutani  56:10  
Awesome. Erin, thank you so much for joining me on the podcast. And thank you so much for all of your open source contributions and contributions to the community.

Erin LeDell  56:19  
Thank you. I appreciate you having me on the podcast. And now I'm joining a bunch of other cool people that have participated in this.

Sanyam Bhutani  56:38  
Thank you so much for listening to this episode. If you enjoyed the show, please be sure to give it a review, or feel free to shoot me a message you can find all of the social media links in the description. If you like the show, please subscribe and tune in each week to "Chai Time Data Science".

